<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Random ODE · PolyChaos.jl</title><script async src="https://www.googletagmanager.com/gtag/js?id=UA-90474609-3"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-90474609-3', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="../assets/warner.js"></script><link rel="canonical" href="https://docs.sciml.ai/PolyChaos/stable/random_ode/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="PolyChaos.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">PolyChaos.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Overview</a></li><li><a class="tocitem" href="../type_hierarchy/">Type Hierarchy</a></li><li><span class="tocitem">Usage</span><ul><li><a class="tocitem" href="../numerical_integration/">Numerical Integration</a></li><li><a class="tocitem" href="../quadrature_rules/">Quadrature Rules</a></li><li><a class="tocitem" href="../orthogonal_polynomials_canonical/">Univariate Monic Orthogonal Polynomials</a></li><li><a class="tocitem" href="../gaussian_mixture_model/">Gaussian Mixture Models</a></li><li><a class="tocitem" href="../multiple_discretization/">Multiple Discretization</a></li><li><a class="tocitem" href="../scalar_products/">Computation of Scalar Products</a></li><li><input class="collapse-toggle" id="menuitem-3-7" type="checkbox" checked/><label class="tocitem" for="menuitem-3-7"><span class="docs-label">Polynomial Chaos</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../pce_tutorial/">Basic Usage</a></li><li><a class="tocitem" href="../chi_squared_k1/">Chi Squared, One DOF</a></li><li><a class="tocitem" href="../chi_squared_k_greater1/">Chi Squared, Several DOFs</a></li><li class="is-active"><a class="tocitem" href>Random ODE</a><ul class="internal"><li><a class="tocitem" href="#Theory"><span>Theory</span></a></li><li><a class="tocitem" href="#Practice"><span>Practice</span></a></li></ul></li></ul></li><li><a class="tocitem" href="../DCsOPF/">Optimal Power Flow</a></li></ul></li><li><a class="tocitem" href="../math/">Mathematical Background</a></li><li><a class="tocitem" href="../functions/">Functions</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Usage</a></li><li><a class="is-disabled">Polynomial Chaos</a></li><li class="is-active"><a href>Random ODE</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Random ODE</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/SciML/PolyChaos.jl/blob/master/docs/src/random_ode.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Galerkin-based-Solution-of-Random-Differential-Equation"><a class="docs-heading-anchor" href="#Galerkin-based-Solution-of-Random-Differential-Equation">Galerkin-based Solution of Random Differential Equation</a><a id="Galerkin-based-Solution-of-Random-Differential-Equation-1"></a><a class="docs-heading-anchor-permalink" href="#Galerkin-based-Solution-of-Random-Differential-Equation" title="Permalink"></a></h1><p>This tutorial demonstrates how random differential equations can be solved using polynomial chaos expansions (PCE).</p><h2 id="Theory"><a class="docs-heading-anchor" href="#Theory">Theory</a><a id="Theory-1"></a><a class="docs-heading-anchor-permalink" href="#Theory" title="Permalink"></a></h2><p>A random differential equation is an ordinary differential equation that has random parameters, hence its solution is itself a (time-varying) random variable. Perhaps the simplest non-trivial example is the following scalar, linear ordinary differential equation</p><p class="math-container">\[\dot{x}(t) = a x(t), \quad x(0) = x_{0},\]</p><p>where <span>$a$</span> is the realization of a Gaussian random variable <span>$\mathsf{a} \sim \mathcal{N}(\mu, \sigma^2)$</span> with mean <span>$\mu$</span> and variance <span>$\sigma^2$</span>. Arguably, for every realization <span>$a$</span> we can solve the differential equation and obtain</p><p class="math-container">\[x(t) = x_0 \mathrm{e}^{a t},\]</p><p>from which we find that</p><p class="math-container">\[\ln (x(t)) = \ln (x_0) + at \sim \mathcal{N}(\ln(x_0) + \mu t, (\sigma t)^2).\]</p><p>In other words, the logarithm of the solution is normally distributed (so-called <a href="https://en.wikipedia.org/wiki/Log-normal_distribution">log-normal distribution</a>).</p><p>We&#39;d like to obtain this result numerically with the help of PCE. The first step is to define the (truncated) PCE for the random variable <span>$\mathsf{a}$</span></p><p class="math-container">\[\mathsf{a} = \sum_{i=0}^{L} a_i \phi_i,\]</p><p>where <span>$a_i$</span> are the so-called PCE coefficients, and <span>$\phi_i$</span> are the orthogonal basis polynomials. As the solution to the random differential equation is itself a random variable, we treat <span>$x(t)$</span> as the realization of the random variable <span>$\mathsf{x}(t)$</span>, and define its PCE</p><p class="math-container">\[\mathsf{x}(t) = \sum_{i=0}^{L} x_i(t) \phi_i.\]</p><p>The question is how to obtain the unknown PCE coefficients <span>$x_i(t)$</span> from the known PCE coefficients <span>$a_i$</span> relative to the orthogonal basis polynomials <span>$\phi_i$</span>. This can be done using Galerkin projection, which is nothing else than projecting onto the orthogonal basis. Think of a three-dimensional space, in which you have placed some three-dimensional object. If you know project the silhouette of the object onto every axis of the three-dimensional space, then you are doing a Galerkin projection. With PCE the concept is equivalent, but the imagination has a harder time. The first step for Galerkin projection is to insert the PCEs</p><p class="math-container">\[\sum_{i=0}^{L} \dot{x}_i(t) \phi_i = \sum_{j=0}^{L} a_j \phi_j \sum_{k=0}^{L} x_k(t) \phi_k;\]</p><p>the second step is to project onto every basis polynomial <span>$\phi_m$</span> for <span>$m = 0, 1, \dots, L$</span>, and to exploit orthogonality of the basis. This gives</p><p class="math-container">\[\dot{x}_m(t) \langle \phi_m, \phi_m \rangle = \sum_{j=0}^{L} \sum_{k=0}^{L} a_j x_k(t) \langle \phi_l \phi_k, \phi_m \rangle \quad m = 0, 1, \dots, L.\]</p><p>Of course, the initial condition must not be forgotten:</p><p class="math-container">\[x_0(0) = x_0, \quad x_m(0) = 0 \quad m = 1, \dots, L.\]</p><p>If we can solve this enlarged system of ordinary random differential equations, we can reconstruct the analytic solution.</p><h2 id="Practice"><a class="docs-heading-anchor" href="#Practice">Practice</a><a id="Practice-1"></a><a class="docs-heading-anchor-permalink" href="#Practice" title="Permalink"></a></h2><p>We begin by defining the random differential equation</p><pre><code class="language-julia hljs">x0 = 2.0
μ, σ = -0.5, 0.05
tend, Δt = 3.0, 0.01</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(3.0, 0.01)</code></pre><p>Next, we define an orthogonal basis (and its quadrature rule) relative to the Gaussian measure using <code>PolyChaos</code>. We choose a maximum degree of <code>L</code>.</p><pre><code class="language-julia hljs">using PolyChaos
L, Nrec = 6, 40
opq = GaussOrthoPoly(L; Nrec = Nrec, addQuadrature = true)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">GaussOrthoPoly{Vector{Float64}, GaussMeasure, Quad{Float64, Vector{Float64}}}(6, [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0  …  30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0], GaussMeasure(PolyChaos.w_gaussian, (-Inf, Inf), true), Quad{Float64, Vector{Float64}}(&quot;golubwelsch&quot;, 39, [-11.289716044476336, -10.313341442756984, -9.501306853782868, -8.77343869806765, -8.099152213152415, -7.462682377866034, -6.854552519790949, -6.268491549685286, -5.70006245427186, -5.145964544094179  …  5.145964544094181, 5.700062454271864, 6.268491549685283, 6.8545525197909525, 7.462682377866034, 8.099152213152408, 8.773438698067643, 9.50130685378287, 10.313341442756998, 11.28971604447633], [9.44334457506254e-29, 2.7847875052255215e-24, 7.592450542206407e-21, 5.3707014584628806e-18, 1.4861295877332447e-15, 1.9987266806236867e-13, 1.491720010448957e-11, 6.748646364787684e-10, 1.9698729205993618e-8, 3.8841182837133245e-7  …  3.884118283713275e-7, 1.9698729205993343e-8, 6.748646364787814e-10, 1.491720010448936e-11, 1.9987266806237069e-13, 1.4861295877332938e-15, 5.3707014584630586e-18, 7.592450542206142e-21, 2.7847875052254187e-24, 9.443344575062644e-29]))</code></pre><p>Now we can define the PCE for <span>$\mathsf{a}$</span> and solve the Galerkin-projected ordinary differential equation using <code>DifferentialEquations.jl</code>.</p><pre><code class="language-julia hljs">using DifferentialEquations

a = [convert2affinePCE(μ, σ, opq); zeros(Float64, L - 1)] # PCE coefficients of a
xinit = [x0; zeros(Float64, L)] # PCE coefficients of initial condition

t2 = Tensor(2, opq); # \langle \phi_i, \phi_j \rangle
t3 = Tensor(3, opq); # \langle \phi_i \phi_j, \phi_k \rangle

# Galerkin-projected random differential equation
function ODEgalerkin(du, u, p, t)
    du[:] = [sum(p[j + 1] * u[k + 1] * t3.get([j, k, m]) / t2.get([m, m]) for j in 0:L
                 for k in 0:L) for m in 0:L]
end

probgalerkin = ODEProblem(ODEgalerkin, xinit, (0, tend), a)
solgalerkin = solve(probgalerkin; saveat = 0:Δt:tend)
t, x = solgalerkin.t, solgalerkin.u;</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">([0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09  …  2.91, 2.92, 2.93, 2.94, 2.95, 2.96, 2.97, 2.98, 2.99, 3.0], [[2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.9900252071385, 0.0009950126035692532, 2.487531508917427e-7, 4.145885853203421e-11, 5.1823554241448126e-15, 5.18237285905222e-19, 4.446367982010917e-23], [1.9801006575270281, 0.0019801006679350595, 9.900482838759834e-7, 3.302217230802382e-10, 7.191587836605381e-14, 2.552297839257448e-16, -9.336417123895147e-19], [1.9702260956550872, 0.0029553391699344914, 2.2164991440224457e-6, 1.1087782320981967e-9, 3.880756852156263e-13, 7.647078374449501e-16, -3.0601683025036123e-18], [1.9604012673415023, 0.0039208025693738945, 3.920795659105188e-6, 2.6145693296525264e-9, 1.2695719817981495e-12, 1.4309116759424666e-15, -5.3314999776696016e-18], [1.9506259196896107, 0.00487656483071621, 6.095699691025267e-6, 5.080409655788689e-9, 3.138859153867438e-12, 2.522647378178159e-15, -6.6478229558329896e-18], [1.94089980108726, 0.005822699423080999, 8.734045035810811e-6, 8.734487546531226e-9, 6.524935767106495e-12, 4.675567823572938e-15, -5.857545001877662e-18], [1.9312226612068097, 0.0067592793202444325, 1.1828737423617071e-5, 1.3800365033883713e-8, 1.2063344567127623e-11, 8.892172692208817e-15, -1.7572954276259006e-18], [1.92159425100513, 0.007686377000639301, 1.5372754518726352e-5, 2.049697784582881e-8, 2.049617247947276e-11, 1.6541808464828827e-14, 6.908074908161587e-18], [1.912014322723603, 0.008604064447354941, 1.935914591954773e-5, 2.9038635406327468e-8, 3.267205060960968e-11, 2.936066842283648e-14, 2.1445493599785843e-17]  …  [0.4717682324476057, 0.06864220151579949, 0.004993736418123419, 0.00024219450240019064, 8.80990541705697e-6, 2.5636668810180443e-7, 6.200375982975948e-9], [0.4694494907228336, 0.0685395483131638, 0.0050034034535759876, 0.00024349724514499942, 8.887729361711562e-6, 2.5952015845416507e-7, 6.2981009199358e-9], [0.46714226194367997, 0.06843626325909681, 0.00501297284569404, 0.000244798443550197, 8.965822463898337e-6, 2.626970759581246e-7, 6.396916976417893e-9], [0.4648464883847447, 0.06833235513846007, 0.005022444764258137, 0.0002460980574677505, 9.044182650674584e-6, 2.658974600039849e-7, 6.4968304287977586e-9], [0.4625621126313897, 0.06822783265777074, 0.005031819383033396, 0.0002473960470441734, 9.122807836618798e-6, 2.6912132882792755e-7, 6.5978475384686746e-9], [0.4602890775797436, 0.06812270444520165, 0.005041096879769474, 0.00024869237272052297, 9.201695923830512e-6, 2.723686995120074e-7, 6.699974551841447e-9], [0.45802732643669797, 0.06801697905058116, 0.005050277436200587, 0.0002499869952324023, 9.28084480193043e-6, 2.75639587984158e-7, 6.803217700344587e-9], [0.4557768027199091, 0.06791066494539329, 0.005059361238045494, 0.0002512798756099595, 9.360252348060364e-6, 2.7893400901818877e-7, 6.907583200424231e-9], [0.45353745025779757, 0.06780377052277768, 0.0050683484750075085, 0.0002525709751778877, 9.439916426883248e-6, 2.8225197623378586e-7, 7.0130772535441425e-9], [0.4513092131895478, 0.06769630409752951, 0.005077239340774493, 0.00025386025555542547, 9.519834890583158e-6, 2.855935020965127e-7, 7.119706046185762e-9]])</code></pre><p>For later purposes, we compute the expected value and the standard deviation at all time instants using PCE.</p><pre><code class="language-julia hljs"># an advantage of PCE is that moments can be computed from the PCE coefficients alone; no sampling required
mean_pce = [mean(x_, opq) for x_ in x]
std_pce = [std(x_, opq) for x_ in x]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">301-element Vector{Float64}:
 0.0
 0.0009950126657575441
 0.0019801011629582794
 0.0029553408323057043
 0.003920806490165914
 0.004876572450342815
 0.005822712524166973
 0.006759300020585329
 0.007686407746251858
 0.008604108005619074
 ⋮
 0.06890642513273801
 0.0688051118567036
 0.06870317328013559
 0.06860061804929832
 0.068497454732652
 0.06839369182086615
 0.06828933772683328
 0.06818440078568276
 0.06807888925479468</code></pre><p>We compare the solution from PCE to a Monte-Carlo-based solution. That means to solve the ordinary differential equation for many samples of <span>$\mathsf{a}$</span>. We first sample from the measure using <code>sampleMeasure</code>, and then generate samples of <span>$\mathsf{a}$</span> using <code>evaluatePCE</code>. After that, we solve the ODE and store the results in <code>xmc</code>.</p><pre><code class="language-julia hljs">using Statistics
Nsmpl = 5000
ξ = sampleMeasure(Nsmpl, opq)     # sample from Gaussian measure; effectively randn() here
asmpl = evaluatePCE(a, ξ, opq)     # sample random variable with PCE coefficients a; effectively μ + σ*randn() here
# or: asmpl = samplePCE(Nsmpl,a,opq)
xmc = [solve(ODEProblem((u, p, t) -&gt; aa * u, x0, (0, tend)); saveat = 0:Δt:tend).u
       for aa in asmpl]
xmc = hcat(xmc...);</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">301×5000 Matrix{Float64}:
 2.0       2.0       2.0       2.0       …  2.0       2.0       2.0
 1.99143   1.99067   1.99165   1.98906      1.98999   1.99137   1.99119
 1.98289   1.98138   1.98334   1.97818      1.98003   1.98278   1.98241
 1.9744    1.97214   1.97507   1.96736      1.97012   1.97422   1.97368
 1.96593   1.96294   1.96683   1.95659      1.96026   1.9657    1.96498
 1.95751   1.95378   1.95862   1.94589   …  1.95044   1.95722   1.95632
 1.94912   1.94466   1.95045   1.93525      1.94068   1.94878   1.9477
 1.94077   1.93559   1.94231   1.92466      1.93097   1.94037   1.93912
 1.93245   1.92656   1.9342    1.91413      1.9213    1.932     1.93057
 1.92417   1.91757   1.92613   1.90366      1.91168   1.92366   1.92206
 ⋮                                       ⋱                      
 0.570666  0.510496  0.58989   0.403077     0.462019  0.56579   0.550768
 0.56822   0.508114  0.587429  0.400872     0.459707  0.563349  0.548341
 0.565785  0.505744  0.584978  0.398679     0.457406  0.560918  0.545924
 0.56336   0.503384  0.582537  0.396498  …  0.455116  0.558498  0.543519
 0.560946  0.501036  0.580106  0.394329     0.452838  0.556088  0.541123
 0.558542  0.498698  0.577685  0.392172     0.450571  0.553688  0.538739
 0.556148  0.496371  0.575275  0.390026     0.448316  0.551299  0.536365
 0.553765  0.494056  0.572875  0.387893     0.446072  0.548921  0.534001
 0.551392  0.491751  0.570484  0.385771  …  0.443839  0.546552  0.531648</code></pre><p>Now we can compare the Monte Carlo mean and standard deviation to the expression from PCE for every time instant.</p><pre><code class="language-julia hljs">[mean(xmc, dims = 2) - mean_pce std(xmc, dims = 2) - std_pce]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">301×2 Matrix{Float64}:
 0.0          0.0
 5.35313e-6   6.86338e-6
 1.06596e-5   1.36782e-5
 1.59198e-5   2.04447e-5
 2.1134e-5    2.71631e-5
 2.63025e-5   3.38335e-5
 3.14256e-5   4.04563e-5
 3.65037e-5   4.70317e-5
 4.15369e-5   5.35599e-5
 4.65256e-5   6.00411e-5
 ⋮            
 0.000444306  0.000677993
 0.000443919  0.000677684
 0.000443527  0.000677367
 0.000443129  0.000677042
 0.000442726  0.000676709
 0.000442318  0.000676369
 0.000441905  0.00067602
 0.000441487  0.000675664
 0.000441064  0.0006753</code></pre><p>Clearly, the accuracy of PCE deteriorates over time. Possible remedies are to increase the dimension of PCE, and to tweak the tolerances of the integrator.</p><p>Finally, we compare whether the samples follow a log-normal distribution, and compare the result to the analytic mean and standard deviation.</p><pre><code class="language-julia hljs">logx_pce = [log.(evaluatePCE(x_, ξ, opq)) for x_ in x]
[mean.(logx_pce) - (log(x0) .+ μ * t) std.(logx_pce) - σ * t]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">301×2 Matrix{Float64}:
 -6.66134e-16  6.662e-16
  2.68829e-6   3.44386e-6
  5.37658e-6   6.88772e-6
  8.06486e-6   1.03316e-5
  1.07531e-5   1.37755e-5
  1.34414e-5   1.72193e-5
  1.61297e-5   2.06632e-5
  1.88181e-5   2.4107e-5
  2.15064e-5   2.75509e-5
  2.41947e-5   3.09947e-5
  ⋮            
  0.000785259  0.00100543
  0.000787952  0.00100887
  0.000790643  0.00101231
  0.000793334  0.00101575
  0.000796024  0.0010192
  0.000798712  0.00102264
  0.000801401  0.00102608
  0.000804089  0.00102953
  0.000806777  0.00103297</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../chi_squared_k_greater1/">« Chi Squared, Several DOFs</a><a class="docs-footer-nextpage" href="../DCsOPF/">Optimal Power Flow »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Monday 5 February 2024 03:36">Monday 5 February 2024</span>. Using Julia version 1.10.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
