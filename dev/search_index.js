var documenterSearchIndex = {"docs":
[{"location":"orthogonal_polynomials_canonical/#UnivariateMonicOrthogonalPolynomials","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"","category":"section"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"Univariate monic orthogonal polynomials make up the core building block of the package. These are real polynomials  pi_k _k geq 0, which are univariate pi_k mathbbR rightarrow mathbbR and orthogonal relative to a nonnegative weight function w mathbbR rightarrow mathbbR_geq 0, and which have a leading coefficient equal to one:","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"beginaligned\npi_k(t) = t^k + a_k-1 t^k-1 + dots + a_1 t + a_0 quad forall k = 0 1 dots \nlangle pi_k pi_l rangle = int_mathbbR pi_k(t) pi_l(t) w(t) mathrmdt =\nbegincases\n0  k neq l text and kl geq 0 \n pi_k ^2  0  k = l geq 0\nendcases\nendaligned","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"These univariate monic orthogonal polynomials satisfy the paramount three-term recurrence relation","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"beginaligned\npi_k+1(t) = (t - alpha_k) pi_k(t) - beta_k pi_k-1(t) quad k= 0 1 dots \npi_o(t) = 1 \npi_-1(t) = 0\nendaligned","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"Hence, every system of n univariate monic orthogonal polynomials  pi_k _k=0^n is isomorphic to its recurrence coefficients  alpha_k beta_k _k=0^n.","category":"page"},{"location":"orthogonal_polynomials_canonical/#Canonical-Orthogonal-Polynomials","page":"Univariate Monic Orthogonal Polynomials","title":"Canonical Orthogonal Polynomials","text":"","category":"section"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"The so-called classical or canonical orthogonal polynomials are polynomials named after famous mathematicians who each discovered a special family of orthogonal polynomials, for example Hermite polynomials or Jacobi polynomials. For classical orthogonal polynomials there exist closed-form expressions of–-among others–-the recurrence coefficients. Also quadrature rules for classical orthogonal polynomials are well-studied (with dedicated packages such as FastGaussQuadrature.jl. However, more often than not these classical orthogonal polynomials are neither monic nor orthogonal, hence not normalized in any sense. For example, there is a distinction between the probabilists' Hermite polynomials and the physicists' Hermite polynomials. The difference is in the weight function w(t) relative to which the polynomials are orthogonal:","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"beginaligned\ntextProbabilists w(t) = frac1sqrt2 pi  exp left( - fract^22 right) \ntextPhysicists w(t) =  exp left( - t^2 right)\nendaligned","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"To streamline the computations, all classical orthogonal polynomials are converted to monic orthogonal polynomials (for which, of course, the closed-form expressions persist). Currently, the following weight functions (hence classical orthogonal polynomials) are supported:","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"Name Weight w(t) Parameters Support Classical polynomial\nhermite $ \\exp \\left( - t^2 \\right)$ - (-infty infty) Hermite\ngenhermite $ \\lvert t \\rvert^{2 \\mu}\\exp \\left( - t^2 \\right)$ mu  -frac12 (-infty infty) Generalized Hermite\nlegendre 1 - (-11) Legendre\njacobi (1-t)^alpha (1+t)^beta alpha beta  -1 (-11) Jacobi\nlaguerre exp(-t) - (0infty) Laguerre\ngenlaguerre t^alphaexp(-t) alpha-1 (0infty) Generalized Laguerre\nmeixnerpollaczek frac12 pi exp((2phi-pi)t) lvertGamma(lambda + mathrmit)rvert^2 lambda  0 0phipi (-inftyinfty) Meixner-Pollaczek","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"Additionally, the following weight functions that are equivalent to probability density functions are supported:","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"Name Weight w(t) Parameters Support Classical polynomial\ngaussian frac1sqrt2 pi  exp left( - fract^22 right) - (-infty infty) Probabilists' Hermite\nuniform01 1 - (01) Legendre\nbeta01 frac1B(alphabeta)  t^alpha-1 (1-t)^beta-1 alpha beta  0 (01) Jacobi\ngamma fracbeta^alphaGamma(alpha) t^alpha-1 exp(-beta t) alpha beta  0 (0infty) Laguerre\nlogistic fracexp(-t)(1+exp(-t))^2 - (-inftyinfty) -","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"To generate the orthogonal polynomials up to maximum degree deg, simply call","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"julia> using PolyChaos\n\njulia> deg = 4\n4\n\njulia> op = GaussOrthoPoly(deg)\nGaussOrthoPoly{Array{Float64,1},GaussMeasure,Quad{Float64,Array{Float64,1}}}(4, [0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 2.0, 3.0, 4.0], GaussMeasure(PolyChaos.w_gaussian, (-Inf, Inf), true), Quad{Float64,Array{Float64,1}}(\"golubwelsch\", 4, [-2.3344142183389778, -0.7419637843027257, 0.7419637843027258, 2.3344142183389778], [0.04587585476806844, 0.45412414523193134, 0.45412414523193106, 0.04587585476806852]))\n\njulia> show(op)\n\nUnivariate orthogonal polynomials\ndegree:         4\n#coeffs:        5\nα =             [0.0, 0.0, 0.0, 0.0, 0.0]\nβ =             [1.0, 1.0, 2.0, 3.0, 4.0]\n\nMeasure dλ(t)=w(t)dt\nw:      w_gaussian\ndom:    (-Inf, Inf)\nsymmetric:      true","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"This generates opas a GaussOrthoPoly type with the underlying Gaussian measure op.measure. The recurrence coefficients are accessible via coeffs().","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"julia> coeffs(op)\n5×2 Array{Float64,2}:\n 0.0  1.0\n 0.0  1.0\n 0.0  2.0\n 0.0  3.0\n 0.0  4.0","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"By default, the constructor for OrthoPoly generates deg+1 recurrence coefficients. Sometimes, some other number Nrec may be required. This is why Nrec is a keyword for the constructor OrthoPoly.","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"julia> N = 100\n100\n\njulia> opLogistic = LogisticOrthoPoly(deg; Nrec = N)\nLogisticOrthoPoly{Array{Float64,1},LogisticMeasure,Quad{Float64,Array{Float64,1}}}(4, [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 3.289868133696453, 10.527578027828648, 22.841084471092515, 40.10505915363294, 62.30810859273584, 89.4476035231595, 121.52266752315666, 158.53293971318436, 200.47824915030117  …  19986.565781520196, 20433.165380253333, 20884.69978120051, 21341.168984361153, 21802.572989734712, 22268.91179732067, 22740.185407118537, 23216.393819127847, 23697.53703334815, 24183.61504977904], LogisticMeasure(PolyChaos.w_logistic, (-Inf, Inf), true), Quad{Float64,Array{Float64,1}}(\"golubwelsch\", 99, [-285.97091675697385, -266.56611354854135, -251.01698966393153, -237.53179686807928, -225.4187633699017, -214.31820469129195, -204.0126795649811, -194.35793540921836, -185.25200558110012, -176.61940782973926  …  176.61940782973895, 185.25200558110018, 194.35793540921847, 204.01267956498108, 214.31820469129212, 225.4187633699016, 237.53179686807948, 251.01698966393138, 266.56611354854135, 285.9709167569736], [1.4541663108207099e-123, 2.897917000559268e-115, 1.3858976222735606e-108, 8.826460482953542e-103, 1.4618715331286334e-97, 8.935651454381735e-93, 2.49282531464423e-88, 3.6557113389197252e-84, 3.1147999002113552e-80, 1.660700338355251e-76  …  1.6607003383554774e-76, 3.1147999002111335e-80, 3.6557113389195227e-84, 2.492825314644278e-88, 8.935651454380596e-93, 1.461871533128785e-97, 8.826460482953113e-103, 1.3858976222735651e-108, 2.8979170005595435e-115, 1.4541663108207404e-123]))\n\njulia> show(opLogistic)\n\nUnivariate orthogonal polynomials\ndegree:         4\n#coeffs:        100\nα =             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]...\nβ =             [1.0, 3.289868133696453, 10.527578027828648, 22.841084471092515, 40.10505915363294, 62.30810859273584, 89.4476035231595]...\n\nMeasure dλ(t)=w(t)dt\nw:      w_logistic\ndom:    (-Inf, Inf)\nsymmetric:      true","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"Let's check whether we truly have more coefficients:","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"julia> size(coeffs(opLogistic), 1) == N\ntrue","category":"page"},{"location":"orthogonal_polynomials_canonical/#Arbitrary-Weights","page":"Univariate Monic Orthogonal Polynomials","title":"Arbitrary Weights","text":"","category":"section"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"If you are given a weight function w that does not belong to the Table above, it is still possible to generate the respective univariate monic orthogonal polynomials. First, we define the measure by specifying a name, the weight, the support, symmetry, and parameters","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"julia> supp = (-1, 1)\n(-1, 1)\n\njulia> w(t) = 1 + t\nw (generic function with 1 method)\n\njulia> my_meas = Measure(\"my_meas\", w, supp, false, Dict())\nMeasure(\"my_meas\", w, (-1.0, 1.0), false, Dict{Any,Any}())","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"Notice: it is advisable to define the weight such that an error is thrown for arguments outside of the support.","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"Now, we want to construct the univariate monic orthogonal polynomials up to degree deg relative to my_meas. The constructor is","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"julia> my_op = OrthoPoly(\"my_op\", deg, my_meas; Nquad = 200);\n\njulia> show(my_op)\n\nUnivariate orthogonal polynomials\ndegree:         4\n#coeffs:        5\nα =             [0.3333333333333335, 0.06666666666666644, 0.028571428571428848, 0.015873015873015657, 0.010101010101010171]\nβ =             [2.0, 0.2222222222222223, 0.23999999999999996, 0.24489795918367344, 0.2469135802469136]\n\nMeasure dλ(t)=w(t)dt\nname:   my_meas\nw:      w\ndom:    (-1.0, 1.0)\nsymmetric:      false\npars:   Dict{Any,Any}()","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"By default, the recurrence coefficients are computed using the Stieltjes procuedure with Clenshaw-Curtis quadrature (with Nquad nodes and weights). Hence, the choice of Nquad influences accuracy.","category":"page"},{"location":"orthogonal_polynomials_canonical/#MultivariateMonicOrthogonalPolynomials","page":"Univariate Monic Orthogonal Polynomials","title":"Multivariate Monic Orthogonal Polynomials","text":"","category":"section"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"Suppose we have p systems of univariate monic orthogonal polynomials,","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":" pi_k^(1) _kgeq 0   pi_k^(2) _kgeq 0 dots  pi_k^(p) _kgeq 0","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"each system being orthogonal relative to the weights w^(1) w^(2) dots w^(p) with supports mathcalW^(1) mathcalW^(2) dots mathcalW^(p). Also, let d^(i) be the maximum degree of the i-th system of univariate orthogonal polynomials. We would like to construct a p-variate monic basis  psi_k _k geq 0 with psi mathbbR^p rightarrow mathbbR of degree at most 0 leq d leq min_i=1dotsk d^(i). Further, this basis shall be orthogonal relative to the product measure w mathcalW = mathcalW^(1) otimes mathcalW^(2) otimes cdots otimes mathcalW^(p) rightarrow mathbbR_geq 0 given by","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"w(t) = prod_i=1^p w^(i)(t_i)","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"hence satisfies","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"langle psi_k psi_l rangle = int_mathcalW psi_k(t) psi_l(t) w(t) mathrmd t =\nbegincases\n0  k neq l text and kl geq 0 \n psi_k ^2  0  k = l geq 0\nendcases","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"For this, there exists the composite struct MultiOrthoPoly. Let's consider an example where we mix classical orthogonal polynomials with an arbitrary weight.","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"julia> deg = [3, 5, 6, 4]\n4-element Array{Int64,1}:\n 3\n 5\n 6\n 4\n\njulia> d = minimum(deg)\n3\n\njulia> op1 = GaussOrthoPoly(deg[1]);\n\njulia> op2 = Uniform01OrthoPoly(deg[2]);\n\njulia> op3 = Beta01OrthoPoly(deg[3], 2, 1.2);\n\njulia> ops = [op1, op2, op3, my_op];\n\njulia> mop = MultiOrthoPoly(ops, d);\n\njulia> show(mop)\n\n4-variate orthogonal polynomials\nname:           GaussOrthoPoly{Array{Float64,1},GaussMeasure,Quad{Float64,Array{Float64,1}}}\n                Uniform01OrthoPoly{Array{Float64,1},Uniform01Measure,Quad{Float64,Array{Float64,1}}}\n                Beta01OrthoPoly{Array{Float64,1},Beta01Measure,Quad{Float64,Array{Float64,1}}}\n                my_op\ndeg:            3\ndim:            35\nind:            [0, 0, 0, 0]\n                [1, 0, 0, 0]\n                [0, 1, 0, 0]\n                [0, 0, 1, 0]\n                [0, 0, 0, 1]\n                [2, 0, 0, 0]\n                [1, 1, 0, 0]\n                ...\n\nfalse","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"The total number of  basis polynomials is stored in the field dim. The univariate basis polynomials making up the multivariate basis are stored in the field uni. The field ind contains the multi-index, i.e. row i stores what combination of univariate polynomials makes up the i-th multivariate polynomial. For example,","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"julia> i = 11;\n\njulia> mop.ind[i + 1, :]\n4-element Array{Int64,1}:\n 0\n 1\n 0\n 1","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"translates mathematically to","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"psi_11(t) = pi_0^(1)(t_1) pi_1^(2)(t_2) pi_0^(3)(t_3) pi_1^(4)(t_4)","category":"page"},{"location":"orthogonal_polynomials_canonical/","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"Notice that there is an offset by one, because the basis counting starts at 0, but Julia is 1-indexed. The underlying measure of mop is now of type ProductMeasure, and stored in the field measure The weight w can be evaluated as one would expect.","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"using PolyChaos, JuMP, MosekTools, LinearAlgebra\nA = [ -1 1 0 0; -1 0 1 0; -1 0 0 1 ; 0 1 -1 0; 0 0 -1 1] # incidence matrix\nNl, N = size(A,1), size(A,2)\nBbr = diagm(0 => -( 2 .+ 10*rand(Nl) )) # line parameters\nΨ = [ zeros(Nl)  -Bbr*A[:,2:end]*inv(A[:,2:end]'*Bbr*A[:,2:end]) ] # PTDF matrix\nCp, Cd = [1 0; 0 0; 0 0; 0 1], [0 0; 1 0; 0 1; 0 0 ] # book-keeping\nNg, Nd = size(Cp,2), size(Cd,2)\nc = 4 .+ 10*rand(Ng) # cost function parameters\nλp, λl = 1.6*ones(Ng), 1.6*ones(Nl) # lambdas for chance constraint reformulations\npmax, pmin = 10*ones(Ng), zeros(Ng) # engineering limits\nplmax, plmin = 10*ones(Nl), -10*ones(Nl) # engineering limits\ndeg = 1\nopq = [Uniform01OrthoPoly(deg; Nrec=5*deg), Uniform01OrthoPoly(deg; Nrec=5*deg)]\nmop = MultiOrthoPoly(opq, deg)\nNpce = mop.dim\nd = zeros(Nd,Npce) # PCE coefficients of load\nd[1,[1,2]] = convert2affinePCE(1., 0.1, mop.uni[1], kind=\"μσ\")\nd[2,[1,3]] = convert2affinePCE(2., 0.2, mop.uni[2], kind=\"μσ\")\nfunction buildSOC(x::Vector,mop::MultiOrthoPoly)\n    t = [ sqrt(Tensor(2,mop).get([i,i])) for i in 0:mop.dim-1 ]\n    (t.*x)[2:end]\nend\nmodel = Model(with_optimizer(Mosek.Optimizer))\n@variable(model, p[i in 1:Ng,j in 1:Npce], base_name=\"p\")\n@constraint(model, energy_balance[j in 1:Npce], sum(p[i,j] for i in 1:Ng) - sum(d[i,j] for i in 1:Nd) == 0)\n@constraint(model, con_pmax[i in 1:Ng], [1/λp[i]*(pmax[i] - mean(p[i,:],mop)); buildSOC(p[i,:],mop)] in SecondOrderCone())\n@constraint(model, con_pmin[i in 1:Ng], [1/λp[i]*(mean(p[i,:],mop) - pmin[i]); buildSOC(p[i,:],mop)] in SecondOrderCone())\npl = Ψ*(Cp*p + Cd*d)\n@constraint(model, con_plmax[i in 1:Nl], [1/λl[i]*(plmax[i] - mean(pl[1,:],mop)); buildSOC(pl[i,:],mop)] in SecondOrderCone())\n@constraint(model, con_plmin[i in 1:Nl], [1/λl[i]*(mean(pl[1,:],mop) - plmin[i]); buildSOC(pl[i,:],mop)] in SecondOrderCone())\n@objective(model, Min, sum( mean(p[i,:],mop)*c[i] for i in 1:Ng) )\noptimize!(model) # here we go\n@assert termination_status(model) == MOI.OPTIMAL \"Model not solved to optimality.\"\npsol, plsol, obj = value.(p), value.(pl), objective_value(model)\np_moments = [ [mean(psol[i,:],mop) var(psol[i,:],mop) ] for i in 1:Ng ]\npbr_moments = [ [mean(plsol[i,:],mop) var(plsol[i,:],mop) ] for i in 1:Nl ]","category":"page"},{"location":"DCsOPF/#Chance-Constrained-DC-Optimal-Power-Flow","page":"Optimal Power Flow","title":"Chance-Constrained DC Optimal Power Flow","text":"","category":"section"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"The purpose of this tutorial is to show how polynomial chaos can be leveraged to solve optimization problems under uncertainty. Specifically, we study chance-constrained DC optimal power flow as it is presented in this paper.","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"We consider the following 4-bus system that has a total of two generators (buses 1 and 3) and two loads (buses 2 and 4):","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"(Image: 4-bus system)","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"We formalize the numbering of the generators (superscript g), loads (superscript d for demand), and branches (superscript br) as follows","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"mathcalN^g =  1 3  mathcalN^d =  2 4  mathcalN^br =  1 2 3 4 5 ","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"With each generator we associate a linear cost with cost coefficient c_i for all i in mathcalN^g. Each generator must adhere to its engineering limits given by (underlinep_i^g  overlinep_i^g ) for all i in mathcalN^g. Also, each line is constrained by its limits (underlinep_i^br overlinep_i^br) for all i in mathcalN^br.","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"We model the demand at the buses i in mathcalN^d in terms of uniform distributions with known mean mu_i and standard deviation sigma_i. We concisely write","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"mathsfp_i^d sim mathsfU(mu_i sigma_i) quad forall i in mathcalN^d","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"For simplicity we consider DC conditions. Hence, energy balance reads","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"sum_i in mathcalN^g mathsfp_i^g - sum_i in mathcalN^d mathsfp_i^d = 0","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"and the vector of branch flows is computed from the power transfer distribution factor (PTDF) matrix Psi via","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"mathsfp^br = Psi (C^pmathsfp^g + C^dmathsfp^d)","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"The matrices C^p and C^d map the generators and the loads to the correct buses, respectively.","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"We want to solve a chance-constrained optimal power flow problem under DC conditions. According to this paper, we can formulate the problem as undersetmathsfp^goperatornamemin  sum_i in mathcalN_g c_i mathbbE( mathsfp_i^g) subject to","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"sum_i in mathcalN^g mathsfp_i^g - sum_i in mathcalN^d mathsfp_i^d = 0 \nunderlinep_i^g leq mathbbE(mathsfp_i^g) pm lambda_i^g sqrtmathbbV(mathsfp_i^g) leq overlinep_i^g  forall i in mathcalN^g\nunderlinep_i^br leq mathbbE(mathsfp_i^br) pm lambda_i^br sqrtmathbbV(mathsfp_i^br) leq overlinep_i^br forall i in mathcalN^br","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"which minimizes the total expected generation cost subject to the DC power flow equations and chance-constrained engineering limits.","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"Let's solve the problem using PolyChaos and JuMP, using Mosek as a solver.","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"using PolyChaos, JuMP, MosekTools, LinearAlgebra","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"Let's define system-specific quantities such as the incidence matrix and the branch flow parameters. From these we can compute the PTDF matrix Psi (assuming the slack is at bus 1).","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"A = [-1 1 0 0; -1 0 1 0; -1 0 0 1; 0 1 -1 0; 0 0 -1 1] # incidence matrix\nNl, N = size(A, 1), size(A, 2)\nBbr = diagm(0 => -(2 .+ 10 * rand(Nl))) # line parameters\nΨ = [zeros(Nl) -Bbr * A[:, 2:end] * inv(A[:, 2:end]' * Bbr * A[:, 2:end])] # PTDF matrix","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"Now we can continue the remaining ingredients that specify our systems:","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"Cp, Cd = [1 0; 0 0; 0 0; 0 1], [0 0; 1 0; 0 1; 0 0] # book-keeping\nNg, Nd = size(Cp, 2), size(Cd, 2)\nc = 4 .+ 10 * rand(Ng) # cost function parameters\nλp, λl = 1.6 * ones(Ng), 1.6 * ones(Nl) # lambdas for chance constraint reformulations\npmax, pmin = 10 * ones(Ng), zeros(Ng) # engineering limits\nplmax, plmin = 10 * ones(Nl), -10 * ones(Nl) # engineering limits","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"We specify the uncertainty using PolyChaos:","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"deg = 1\nopq = [Uniform01OrthoPoly(deg; Nrec = 5 * deg), Uniform01OrthoPoly(deg; Nrec = 5 * deg)]\nmop = MultiOrthoPoly(opq, deg)\nNpce = mop.dim","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"It remains to specify the PCE coefficients, for which we will use convert2affine.","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"d = zeros(Nd, Npce) # PCE coefficients of load\nd[1, [1, 2]] = convert2affinePCE(1.0, 0.1, mop.uni[1], kind = \"μσ\")\nd[2, [1, 3]] = convert2affinePCE(2.0, 0.2, mop.uni[2], kind = \"μσ\")","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"Now, let's put it all into an optimization problem, specifically a second-order cone program. To build the second-order cone constraints we define a helper function buildSOC.","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"function buildSOC(x::Vector, mop::MultiOrthoPoly)\n    t = [sqrt(Tensor(2, mop).get([i, i])) for i in 0:(mop.dim - 1)]\n    (t .* x)[2:end]\nend","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"Finally, let's use JuMP to formulate and then solve the problem. We use Mosek to solve the problem; for academic use there are free license.","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"model = Model(with_optimizer(Mosek.Optimizer))\n@variable(model, p[i in 1:Ng, j in 1:Npce], base_name=\"p\")\n@constraint(model, energy_balance[j in 1:Npce],\n            sum(p[i, j] for i in 1:Ng) - sum(d[i, j] for i in 1:Nd)==0)\n@constraint(model, con_pmax[i in 1:Ng],\n            [1 / λp[i] * (pmax[i] - mean(p[i, :], mop)); buildSOC(p[i, :], mop)] in SecondOrderCone())\n@constraint(model, con_pmin[i in 1:Ng],\n            [1 / λp[i] * (mean(p[i, :], mop) - pmin[i]); buildSOC(p[i, :], mop)] in SecondOrderCone())\npl = Ψ * (Cp * p + Cd * d)\n@constraint(model, con_plmax[i in 1:Nl],\n            [1 / λl[i] * (plmax[i] - mean(pl[1, :], mop)); buildSOC(pl[i, :], mop)] in SecondOrderCone())\n@constraint(model, con_plmin[i in 1:Nl],\n            [1 / λl[i] * (mean(pl[1, :], mop) - plmin[i]); buildSOC(pl[i, :], mop)] in SecondOrderCone())\n@objective(model, Min, sum(mean(p[i, :], mop) * c[i] for i in 1:Ng))\noptimize!(model) # here we go","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"Let's extract the numerical values of the optimal solution.","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"@assert termination_status(model)==MOI.OPTIMAL \"Model not solved to optimality.\"\npsol, plsol, obj = value.(p), value.(pl), objective_value(model)","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"Great, we've solved the problem. How do we now make sense of the solution? For instance, we can look at the moments of the generated power:","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"p_moments = [[mean(psol[i, :], mop) var(psol[i, :], mop)] for i in 1:Ng]","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"Simiarly, we can study the moments for the branch flows:","category":"page"},{"location":"DCsOPF/","page":"Optimal Power Flow","title":"Optimal Power Flow","text":"pbr_moments = [[mean(plsol[i, :], mop) var(plsol[i, :], mop)] for i in 1:Nl]","category":"page"},{"location":"functions/#Functions","page":"Functions","title":"Functions","text":"","category":"section"},{"location":"functions/","page":"Functions","title":"Functions","text":"note: Note\nThe core interface of all essential functions are not dependent on specialized types such as AbstractOrthoPoly. Having said that, for exactly those essential functions there exist overloaded functions that accept specialized types such as AbstractOrthoPoly as arguments.Too abstract? For example, the function evaluate that evaluates a polynomial of degree n at points x has the core interface    evaluate(n::Int,x::Array{<:Real},a::Vector{<:Real},b::Vector{<:Real})where a and b are the vectors of recurrence coefficients. For simplicity, there also exists the interface    evaluate(n::Int64,x::Vector{<:Real},op::AbstractOrthoPoly)So fret not upon the encounter of multiply-dispatched versions of the same thing. It's there to simplify your life.The idea of this approach is to make it simpler for others to copy and paste code snippets and use them in their own work.","category":"page"},{"location":"functions/","page":"Functions","title":"Functions","text":"List of all functions in PolyChaos.","category":"page"},{"location":"functions/","page":"Functions","title":"Functions","text":"","category":"page"},{"location":"functions/#Recurrence-Coefficients-for-Monic-Orthogonal-Polynomials","page":"Functions","title":"Recurrence Coefficients for Monic Orthogonal Polynomials","text":"","category":"section"},{"location":"functions/","page":"Functions","title":"Functions","text":"The functions below provide analytic expressions for the recurrence coefficients of common orthogonal polynomials. All of these provide monic orthogonal polynomials relative to the weights.","category":"page"},{"location":"functions/","page":"Functions","title":"Functions","text":"note: Note\nThe number N of recurrence coefficients has to be positive for all functions below.","category":"page"},{"location":"functions/","page":"Functions","title":"Functions","text":"r_scale\nrm_compute\nrm_logistic\nrm_hermite\nrm_hermite_prob\nrm_laguerre\nrm_legendre\nrm_legendre01\nrm_jacobi\nrm_jacobi01\nrm_meixner_pollaczek\nstieltjes\nlanczos\nmcdiscretization","category":"page"},{"location":"functions/#PolyChaos.r_scale","page":"Functions","title":"PolyChaos.r_scale","text":"r_scale(c::Real,β::AbstractVector{<:Real},α::AbstractVector{<:Real})\n\nGiven the recursion coefficients (α,β) for a system of orthogonal polynomials that are orthogonal with respect to some positive weight m(t), this function returns the recursion coefficients (α_,β_) for the scaled measure c m(t) for some positive c.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.rm_compute","page":"Functions","title":"PolyChaos.rm_compute","text":"rm_compute(weight::Function,lb::Real,ub::Real,Npoly::Int=4,Nquad::Int=10;quadrature::Function=clenshaw_curtis)\n\nGiven a positive weight function with domain (lb,ub), i.e. a function w lb ub  rightarrow mathbbR_geq 0, this function creates Npoly recursion coefficients (α,β).\n\nThe keyword quadrature specifies what quadrature rule is being used.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.rm_logistic","page":"Functions","title":"PolyChaos.rm_logistic","text":"rm_logistic(N::Int)\n\nCreates N recurrence coefficients for monic polynomials that are orthogonal on (-inftyinfty) relative to w(t) = fracmathrme^-t(1 - mathrme^-t)^2\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.rm_hermite","page":"Functions","title":"PolyChaos.rm_hermite","text":"rm_hermite(N::Int,mu::Real)\nrm_hermite(N::Int)\n\nCreates N recurrence coefficients for monic generalized Hermite polynomials that are orthogonal on (-inftyinfty) relative to w(t) = t^2 mu mathrme^-t^2\n\nThe call rm_hermite(N) is the same as rm_hermite(N,0).\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.rm_hermite_prob","page":"Functions","title":"PolyChaos.rm_hermite_prob","text":"rm_hermite_prob(N::Int)\n\nCreates N recurrence coefficients for monic probabilists' Hermite polynomials that are orthogonal on (-inftyinfty) relative to w(t) = mathrme^-05t^2\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.rm_laguerre","page":"Functions","title":"PolyChaos.rm_laguerre","text":"rm_laguerre(N::Int,a::Real)\nrm_laguerre(N::Int)\n\nCreates N recurrence coefficients for monic generalized Laguerre polynomials that are orthogonal on (0infty) relative to w(t) = t^a mathrme^-t.\n\nThe call rm_laguerre(N) is the same as rm_laguerre(N,0).\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.rm_legendre","page":"Functions","title":"PolyChaos.rm_legendre","text":"rm_legendre(N::Int)\n\nCreates N recurrence coefficients for monic Legendre polynomials that are orthogonal on (-11) relative to w(t) = 1.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.rm_legendre01","page":"Functions","title":"PolyChaos.rm_legendre01","text":"rm_legendre01(N::Int)\n\nCreates N recurrence coefficients for monic Legendre polynomials that are orthogonal on (01) relative to w(t) = 1.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.rm_jacobi","page":"Functions","title":"PolyChaos.rm_jacobi","text":"rm_jacobi(N::Int,a::Real,b::Real)\nrm_jacobi(N::Int,a::Real)\nrm_jacobi(N::Int)\n\nCreates N recurrence coefficients for monic Jacobi polynomials that are orthogonal on (-11) relative to w(t) = (1-t)^a (1+t)^b.\n\nThe call rm_jacobi(N,a) is the same as rm_jacobi(N,a,a) and rm_jacobi(N) the same as rm_jacobi(N,0,0).\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.rm_jacobi01","page":"Functions","title":"PolyChaos.rm_jacobi01","text":"rm_jacobi01(N::Int,a::Real,b::Real)\nrm_jacobi01(N::Int,a::Real)\nrm_jacobi01(N::Int)\n\nCreates N recurrence coefficients for monic Jacobi polynomials that are orthogonal on (01) relative to w(t) = (1-t)^a t^b.\n\nThe call rm_jacobi01(N,a) is the same as rm_jacobi01(N,a,a) and rm_jacobi01(N) the same as rm_jacobi01(N,0,0).\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.rm_meixner_pollaczek","page":"Functions","title":"PolyChaos.rm_meixner_pollaczek","text":"rm_meixner_pollaczek(N::Int,lambda::Real,phi::Real)\nrm_meixner_pollaczek(N::Int,lambda::Real)\n\nCreates N recurrence coefficients for monic Meixner-Pollaczek polynomials with parameters λ and ϕ. These are orthogonal on -inftyinfty relative to the weight function w(t)=(2 pi)^-1 exp(2 phi-pi)t Gamma(lambda+ i t)^2.\n\nThe call rm_meixner_pollaczek(n,lambda) is the same as rm_meixner_pollaczek(n,lambda,pi/2).\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.stieltjes","page":"Functions","title":"PolyChaos.stieltjes","text":"stieltjes(N::Int,nodes_::AbstractVector{<:Real},weights_::AbstractVector{<:Real};removezeroweights::Bool=true)\n\nStieltjes procedure–-Given the nodes and weights the function generates the firstN recurrence coefficients of the corresponding discrete orthogonal polynomials.\n\nSet the Boolean removezeroweights to true if zero weights should be removed.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.lanczos","page":"Functions","title":"PolyChaos.lanczos","text":"lanczos(N::Int,nodes::AbstractVector{<:Real},weights::AbstractVector{<:Real};removezeroweights::Bool=true)\n\nLanczos procedure–-given the nodes and weights the function generates the first N recurrence coefficients of the corresponding discrete orthogonal polynomials.\n\nSet the Boolean removezeroweights to true if zero weights should be removed.\n\nThe script is adapted from the routine RKPW in W.B. Gragg and W.J. Harrod, The numerically stable reconstruction of Jacobi matrices from spectral data, Numer. Math. 44 (1984), 317-335.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.mcdiscretization","page":"Functions","title":"PolyChaos.mcdiscretization","text":"mcdiscretization(N::Int,quads::Vector{},discretemeasure::AbstractMatrix{<:Real}=zeros(0,2);discretization::Function=stieltjes,Nmax::Integer=300,ε::Float64=1e-8,gaussquad::Bool=false)\n\nThis routine returns N recurrence coefficients of the polynomials that are orthogonal relative to a weight function w that is decomposed as a sum of m weights w_i with domains a_ib_i for i=1dotsm,\n\nw(t) = sum_i^m w_i(t) quad textwith  operatornamedom(w_i) = a_i b_i\n\nFor each weight w_i and its domain a_i b_i the function mcdiscretization() expects a quadrature rule of the form nodes::AbstractVector{<:Real}, weights::AbstractVector{<:Real} = myquadi(N::Int) all of which are stacked in the parameter quad quad = [ myquad1, ..., myquadm ] If the weight function has a discrete part (specified by discretemeasure) it is added on to the discretized continuous weight function.\n\nThe function mcdiscretization() performs a sequence of discretizations of the given weight w(t), each discretization being followed by an application of the Stieltjes or Lanczos procedure (keyword discretization in [stieltjes, lanczos]) to produce approximations to the desired recurrence coefficients. The function applies to each subinterval i an N-point quadrature rule (the ith entry of quad) to discretize the weight function w_i on that subinterval. If the procedure converges to within a prescribed accuracy ε before N reaches its maximum allowed value Nmax. If the function does not converge, the function prompts an error message.\n\nThe keyword gaussquad should be set to true if Gauss quadrature rules are available for all m weights w_i(t) with i = 1 dots m.\n\nFor further information, please see W. Gautschi \"Orthogonal Polynomials: Approximation and Computation\", Section 2.2.4.\n\n\n\n\n\n","category":"function"},{"location":"functions/#Show-Orthogonal-Polynomials","page":"Functions","title":"Show Orthogonal Polynomials","text":"","category":"section"},{"location":"functions/","page":"Functions","title":"Functions","text":"To get a human-readable output of the orthognoal polynomials there is the function showpoly","category":"page"},{"location":"functions/","page":"Functions","title":"Functions","text":"showpoly","category":"page"},{"location":"functions/#PolyChaos.showpoly","page":"Functions","title":"PolyChaos.showpoly","text":"showpoly(coeffs::Vector{<:Real};sym::String,digits::Integer)\n\nShow the monic polynomial with coefficients coeffs in a human readable way. They keyword sym sets the name of the variable, and digits controls the number of shown digits.\n\njulia> using PolyChaos\n\njulia> showpoly([1.2, 2.3, 3.4456])\nx^3 + 3.45x^2 + 2.3x + 1.2\n\njulia> showpoly([1.2, 2.3, 3.4456], sym = \"t\", digits = 2)\nt^3 + 3.45t^2 + 2.3t + 1.2\n\nshowpoly(d::Integer,α::Vector{<:Real},β::Vector{<:Real}; sym::String,digits::Integer)\nshowpoly(d::Range,α::Vector{<:Real},β::Vector{<:Real};sym::String,digits::Integer) where Range <: OrdinalRange\n\nShow the monic polynomial of degree/range d that has the recurrence coefficients α, β.\n\njulia> using PolyChaos\n\njulia> α, β = rm_hermite(10)\n([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.77245, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5])\n\njulia> showpoly(3, α, β)\nx^3 - 1.5x\n\njulia> showpoly(0:2:10, α, β)\n1\nx^2 - 0.5\nx^4 - 3.0x^2 + 0.75\nx^6 - 7.5x^4 + 11.25x^2 - 1.88\nx^8 - 14.0x^6 + 52.5x^4 - 52.5x^2 + 6.56\nx^10 - 22.5x^8 + 157.5x^6 - 393.75x^4 + 295.31x^2 - 29.53\n\nTailored to types from PolyChaos.jl\n\nshowpoly(d::Union{Integer,Range},op::AbstractOrthoPoly;sym::String,digits::Integer) where Range <: OrdinalRange\n\nShow the monic polynomial of degree/range d of an AbstractOrthoPoly.\n\njulia> using PolyChaos\n\njulia> op = GaussOrthoPoly(5);\n\njulia> showpoly(3, op)\nx^3 - 3.0x\n\njulia> showpoly(0:(op.deg), op; sym = \"t\")\n1\nt\nt^2 - 1.0\nt^3 - 3.0t\nt^4 - 6.0t^2 + 3.0\nt^5 - 10.0t^3 + 15.0t\n\nThanks @pfitzseb for providing this functionality.\n\n\n\n\n\n","category":"function"},{"location":"functions/","page":"Functions","title":"Functions","text":"In case you want to see the entire basis, just use showbasis","category":"page"},{"location":"functions/","page":"Functions","title":"Functions","text":"showbasis","category":"page"},{"location":"functions/#PolyChaos.showbasis","page":"Functions","title":"PolyChaos.showbasis","text":"showbasis(α::Vector{<:Real},β::Vector{<:Real};sym::String,digits::Integer)\n\nShow all basis polynomials given the recurrence coefficients α, β. They keyword sym sets the name of the variable, and digits controls the number of shown digits.\n\njulia> using PolyChaos\n\njulia> α, β = rm_hermite(5);\n\njulia> showbasis(α, β)\n1\nx\nx^2 - 0.5\nx^3 - 1.5x\nx^4 - 3.0x^2 + 0.75\nx^5 - 5.0x^3 + 3.75x\n\nTailored to types from PolyChaos.jl\n\nshowbasis(op::AbstractOrthoPoly;sym::String,digits::Integer)\n\nShow all basis polynomials of an AbstractOrthoPoly.\n\njulia> using PolyChaos\n\njulia> op = LegendreOrthoPoly(4);\n\njulia> showbasis(op)\n1\nx\nx^2 - 0.33\nx^3 - 0.6x\nx^4 - 0.86x^2 + 0.09\n\n\n\n\n\n","category":"function"},{"location":"functions/","page":"Functions","title":"Functions","text":"Both of these functions make excessive use of","category":"page"},{"location":"functions/","page":"Functions","title":"Functions","text":"rec2coeff","category":"page"},{"location":"functions/#PolyChaos.rec2coeff","page":"Functions","title":"PolyChaos.rec2coeff","text":"rec2coeff(deg::Int,a::Vector{<:Real},b::Vector{<:Real})\nrec2coeff(a,b) = rec2coeff(length(a),a,b)\n\nGet the coefficients of the orthogonal polynomial of degree up to deg specified by its recurrence coefficients (a,b). The function returns the values c_i^(k) from\n\np_k (t) = t^d + sum_i=0^k-1 c_i t^i\n\nwhere k runs from 1 to deg.\n\nThe call rec2coeff(a,b) outputs all possible recurrence coefficients given (a,b).\n\n\n\n\n\n","category":"function"},{"location":"functions/#Evaluate-Orthogonal-Polynomials","page":"Functions","title":"Evaluate Orthogonal Polynomials","text":"","category":"section"},{"location":"functions/","page":"Functions","title":"Functions","text":"evaluate","category":"page"},{"location":"functions/#PolyChaos.evaluate","page":"Functions","title":"PolyChaos.evaluate","text":"Univariate\n\nevaluate(n::Int,x::Array{<:Real},a::AbstractVector{<:Real},b::AbstractVector{<:Real})\nevaluate(n::Int,x::Real,a::AbstractVector{<:Real},b::AbstractVector{<:Real})\nevaluate(n::Int,x::AbstractVector{<:Real},op::AbstractOrthoPoly)\nevaluate(n::Int,x::Real,op::AbstractOrthoPoly)\n\nEvaluate the n-th univariate basis polynomial at point(s) x The function is multiply dispatched to facilitate its use with the composite type AbstractOrthoPoly\n\nIf several basis polynomials (stored in ns) are to be evaluated at points x, then call\n\nevaluate(ns::AbstractVector{<:Int},x::AbstractVector{<:Real},op::AbstractOrthoPoly) = evaluate(ns,x,op.α,op.β)\nevaluate(ns::AbstractVector{<:Int},x::Real,op::AbstractOrthoPoly) = evaluate(ns,[x],op)\n\nIf all basis polynomials are to be evaluated at points x, then call\n\nevaluate(x::AbstractVector{<:Real},op::AbstractOrthoPoly) = evaluate(collect(0:op.deg),x,op)\nevaluate(x::Real,op::AbstractOrthoPoly) = evaluate([x],op)\n\nwhich returns an Array of dimensions (length(x),op.deg+1).\n\nnote: Note\nn is the degree of the univariate basis polynomial\nlength(x) = N, where N is the number of points\n(a,b) are the recursion coefficients\n\nMultivariate\n\nevaluate(n::AbstractVector{<:Int},x::AbstractMatrix{<:Real},a::Vector{<:AbstractVector{<:Real}},b::Vector{<:AbstractVector{<:Real}})\nevaluate(n::AbstractVector{<:Int},x::AbstractVector{<:Real},a::Vector{<:AbstractVector{<:Real}},b::Vector{<:AbstractVector{<:Real}})\nevaluate(n::AbstractVector{<:Int},x::AbstractMatrix{<:Real},op::MultiOrthoPoly)\nevaluate(n::AbstractVector{<:Int},x::AbstractVector{<:Real},op::MultiOrthoPoly)\n\nEvaluate the n-th p-variate basis polynomial at point(s) x The function is multiply dispatched to facilitate its use with the composite type MultiOrthoPoly\n\nIf several basis polynomials are to be evaluated at points x, then call\n\nevaluate(ind::AbstractMatrix{<:Int},x::AbstractMatrix{<:Real},a::Vector{<:AbstractVector{<:Real}},b::Vector{<:AbstractVector{<:Real}})\nevaluate(ind::AbstractMatrix{<:Int},x::AbstractMatrix{<:Real},op::MultiOrthoPoly)\n\nwhere ind is a matrix of multi-indices.\n\nIf all basis polynomials are to be evaluated at points x, then call\n\nevaluate(x::AbstractMatrix{<:Real},mop::MultiOrthoPoly) = evaluate(mop.ind,x,mop)\n\nwhich returns an array of dimensions (mop.dim,size(x,1)).\n\nnote: Note\nn is a multi-index\nlength(n) == p, i.e. a p-variate basis polynomial\nsize(x) = (N,p), where N is the number of points\nsize(a)==size(b)=p.\n\n\n\n\n\n","category":"function"},{"location":"functions/#Scalar-Products","page":"Functions","title":"Scalar Products","text":"","category":"section"},{"location":"functions/","page":"Functions","title":"Functions","text":"computeSP2\ncomputeSP","category":"page"},{"location":"functions/#PolyChaos.computeSP2","page":"Functions","title":"PolyChaos.computeSP2","text":"computeSP2(n::Integer,β::AbstractVector{<:Real})\ncomputeSP2(n::Integer,op::AbstractOrthoPoly) = computeSP2(n,op.β)\ncomputeSP2(op::AbstractOrthoPoly) = computeSP2(op.deg,op.β)\n\nComputes the n regular scalar products aka 2-norms of the orthogonal polynomials, namely\n\nϕ_i^2 = langle phi_iphi_irangle quad forall i in  0dotsn \n\nNotice that only the values of β of the recurrence coefficients (α,β) are required. The computation is based on equation (1.3.7) from Gautschi, W. \"Orthogonal Polynomials: Computation and Approximation\". Whenever there exists an analytic expressions for β, this function should be used.\n\nThe function is multiply dispatched to facilitate its use with AbstractOrthoPoly.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.computeSP","page":"Functions","title":"PolyChaos.computeSP","text":"Univariate\n\ncomputeSP(a::AbstractVector{<:Integer},α::AbstractVector{<:Real},β::AbstractVector{<:Real},nodes::AbstractVector{<:Real},weights::AbstractVector{<:Real};issymmetric::Bool=false)\ncomputeSP(a::AbstractVector{<:Integer},op::AbstractOrthoPoly;issymmetric=issymmetric(op))\n\nMultivariate\n\ncomputeSP( a::AbstractVector{<:Integer},\n           α::AbstractVector{<:AbstractVector{<:Real}},β::AbstractVector{<:AbstractVector{<:Real}},\n           nodes::AbstractVector{<:AbstractVector{<:Real}},weights::AbstractVector{<:AbstractVector{<:Real}},\n           ind::AbstractMatrix{<:Integer};\n           issymmetric::BitArray=falses(length(α)))\ncomputeSP(a::AbstractVector{<:Integer},op::AbstractVector,ind::AbstractMatrix{<:Integer})\ncomputeSP(a::AbstractVector{<:Integer},mOP::MultiOrthoPoly)\n\nComputes the scalar product\n\nlangle phi_a_1phi_a_2cdotsphi_a_n rangle\n\nwhere n = length(a). This requires to provide the recurrence coefficients (α,β) and the quadrature rule (nodes,weights), as well as the multi-index ind. If provided via the keyword issymmetric, symmetry of the weight function is exploited. All computations of the multivariate scalar products resort back to efficient computations of the univariate scalar products. Mathematically, this follows from Fubini's theorem.\n\nThe function is dispatched to facilitate its use with AbstractOrthoPoly and its quadrature rule Quad.\n\nnote: Note\nZero entries of a are removed automatically to simplify computations, which follows fromlangle phi_i phi_j phi_0cdotsphi_0 rangle = langle phi_i phi_j ranglebecause \\phi_0 = 1.It is checked whether enough quadrature points are supplied to solve the integral exactly.\n\n\n\n\n\n","category":"function"},{"location":"functions/#Quadrature-Rules","page":"Functions","title":"Quadrature Rules","text":"","category":"section"},{"location":"functions/","page":"Functions","title":"Functions","text":"fejer\nfejer2\nclenshaw_curtis\nquadgp\ngauss\nradau\nlobatto","category":"page"},{"location":"functions/#PolyChaos.fejer","page":"Functions","title":"PolyChaos.fejer","text":"fejer(N::Int)\n\nFejer's first quadrature rule.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.fejer2","page":"Functions","title":"PolyChaos.fejer2","text":"fejer2(n::Int)\n\nFejer's second quadrature rule according to Waldvogel, J. Bit Numer Math (2006) 46: 195.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.clenshaw_curtis","page":"Functions","title":"PolyChaos.clenshaw_curtis","text":"clenshaw_curtis(n::Int)\n\nClenshaw-Curtis quadrature according to Waldvogel, J. Bit Numer Math (2006) 46: 195.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.quadgp","page":"Functions","title":"PolyChaos.quadgp","text":"quadgp(weight::Function,lb::Real,ub::Real,N::Int=10;quadrature::Function=clenshaw_curtis,bnd::Float64=Inf)\n\ngeneral purpose quadrature based on Gautschi, \"Orthogonal Polynomials: Computation and Approximation\", Section 2.2.2, pp. 93-95\n\nCompute the N-point quadrature rule for weight with support (lb, ub). The quadrature rule can be specified by the keyword quadrature. The keyword bnd sets the numerical value for infinity.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.gauss","page":"Functions","title":"PolyChaos.gauss","text":"gauss(N::Int,α::AbstractVector{<:Real},β::AbstractVector{<:Real})\ngauss(α::AbstractVector{<:Real},β::AbstractVector{<:Real})\ngauss(N::Int,op::Union{OrthoPoly,AbstractCanonicalOrthoPoly})\ngauss(op::Union{OrthoPoly,AbstractCanonicalOrthoPoly})\n\nGauss quadrature rule, also known as Golub-Welsch algorithm\n\ngauss() generates the N Gauss quadrature nodes and weights for a given weight function. The weight function is represented by the N recurrence coefficients for the monic polynomials orthogonal with respect to the weight function.\n\nnote: Note\nThe function gauss accepts at most N = length(α) - 1 quadrature points, hence providing at most an (length(α) - 1)-point quadrature rule.\n\nnote: Note\nIf no N is provided, then N = length(α) - 1.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.radau","page":"Functions","title":"PolyChaos.radau","text":"radau(N::Int,α::AbstractVector{<:Real},β::AbstractVector{<:Real},end0::Real)\nradau(α::AbstractVector{<:Real},β::AbstractVector{<:Real},end0::Real)\nradau(N::Int,op::Union{OrthoPoly,AbstractCanonicalOrthoPoly},end0::Real)\nradau(op::Union{OrthoPoly,AbstractCanonicalOrthoPoly},end0::Real)\n\nGauss-Radau quadrature rule. Given a weight function encoded by the recurrence coefficients (α,β)for the associated orthogonal polynomials, the function generates the nodes and weights (N+1)-point Gauss-Radau quadrature rule for the weight function having a prescribed node end0 (typically at one of the end points of the support interval of w, or outside thereof).\n\nnote: Note\nThe function radau accepts at most N = length(α) - 2 as an input, hence providing at most an (length(α) - 1)-point quadrature rule.\n\nnote: Note\nReference: OPQ: A MATLAB SUITE OF PROGRAMS FOR GENERATING ORTHOGONAL POLYNOMIALS AND RELATED QUADRATURE RULES by Walter Gautschi\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.lobatto","page":"Functions","title":"PolyChaos.lobatto","text":"lobatto(N::Int,α::AbstractVector{<:Real},β::AbstractVector{<:Real},endl::Real,endr::Real)\nlobatto(α::AbstractVector{<:Real},β::AbstractVector{<:Real},endl::Real,endr::Real)\nlobatto(N::Int,op::Union{OrthoPoly,AbstractCanonicalOrthoPoly},endl::Real,endr::Real)\nlobatto(op::Union{OrthoPoly,AbstractCanonicalOrthoPoly},endl::Real,endr::Real)\n\nGauss-Lobatto quadrature rule. Given a weight function encoded by the recurrence coefficients for the associated orthogonal polynomials, the function generates the nodes and weights of the (N+2)-point Gauss-Lobatto quadrature rule for the weight function, having two prescribed nodes endl, endr (typically the left and right end points of the support interval, or points to the left resp. to the right thereof).\n\nnote: Note\nThe function radau accepts at most N = length(α) - 3 as an input, hence providing at most an (length(α) - 1)-point quadrature rule.\n\nnote: Note\nReference: OPQ: A MATLAB SUITE OF PROGRAMS FOR GENERATING ORTHOGONAL POLYNOMIALS AND RELATED QUADRATURE RULES by Walter Gautschi\n\n\n\n\n\n","category":"function"},{"location":"functions/#Polynomial-Chaos","page":"Functions","title":"Polynomial Chaos","text":"","category":"section"},{"location":"functions/","page":"Functions","title":"Functions","text":"mean\nvar\nstd\nsampleMeasure\nevaluatePCE\nsamplePCE\ncalculateAffinePCE\nconvert2affinePCE","category":"page"},{"location":"functions/#Statistics.mean","page":"Functions","title":"Statistics.mean","text":"Univariate\n\nmean(x::AbstractVector,op::AbstractOrthoPoly)\n\nMultivariate\n\nmean(x::AbstractVector,mop::MultiOrthoPoly)\n\ncompute mean of random variable with PCE x\n\n\n\n\n\n","category":"function"},{"location":"functions/#Statistics.var","page":"Functions","title":"Statistics.var","text":"Univariate\n\nvar(x::AbstractVector,op::AbstractOrthoPoly)\nvar(x::AbstractVector,t2::Tensor)\n\nMultivariate\n\nvar(x::AbstractVector,mop::MultiOrthoPoly)\nvar(x::AbstractVector,t2::Tensor)\n\ncompute variance of random variable with PCE x\n\n\n\n\n\n","category":"function"},{"location":"functions/#Statistics.std","page":"Functions","title":"Statistics.std","text":"Univariate\n\nstd(x::AbstractVector,op::AbstractOrthoPoly)\n\nMultivariate\n\nstd(x::AbstractVector,mop::MultiOrthoPoly)\n\ncompute standard deviation of random variable with PCE x\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.sampleMeasure","page":"Functions","title":"PolyChaos.sampleMeasure","text":"Univariate\n\nsampleMeasure(n::Int,name::String,w::Function,dom::Tuple{<:Real,<:Real},symm::Bool,d::Dict;method::String=\"adaptiverejection\")\nsampleMeasure(n::Int,m::Measure;method::String=\"adaptiverejection\")\nsampleMeasure(n::Int,op::AbstractOrthoPoly;method::String=\"adaptiverejection\")\n\nDraw n samples from the measure m described by its\n\nname\nweight function w,\ndomain dom,\nsymmetry property symm,\nand, if applicable, parameters stored in the dictionary d. By default an adaptive rejection sampling method is used (from AdaptiveRejectionSampling.jl), unless it is a common random variable for which Distributions.jl is used.\n\nThe function is dispatched to accept AbstractOrthoPoly.\n\nMultivariate\n\nsampleMeasure(n::Int,m::ProductMeasure;method::Vector{String}=[\"adaptiverejection\" for i=1:length(m.name)])\nsampleMeasure(n::Int,mop::MultiOrthoPoly;method::Vector{String}=[\"adaptiverejection\" for i=1:length(mop.meas.name)])\n\nMultivariate extension which provides array of samples with n rows and as many columns as the multimeasure has univariate measures.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.evaluatePCE","page":"Functions","title":"PolyChaos.evaluatePCE","text":"evaluatePCE(x::AbstractVector{<:Real},ξ::AbstractVector{<:Real},α::AbstractVector{<:Real},β::AbstractVector{<:Real})\n\nEvaluation of polynomial chaos expansion\n\nmathsfx = sum_i=0^L x_i phi_ixi_j\n\nwhere L+1 = length(x) and x_j is the jth sample where j=1dotsm with m = length(ξ).\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.samplePCE","page":"Functions","title":"PolyChaos.samplePCE","text":"Univariate\n\nsamplePCE(n::Int,x::AbstractVector{<:Real},op::AbstractOrthoPoly;method::String=\"adaptiverejection\")\n\nCombines sampleMeasure and evaluatePCE, i.e. it first draws n samples from the measure, then evaluates the PCE for those samples.\n\nMultivariate\n\nsamplePCE(n::Int,x::AbstractVector{<:Real},mop::MultiOrthoPoly;method::Vector{String}=[\"adaptiverejection\" for i=1:length(mop.meas.name)])\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.calculateAffinePCE","page":"Functions","title":"PolyChaos.calculateAffinePCE","text":"calculateAffinePCE(α::AbstractVector{<:Real})\n\nComputes the affine PCE coefficients x_0 and x_1 from recurrence coefficients lpha.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.convert2affinePCE","page":"Functions","title":"PolyChaos.convert2affinePCE","text":"convert2affinePCE(mu::Real, sigma::Real, op::AbstractCanonicalOrthoPoly; kind::String)\n\nComputes the affine PCE coefficients x_0 and x_1 from\n\nX = a_1 + a_2 Xi = x_0 + x_1 phi_1(Xi)\n\nwhere phi_1(t) = t-alpha_0 is the first-order monic basis polynomial.\n\nWorks for subtypes of AbstractCanonicalOrthoPoly. The keyword kind in [\"lbub\", \"μσ\"] specifies whether p1 and p2 have the meaning of lower/upper bounds or mean/standard deviation.\n\n\n\n\n\n","category":"function"},{"location":"functions/#Auxiliary-Functions","page":"Functions","title":"Auxiliary Functions","text":"","category":"section"},{"location":"functions/","page":"Functions","title":"Functions","text":"nw\ncoeffs\nintegrate\nPolyChaos.issymmetric","category":"page"},{"location":"functions/#PolyChaos.nw","page":"Functions","title":"PolyChaos.nw","text":"nw(q::EmptyQuad)\nnw(q::AbstractQuad)\nnw(opq::AbstractOrthoPoly)\nnw(opq::AbstractVector)\nnw(mop::MultiOrthoPoly)\n\nreturns nodes and weights in matrix form\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.coeffs","page":"Functions","title":"PolyChaos.coeffs","text":"coeffs(op::AbstractOrthoPoly)\ncoeffs(op::AbstractVector)\ncoeffs(mop::MultiOrthoPoly)\n\nreturns recurrence coefficients of in matrix form\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.integrate","page":"Functions","title":"PolyChaos.integrate","text":"integrate(f::Function,nodes::AbstractVector{<:Real},weights::AbstractVector{<:Real})\nintegrate(f::Function,q::AbstractQuad)\nintegrate(f::Function,opq::AbstractOrthoPoly)\n\nintegrate function f using quadrature rule specified via nodes, weights. For example int_0^1 6x^5 = 1 can be solved as follows:\n\njulia> opq = Uniform01OrthoPoly(3) # a quadrature rule is added by default\n\njulia> integrate(x -> 6x^5, opq)\n0.9999999999999993\n\nnote: Note\n\n\nfunction f is assumed to return a scalar.\ninterval of integration is \"hidden\" in nodes.\n\n\n\n\n\n","category":"function"},{"location":"functions/#LinearAlgebra.issymmetric","page":"Functions","title":"LinearAlgebra.issymmetric","text":"issymmetric(m::AbstractMeasure)\nissymmetric(op::AbstractOrthoPoly)\n\nIs the measure symmetric (around any point in the domain)?\n\n\n\n\n\n","category":"function"},{"location":"chi_squared_k_greater1/","page":"Chi Squared, Several DOFs","title":"Chi Squared, Several DOFs","text":"k = 12\nusing PolyChaos\ndegree, Nrec = 2, 20\nopq = GaussOrthoPoly(degree; Nrec=Nrec, addQuadrature = true);\nmop = MultiOrthoPoly([opq for i in 1:k], degree)\nL = dim(mop)\nmu, sig = 0., 1.\nx = [ assign2multi(convert2affinePCE(mu, sig, opq),i,mop.ind) for i in 1:k ]\nt2 = Tensor(2,mop)\nt3 = Tensor(3,mop)\ny = [ sum( x[i][j1]*x[i][j2]*t3.get([j1-1,j2-1,m-1])/t2.get([m-1,m-1])  for i=1:k, j1=1:L, j2=1:L ) for m=1:L ]\nmoms_analytic(k) = [k, sqrt(2k), sqrt(8/k)]\nfunction myskew(y)\n   e3 = sum( y[i]*y[j]*y[k]*t3.get([i-1,j-1,k-1]) for i=1:L,j=1:L,k=1:L )\n   μ = y[1]\n   σ = std(y,mop)\n   (e3-3*μ*σ^2-μ^3)/(σ^3)\nend\nprint(\"Expected value:\\t\\t$(moms_analytic(k)[1]) = $(mean(y,mop))\\n\")\nprint(\"\\t\\t\\terror = $(abs(mean(y,mop)-moms_analytic(k)[1]))\\n\")\nprint(\"Standard deviation:\\t$(moms_analytic(k)[2]) = $(std(y,mop))\\n\")\nprint(\"\\t\\t\\terror = $(moms_analytic(k)[2]-std(y,mop))\\n\")\nprint(\"Skewness:\\t\\t$(moms_analytic(k)[3]) = $(myskew(y))\\n\")\nprint(\"\\t\\t\\terror = $(moms_analytic(k)[3]-myskew(y))\\n\")\nusing Plots\nNsmpl = 10000\nysmpl = samplePCE(Nsmpl, y, mop)\nhistogram(ysmpl;normalize=true, xlabel=\"t\",ylabel=\"rho(t)\")\nimport SpecialFunctions: gamma\nρ(t) = 1/(2^(0.5*k)*gamma(0.5*k))*t^(0.5*k-1)*exp(-0.5*t)\nt = range(0.1; stop=maximum(ysmpl), length=100)\nplot!(t,ρ.(t),w=4)","category":"page"},{"location":"chi_squared_k_greater1/#Chi-squared-Distribution-(k1)","page":"Chi Squared, Several DOFs","title":"Chi-squared Distribution (k1)","text":"","category":"section"},{"location":"chi_squared_k_greater1/#Theory","page":"Chi Squared, Several DOFs","title":"Theory","text":"","category":"section"},{"location":"chi_squared_k_greater1/","page":"Chi Squared, Several DOFs","title":"Chi Squared, Several DOFs","text":"Given k standard random variables X_i sim mathcalN(01) for i=1dotsk we would like to find the random variable Y = sum_i=1^k X_i^2. The analytic solution is known: Y follows a chi-squared distribution with k degrees of freedom.","category":"page"},{"location":"chi_squared_k_greater1/","page":"Chi Squared, Several DOFs","title":"Chi Squared, Several DOFs","text":"Using polynomial chaos expansion (PCE), the problem can be solved using Galerkin projection. Let phi_k _k=0^n be the monic orthogonal basis relative to the probability density of X = X_1 dots X_k, namely","category":"page"},{"location":"chi_squared_k_greater1/","page":"Chi Squared, Several DOFs","title":"Chi Squared, Several DOFs","text":"f_X(x) =  prod_i=1^k frac1sqrt2 pi  exp left( - fracx_i^22 right)","category":"page"},{"location":"chi_squared_k_greater1/","page":"Chi Squared, Several DOFs","title":"Chi Squared, Several DOFs","text":"Then, the PCE of X_i is given by","category":"page"},{"location":"chi_squared_k_greater1/","page":"Chi Squared, Several DOFs","title":"Chi Squared, Several DOFs","text":"X_i = sum_k=0^n x_ik phi_k","category":"page"},{"location":"chi_squared_k_greater1/","page":"Chi Squared, Several DOFs","title":"Chi Squared, Several DOFs","text":"with","category":"page"},{"location":"chi_squared_k_greater1/","page":"Chi Squared, Several DOFs","title":"Chi Squared, Several DOFs","text":"x_i0 = 0 quad x_ii+1 = 1 quad x_il = 0 quad forall l in 1dotsn setminus i+1","category":"page"},{"location":"chi_squared_k_greater1/","page":"Chi Squared, Several DOFs","title":"Chi Squared, Several DOFs","text":"To find the PCE coefficients y_k for Y = sum_k=^n y_k phi_k, we apply Galerkin projection, which leads to","category":"page"},{"location":"chi_squared_k_greater1/","page":"Chi Squared, Several DOFs","title":"Chi Squared, Several DOFs","text":"y_m langle phi_m phi_m rangle = sum_i=1^k sum_j_1=0^n sum_j_2=0^n x_ij_1 x_ij_2 langle phi_j_1 phi_j_2 phi_m rangle quad forall m = 0 dots n","category":"page"},{"location":"chi_squared_k_greater1/","page":"Chi Squared, Several DOFs","title":"Chi Squared, Several DOFs","text":"Hence, knowing the scalars langle phi_m phi_m rangle, and langle phi_j_1 phi_j_2 phi_m rangle, the PCE coefficients y_k can be obtained immediately. From the PCE coefficients we can get the moments and compare them to the closed-form expressions.","category":"page"},{"location":"chi_squared_k_greater1/","page":"Chi Squared, Several DOFs","title":"Chi Squared, Several DOFs","text":"Notice: A maximum degree of 2 suffices to get the exact solution with PCE. In other words, increasing the maximum degree to values greater than 2 introduces nothing but computational overhead (and numerical errors, possibly).","category":"page"},{"location":"chi_squared_k_greater1/#Practice","page":"Chi Squared, Several DOFs","title":"Practice","text":"","category":"section"},{"location":"chi_squared_k_greater1/","page":"Chi Squared, Several DOFs","title":"Chi Squared, Several DOFs","text":"First, we create a orthogonal basis relative to f_X(x) of degree at most d=2 (degree below).","category":"page"},{"location":"chi_squared_k_greater1/","page":"Chi Squared, Several DOFs","title":"Chi Squared, Several DOFs","text":"Notice that we consider a total of Nrec recursion coefficients, and that we also add a quadrature rule by setting addQuadrature = true.","category":"page"},{"location":"chi_squared_k_greater1/","page":"Chi Squared, Several DOFs","title":"Chi Squared, Several DOFs","text":"k = 12\nusing PolyChaos\ndegree, Nrec = 2, 20\nopq = GaussOrthoPoly(degree; Nrec = Nrec, addQuadrature = true);","category":"page"},{"location":"chi_squared_k_greater1/","page":"Chi Squared, Several DOFs","title":"Chi Squared, Several DOFs","text":"Now let's define a multivariate basis","category":"page"},{"location":"chi_squared_k_greater1/","page":"Chi Squared, Several DOFs","title":"Chi Squared, Several DOFs","text":"mop = MultiOrthoPoly([opq for i in 1:k], degree)","category":"page"},{"location":"chi_squared_k_greater1/","page":"Chi Squared, Several DOFs","title":"Chi Squared, Several DOFs","text":"Next, we define the PCE for all X_i with i = 1 dots k.","category":"page"},{"location":"chi_squared_k_greater1/","page":"Chi Squared, Several DOFs","title":"Chi Squared, Several DOFs","text":"L = dim(mop)\nmu, sig = 0.0, 1.0\nx = [assign2multi(convert2affinePCE(mu, sig, opq), i, mop.ind) for i in 1:k]","category":"page"},{"location":"chi_squared_k_greater1/","page":"Chi Squared, Several DOFs","title":"Chi Squared, Several DOFs","text":"With the orthogonal basis and the quadrature at hand, we can compute the tensors t2 and t3 that store the entries langle phi_m phi_m rangle, and langle phi_j_1 phi_j_2 phi_m rangle, respectively.","category":"page"},{"location":"chi_squared_k_greater1/","page":"Chi Squared, Several DOFs","title":"Chi Squared, Several DOFs","text":"t2 = Tensor(2, mop)\nt3 = Tensor(3, mop)","category":"page"},{"location":"chi_squared_k_greater1/","page":"Chi Squared, Several DOFs","title":"Chi Squared, Several DOFs","text":"With the tensors at hand, we can compute the Galerkin projection.","category":"page"},{"location":"chi_squared_k_greater1/","page":"Chi Squared, Several DOFs","title":"Chi Squared, Several DOFs","text":"Notice: there are more efficient ways to do this, but let's keep it simple.","category":"page"},{"location":"chi_squared_k_greater1/","page":"Chi Squared, Several DOFs","title":"Chi Squared, Several DOFs","text":"y = [sum(x[i][j1] * x[i][j2] * t3.get([j1 - 1, j2 - 1, m - 1]) / t2.get([m - 1, m - 1])\n         for i in 1:k, j1 in 1:L, j2 in 1:L) for m in 1:L]","category":"page"},{"location":"chi_squared_k_greater1/","page":"Chi Squared, Several DOFs","title":"Chi Squared, Several DOFs","text":"Let's compare the moments via PCE to the closed-form expressions.","category":"page"},{"location":"chi_squared_k_greater1/","page":"Chi Squared, Several DOFs","title":"Chi Squared, Several DOFs","text":"moms_analytic(k) = [k, sqrt(2k), sqrt(8 / k)]\nfunction myskew(y)\n    e3 = sum(y[i] * y[j] * y[k] * t3.get([i - 1, j - 1, k - 1])\n             for i in 1:L, j in 1:L, k in 1:L)\n    μ = y[1]\n    σ = std(y, mop)\n    (e3 - 3 * μ * σ^2 - μ^3) / (σ^3)\nend\n\nprint(\"Expected value:\\t\\t$(moms_analytic(k)[1]) = $(mean(y,mop))\\n\")\nprint(\"\\t\\t\\terror = $(abs(mean(y,mop)-moms_analytic(k)[1]))\\n\")\nprint(\"Standard deviation:\\t$(moms_analytic(k)[2]) = $(std(y,mop))\\n\")\nprint(\"\\t\\t\\terror = $(moms_analytic(k)[2]-std(y,mop))\\n\")\nprint(\"Skewness:\\t\\t$(moms_analytic(k)[3]) = $(myskew(y))\\n\")\nprint(\"\\t\\t\\terror = $(moms_analytic(k)[3]-myskew(y))\\n\")","category":"page"},{"location":"chi_squared_k_greater1/","page":"Chi Squared, Several DOFs","title":"Chi Squared, Several DOFs","text":"Let's plot the probability density function to compare results. We first draw samples from the measure with the help of sampleMeasure(), and then evaluate the basis at these samples and multiply times the PCE coefficients. The latter stop is done using evaluatePCE(). Both steps are combined in the function samplePCE(). Finally, we compare the result agains the analytical PDF rho(t) = fract^t2-1mathrme^-t22^k2  Gamma(k2) of the chi-squared distribution with one degree of freedom.","category":"page"},{"location":"chi_squared_k_greater1/","page":"Chi Squared, Several DOFs","title":"Chi Squared, Several DOFs","text":"using Plots\nNsmpl = 10000\n# long way: ξ = sampleMeasure(Nsmpl,mop), ysmpl = evaluatePCE(y,ξ,mop)\nysmpl = samplePCE(Nsmpl, y, mop)\nhistogram(ysmpl; normalize = true, xlabel = \"t\", ylabel = \"rho(t)\")\n\nimport SpecialFunctions: gamma\nρ(t) = 1 / (2^(0.5 * k) * gamma(0.5 * k)) * t^(0.5 * k - 1) * exp(-0.5 * t)\nt = range(0.1; stop = maximum(ysmpl), length = 100)\nplot!(t, ρ.(t), w = 4)","category":"page"},{"location":"chi_squared_k1/","page":"Chi Squared, One DOF","title":"Chi Squared, One DOF","text":"using PolyChaos\nk = 1\ndeg, Nrec = 2, 20\nopq = GaussOrthoPoly(deg; Nrec=Nrec, addQuadrature=true);\nshowbasis(opq; sym=\"ξ\") # works for `op` too!\nshowpoly(0:2:deg,opq)\nL = dim(opq)\nmu, sig = 0., 1.\nx = [ convert2affinePCE(mu, sig, opq); zeros(Float64,L-2) ]\nt2 = Tensor(2, opq);\nt3 = Tensor(3, opq)\ny = [ sum( x[i]*x[j]*t3.get([i-1,j-1,m-1])/t2.get([m-1,m-1])  for i=1:L, j=1:L ) for m=1:L ]\nmoms_analytic(k) = [k, sqrt(2k), sqrt(8/k)]\nfunction myskew(y)\n   e3 = sum( y[i]*y[j]*y[k]*t3.get([i-1,j-1,k-1]) for i=1:L,j=1:L,k=1:L )\n   μ = y[1]\n   σ = std(y,opq)\n   (e3-3*μ*σ^2-μ^3)/(σ^3)\nend\nprint(\"Expected value:\\t\\t$(moms_analytic(k)[1]) = $(mean(y,opq))\\n\")\nprint(\"\\t\\t\\terror = $(abs(mean(y,opq)-moms_analytic(k)[1]))\\n\")\nprint(\"Standard deviation:\\t$(moms_analytic(k)[2]) = $(std(y,opq))\\n\")\nprint(\"\\t\\t\\terror = $(moms_analytic(k)[2]-std(y,opq))\\n\")\nprint(\"Skewness:\\t\\t$(moms_analytic(k)[3]) = $(myskew(y))\\n\")\nprint(\"\\t\\t\\terror = $(moms_analytic(k)[3]-myskew(y))\\n\")\nusing Plots\nNsmpl = 10000\nysmpl = samplePCE(Nsmpl, y, opq)\nhistogram(ysmpl;normalize=true,xlabel=\"t\",ylabel=\"rho(t)\")\nimport SpecialFunctions: gamma\nρ(t) = 1/(sqrt(2)*gamma(0.5))*1/sqrt(t)*exp(-0.5*t)\nt = range(0.1; stop=maximum(ysmpl), length=100)\nplot!(t, ρ.(t), w=4)","category":"page"},{"location":"chi_squared_k1/#Chi-squared-Distribution-(k1)","page":"Chi Squared, One DOF","title":"Chi-squared Distribution (k=1)","text":"","category":"section"},{"location":"chi_squared_k1/#Theory","page":"Chi Squared, One DOF","title":"Theory","text":"","category":"section"},{"location":"chi_squared_k1/","page":"Chi Squared, One DOF","title":"Chi Squared, One DOF","text":"Given a standard random variable X sim mathcalN(01) we would like to find the random variable Y = X^2. The analytic solution is known: Y follows a chi-squared distribution with k=1 degree of freedom.","category":"page"},{"location":"chi_squared_k1/","page":"Chi Squared, One DOF","title":"Chi Squared, One DOF","text":"Using polynomial chaos expansion (PCE), the problem can be solved using Galerkin projection. Let phi_k _k=0^n be the monic orthogonal basis relative to the probability density of X, namely","category":"page"},{"location":"chi_squared_k1/","page":"Chi Squared, One DOF","title":"Chi Squared, One DOF","text":"f_X(x) = frac1sqrt2 pi exp left( - fracx^22 right)","category":"page"},{"location":"chi_squared_k1/","page":"Chi Squared, One DOF","title":"Chi Squared, One DOF","text":"Then, the PCE of X is given by","category":"page"},{"location":"chi_squared_k1/","page":"Chi Squared, One DOF","title":"Chi Squared, One DOF","text":"X = sum_k=0^n x_k phi_k","category":"page"},{"location":"chi_squared_k1/","page":"Chi Squared, One DOF","title":"Chi Squared, One DOF","text":"with","category":"page"},{"location":"chi_squared_k1/","page":"Chi Squared, One DOF","title":"Chi Squared, One DOF","text":"x_0 = 0 quad x_1 = 1 quad x_i = 0 quad forall i =2dotsn","category":"page"},{"location":"chi_squared_k1/","page":"Chi Squared, One DOF","title":"Chi Squared, One DOF","text":"To find the PCE coefficients y_k for Y = sum_k=^n y_k phi_k, we apply Galerkin projection, which leads to","category":"page"},{"location":"chi_squared_k1/","page":"Chi Squared, One DOF","title":"Chi Squared, One DOF","text":"y_m langle phi_m phi_m rangle = sum_i=0^n sum_j=0^n x_i x_j langle phi_i phi_j phi_m rangle quad forall m = 0 dots n","category":"page"},{"location":"chi_squared_k1/","page":"Chi Squared, One DOF","title":"Chi Squared, One DOF","text":"Hence, knowing the scalars langle phi_m phi_m rangle, and langle phi_i phi_j phi_m rangle, the PCE coefficients y_k can be obtained immediately. From the PCE coefficients we can get the moments and compare them to the closed-form expressions.","category":"page"},{"location":"chi_squared_k1/","page":"Chi Squared, One DOF","title":"Chi Squared, One DOF","text":"Notice: A maximum degree of 2 suffices to get the exact solution with PCE. In other words, increasing the maximum degree to values greater than 2 introduces nothing but computational overhead (and numerical errors, possibly).","category":"page"},{"location":"chi_squared_k1/#Practice","page":"Chi Squared, One DOF","title":"Practice","text":"","category":"section"},{"location":"chi_squared_k1/","page":"Chi Squared, One DOF","title":"Chi Squared, One DOF","text":"First, we create a orthogonal basis relative to f_X(x) of degree at most d=2 (deg below).","category":"page"},{"location":"chi_squared_k1/","page":"Chi Squared, One DOF","title":"Chi Squared, One DOF","text":"Notice that we consider a total of Nrec recursion coefficients, and that we also add a quadrature rule by setting addQuadrature = true.","category":"page"},{"location":"chi_squared_k1/","page":"Chi Squared, One DOF","title":"Chi Squared, One DOF","text":"using PolyChaos\nk = 1\ndeg, Nrec = 2, 20\nopq = GaussOrthoPoly(deg; Nrec = Nrec, addQuadrature = true);","category":"page"},{"location":"chi_squared_k1/","page":"Chi Squared, One DOF","title":"Chi Squared, One DOF","text":"What are the basis polynomials?","category":"page"},{"location":"chi_squared_k1/","page":"Chi Squared, One DOF","title":"Chi Squared, One DOF","text":"showbasis(opq; sym = \"ξ\")","category":"page"},{"location":"chi_squared_k1/","page":"Chi Squared, One DOF","title":"Chi Squared, One DOF","text":"Note that the command showbasis is based on the more general showpoly:","category":"page"},{"location":"chi_squared_k1/","page":"Chi Squared, One DOF","title":"Chi Squared, One DOF","text":"showpoly(0:2:deg, opq)","category":"page"},{"location":"chi_squared_k1/","page":"Chi Squared, One DOF","title":"Chi Squared, One DOF","text":"Next, we define the PCE for X.","category":"page"},{"location":"chi_squared_k1/","page":"Chi Squared, One DOF","title":"Chi Squared, One DOF","text":"L = dim(opq)\nmu, sig = 0.0, 1.0\nx = [convert2affinePCE(mu, sig, opq); zeros(Float64, L - 2)]","category":"page"},{"location":"chi_squared_k1/","page":"Chi Squared, One DOF","title":"Chi Squared, One DOF","text":"With the orthogonal basis and the quadrature at hand, we can compute the tensors t2 and t3 that store the entries langle phi_m phi_m rangle, and langle phi_i phi_j phi_m rangle, respectively.","category":"page"},{"location":"chi_squared_k1/","page":"Chi Squared, One DOF","title":"Chi Squared, One DOF","text":"t2 = Tensor(2, opq);\nt3 = Tensor(3, opq)","category":"page"},{"location":"chi_squared_k1/","page":"Chi Squared, One DOF","title":"Chi Squared, One DOF","text":"With the tensors at hand, we can compute the Galerkin projection.","category":"page"},{"location":"chi_squared_k1/","page":"Chi Squared, One DOF","title":"Chi Squared, One DOF","text":"y = [sum(x[i] * x[j] * t3.get([i - 1, j - 1, m - 1]) / t2.get([m - 1, m - 1])\n         for i in 1:L, j in 1:L) for m in 1:L]","category":"page"},{"location":"chi_squared_k1/","page":"Chi Squared, One DOF","title":"Chi Squared, One DOF","text":"Let's compare the moments via PCE to the closed-form expressions.","category":"page"},{"location":"chi_squared_k1/","page":"Chi Squared, One DOF","title":"Chi Squared, One DOF","text":"moms_analytic(k) = [k, sqrt(2k), sqrt(8 / k)]\nfunction myskew(y)\n    e3 = sum(y[i] * y[j] * y[k] * t3.get([i - 1, j - 1, k - 1])\n             for i in 1:L, j in 1:L, k in 1:L)\n    μ = y[1]\n    σ = std(y, opq)\n    (e3 - 3 * μ * σ^2 - μ^3) / (σ^3)\nend\n\nprint(\"Expected value:\\t\\t$(moms_analytic(k)[1]) = $(mean(y,opq))\\n\")\nprint(\"\\t\\t\\terror = $(abs(mean(y,opq)-moms_analytic(k)[1]))\\n\")\nprint(\"Standard deviation:\\t$(moms_analytic(k)[2]) = $(std(y,opq))\\n\")\nprint(\"\\t\\t\\terror = $(moms_analytic(k)[2]-std(y,opq))\\n\")\nprint(\"Skewness:\\t\\t$(moms_analytic(k)[3]) = $(myskew(y))\\n\")\nprint(\"\\t\\t\\terror = $(moms_analytic(k)[3]-myskew(y))\\n\")","category":"page"},{"location":"chi_squared_k1/","page":"Chi Squared, One DOF","title":"Chi Squared, One DOF","text":"Let's plot the probability density function to compare results. We first draw samples from the measure with the help of sampleMeasure(), and then evaluate the basis at these samples and multiply times the PCE coefficients. The latter stop is done using evaluatePCE(). Finally, we compare the result agains the analytical PDF rho(t) = fracmathrme^-05tsqrt2 t  Gamma(05) of the chi-squared distribution with one degree of freedom.","category":"page"},{"location":"chi_squared_k1/","page":"Chi Squared, One DOF","title":"Chi Squared, One DOF","text":"using Plots\nNsmpl = 10000\n# long way: ξ = sampleMeasure(Nsmpl,opq), ysmpl = evaluatePCE(y,ξ,opq)\nysmpl = samplePCE(Nsmpl, y, opq)\nhistogram(ysmpl; normalize = true, xlabel = \"t\", ylabel = \"rho(t)\")\n\nimport SpecialFunctions: gamma\nρ(t) = 1 / (sqrt(2) * gamma(0.5)) * 1 / sqrt(t) * exp(-0.5 * t)\nt = range(0.1; stop = maximum(ysmpl), length = 100)\nplot!(t, ρ.(t), w = 4)","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"using PolyChaos, LinearAlgebra\ndeg, n = 4, 20\ns_α, s_β = 2.1, 3.2\nopq = Beta01OrthoPoly(deg, s_α, s_β; Nrec=n, addQuadrature=true)\nnormsq = computeSP2(opq)\nm = 3\nt = Tensor(3,opq)\nt.get([1,2,3])\nT = [ t.get([i1,i2,i3]) for i1=0:dim(opq)-1, i2=0:dim(opq)-1, i3=0:dim(opq)-1]\n#@show normsq == diag(T[:,:,1])\n#@show normsq == diag(T[:,1,:])\n#@show normsq == diag(T[1,:,:])\nt2 = Tensor(2, opq)\n@show normsq == [ t2.get([i, i]) for i in 0:dim(opq)-1]\nusing SpecialFunctions\nsupp = (0, 1)\nw(t) = (t^(s_α-1)*(1-t)^(s_β-1)/SpecialFunctions.beta(s_α,s_β))\nmy_meas = Measure(\"my_meas\", w, supp, false)\nmy_opq = OrthoPoly(\"my_op\", deg, my_meas; Nrec=n, addQuadrature = true)\nmy_normsq = computeSP2(my_opq)\nmy_t = Tensor(m, my_opq)\nmy_T = [ my_t.get([i1,i2,i3]) for i1=0:dim(opq)-1,i2=0:dim(opq)-1,i3=0:dim(opq)-1]\n@show abs.(normsq-my_normsq)\n@show norm(T-my_T)\nmop = MultiOrthoPoly([opq, my_opq], deg)\nmt2 = Tensor(2,mop)\nmt3 = Tensor(3,mop)\nmT2 = [ mt2.get([i,i]) for i=0:dim(mop)-1 ]\nmop.ind\nind_opq = findUnivariateIndices(1,mop.ind)\nind_my_opq = findUnivariateIndices(2,mop.ind)\n@show mT2[ind_opq] - normsq\n@show mT2[ind_my_opq] - my_normsq;","category":"page"},{"location":"scalar_products/#ComputationOfScalarProducts","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"","category":"section"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"By now, we are able to construct orthogonal polynomials, and to construct quadrature rules for a given nonnegative weight function, respectively. Now we combine both ideas to solve integrals involving the orthogonal polynomials","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"langle phi_i_1 phi_i_2 cdots phi_i_m-1 phi_i_m rangle\n= int phi_i_1(t) phi_i_2(t) cdots phi_i_m-1(t) phi_i_m(t) w(t) mathrmd t","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"both for the univariate and multivariate case. The integrand is a polynomial (possibly multivariate) that can be solved exactly with the appropriate Gauss quadrature rules.","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"note: Note\nTo simplify notation we drop the integration interval. It is clear from the context.","category":"page"},{"location":"scalar_products/#Univariate-Polynomials","page":"Computation of Scalar Products","title":"Univariate Polynomials","text":"","category":"section"},{"location":"scalar_products/#Classical-Polynomials","page":"Computation of Scalar Products","title":"Classical Polynomials","text":"","category":"section"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"Let's begin with a univariate basis for some classical orthogonal polynomial","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"using PolyChaos\ndeg, n = 4, 20\ns_α, s_β = 2.1, 3.2\nopq = Beta01OrthoPoly(deg, s_α, s_β; Nrec = n, addQuadrature = true)","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"By setting addQuadrature = true (which is default), an n-point Gauss quadrature rule is create relative to the underlying measure opq.measure, where n is the number of recurrence coefficients stored in opq.α and opq.β.","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"To compute the squared norms","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":" phi_k ^2 = langle phi_k phi_k  rangle\n= int phi_k(t) phi_k(t) w(t) mathrmd t","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"of the basis we call computeSP2()","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"normsq = computeSP2(opq)","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"For the general case","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"langle phi_i_1 phi_i_2 cdots phi_i_m-1 phi_i_m rangle\n= int phi_i_1(t) phi_i_2(t) cdots phi_i_m-1(t) phi_i_m(t) w(t) mathrmd t","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"there exists a type Tensor that requires only two arguments: the dimension m geq 1, and an AbstractOrthoPoly","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"m = 3\nt = Tensor(3, opq)","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"To get the desired entries, Tensor comes with a get() function that is called for some index a in mathbbN_0^m that has the entries a = i_1 i_2 dots i_m. For example","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"t.get([1, 2, 3])","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"Or using comprehension","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"T = [t.get([i1, i2, i3])\n     for i1 in 0:(dim(opq) - 1), i2 in 0:(dim(opq) - 1), i3 in 0:(dim(opq) - 1)]","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"Notice that we can cross-check the results.","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"using LinearAlgebra\nnormsq == diag(T[:, :, 1]) == diag(T[:, 1, :]) == diag(T[1, :, :])","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"Also, normsq can be computed analogously in Tensor format","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"t2 = Tensor(2, opq)\nnormsq == [t2.get([i, i]) for i in 0:(dim(opq) - 1)]","category":"page"},{"location":"scalar_products/#Arbitrary-Weights","page":"Computation of Scalar Products","title":"Arbitrary Weights","text":"","category":"section"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"Of course, the type OrthoPoly can be constructed for arbitrary weights w(t). In this case we have to compute the orthogonal basis and the respective quadrature rule. Let's re-work the above example by hand.","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"using SpecialFunctions\nsupp = (0, 1)\nw(t) = (t^(s_α - 1) * (1 - t)^(s_β - 1) / SpecialFunctions.beta(s_α, s_β))\nmy_meas = Measure(\"my_meas\", w, supp, false)\nmy_opq = OrthoPoly(\"my_op\", deg, my_meas; Nrec = n, addQuadrature = true)","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"Now we can compute the squared norms  phi_k ^2","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"my_normsq = computeSP2(my_opq)","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"And the tensor","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"my_t = Tensor(m, my_opq)\nmy_T = [my_t.get([i1, i2, i3])\n        for i1 in 0:(dim(opq) - 1), i2 in 0:(dim(opq) - 1), i3 in 0:(dim(opq) - 1)]","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"Let's compare the results:","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"abs.(normsq - my_normsq)","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"norm(T - my_T)","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"note: Note\nThe possibility to create quadrature rules for arbitrary weights should be reserved to cases different from classical ones.","category":"page"},{"location":"scalar_products/#Multivariate-Polynomials","page":"Computation of Scalar Products","title":"Multivariate Polynomials","text":"","category":"section"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"For multivariate polynomials the syntax for Tensor is very much alike, except that we are dealing with the type MultiOrthoPoly now.","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"mop = MultiOrthoPoly([opq, my_opq], deg)","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"mt2 = Tensor(2, mop)\nmt3 = Tensor(3, mop)\nmT2 = [mt2.get([i, i]) for i in 0:(dim(mop) - 1)]","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"Notice that mT2 carries the elements of the 2-dimensional tensors for the univariate bases opq and my_opq. The encoding is given by the multi-index mop.ind","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"mop.ind","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"To cross-check the results we can distribute the multi-index back to its univariate indices with the help of findUnivariateIndices.","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"ind_opq = findUnivariateIndices(1, mop.ind)\nind_my_opq = findUnivariateIndices(2, mop.ind)","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"mT2[ind_opq] - normsq","category":"page"},{"location":"scalar_products/","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"mT2[ind_my_opq] - my_normsq","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"using PolyChaos, DifferentialEquations\nx0 = 2.0\nμ, σ = -0.5, 0.05\ntend, Δt = 3.0, 0.01\nusing PolyChaos\nL, Nrec = 6, 40\nopq = GaussOrthoPoly(L; Nrec=Nrec, addQuadrature=true)\nusing DifferentialEquations\n\na = [ convert2affinePCE(μ, σ, opq); zeros(Float64,L-1) ] # PCE coefficients of a\nxinit = [ x0; zeros(Float64,L) ] # PCE coefficients of initial condition\n\nt2 = Tensor(2, opq); # \\langle \\phi_i, \\phi_j \\rangle\nt3 = Tensor(3, opq); # \\langle \\phi_i \\phi_j, \\phi_k \\rangle\n\n# Galerkin-projected random differential equation\nfunction ODEgalerkin(du,u,p,t)\n   du[:] = [ sum( p[j+1]*u[k+1]*t3.get([j,k,m])/t2.get([m,m]) for j=0:L for k=0:L) for m=0:L ]\nend\n\nprobgalerkin = ODEProblem(ODEgalerkin,xinit,(0,tend),a)\nsolgalerkin = solve(probgalerkin;saveat=0:Δt:tend)\nt, x = solgalerkin.t, solgalerkin.u;\n# an advantage of PCE is that moments can be computed from the PCE coefficients alone; no sampling required\nmean_pce = [ mean(x_, opq) for x_ in x]  \nstd_pce = [ std(x_, opq) for x_ in x]\nusing Statistics\nNsmpl = 5000\nξ = sampleMeasure(Nsmpl,opq)     # sample from Gaussian measure; effectively randn() here    \nasmpl = evaluatePCE(a,ξ,opq)     # sample random variable with PCE coefficients a; effectively μ + σ*randn() here\n# or: asmpl = samplePCE(Nsmpl,a,opq)\nxmc = [ solve(ODEProblem((u,p,t)->aa*u,x0,(0,tend));saveat=0:Δt:tend).u for aa in asmpl]\nxmc = hcat(xmc...);\n[ mean(xmc,dims=2)-mean_pce std(xmc,dims=2)-std_pce]\nlogx_pce = [ log.(evaluatePCE(x[i],ξ,opq)) for i=1:length(t)]\n[mean.(logx_pce)-(log(x0) .+ μ*t) std.(logx_pce)-σ*t ]","category":"page"},{"location":"random_ode/#Galerkin-based-Solution-of-Random-Differential-Equation","page":"Random ODE","title":"Galerkin-based Solution of Random Differential Equation","text":"","category":"section"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"This tutorial demonstrates how random differential equations can be solved using polynomial chaos expansions (PCE).","category":"page"},{"location":"random_ode/#Theory","page":"Random ODE","title":"Theory","text":"","category":"section"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"A random differential equation is an ordinary differential equation that has random parameters, hence its solution is itself a (time-varying) random variable. Perhaps the simplest non-trivial example is the following scalar, linear ordinary differential equation","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"dotx(t) = a x(t) quad x(0) = x_0","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"where a is the realization of a Gaussian random variable mathsfa sim mathcalN(mu sigma^2) with mean mu and variance sigma^2. Arguably, for every realization a we can solve the differential equation and obtain","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"x(t) = x_0 mathrme^a t","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"from which we find that","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"ln (x(t)) = ln (x_0) + at sim mathcalN(ln(x_0) + mu t (sigma t)^2)","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"In other words, the logarithm of the solution is normally distributed (so-called log-normal distribution).","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"We'd like to obtain this result numerically with the help of PCE. The first step is to define the (truncated) PCE for the random variable mathsfa","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"mathsfa = sum_i=0^L a_i phi_i","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"where a_i are the so-called PCE coefficients, and phi_i are the orthogonal basis polynomials. As the solution to the random differential equation is itself a random variable, we treat x(t) as the realization of the random variable mathsfx(t), and define its PCE","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"mathsfx(t) = sum_i=0^L x_i(t) phi_i","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"The question is how to obtain the unknown PCE coefficients x_i(t) from the known PCE coefficients a_i relative to the orthogonal basis polynomials phi_i. This can be done using Galerkin projection, which is nothing else than projecting onto the orthogonal basis. Think of a three-dimensional space, in which you have placed some three-dimensional object. If you know project the silhouett of the object onto every axis of the three-dimensional space, then you are doing a Galerkin projection. With PCE the concept is equivalent, but the imagination has a harder time. The first step for Galerkin projection is to insert the PCEs","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"sum_i=0^L dotx_i(t) phi_i = sum_j=0^L a_j phi_j sum_k=0^L x_k(t) phi_k","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"the second step is to project onto every basis polynomial phi_m for m = 0 1 dots L, and to exploit orthogonality of the basis. This gives","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"dotx_m(t) langle phi_m phi_m rangle = sum_j=0^L sum_k=0^L a_j x_k(t) langle phi_l phi_k phi_m rangle quad m = 0 1 dots L","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"Of course, the initial condition must not be forgotten:","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"x_0(0) = x_0 quad x_m(0) = 0 quad m = 1 dots L","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"If we can solve this enlarged system of ordinary random differential equations, we can reconstruct the analytic solution.","category":"page"},{"location":"random_ode/#Practice","page":"Random ODE","title":"Practice","text":"","category":"section"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"We begin by defining the random differential equation","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"x0 = 2.0\nμ, σ = -0.5, 0.05\ntend, Δt = 3.0, 0.01","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"Next, we define an orthogonal basis (and its quadrature rule) relative to the Gaussian measure using PolyChaos. We choose a maximum degree of L.","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"using PolyChaos\nL, Nrec = 6, 40\nopq = GaussOrthoPoly(L; Nrec = Nrec, addQuadrature = true)","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"Now we can define the PCE for mathsfa and solve the Galerkin-projected ordinary differential equation using DifferentialEquations.jl.","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"using DifferentialEquations\n\na = [convert2affinePCE(μ, σ, opq); zeros(Float64, L - 1)] # PCE coefficients of a\nxinit = [x0; zeros(Float64, L)] # PCE coefficients of initial condition\n\nt2 = Tensor(2, opq); # \\langle \\phi_i, \\phi_j \\rangle\nt3 = Tensor(3, opq); # \\langle \\phi_i \\phi_j, \\phi_k \\rangle\n\n# Galerkin-projected random differential equation\nfunction ODEgalerkin(du, u, p, t)\n    du[:] = [sum(p[j + 1] * u[k + 1] * t3.get([j, k, m]) / t2.get([m, m]) for j in 0:L\n                 for k in 0:L) for m in 0:L]\nend\n\nprobgalerkin = ODEProblem(ODEgalerkin, xinit, (0, tend), a)\nsolgalerkin = solve(probgalerkin; saveat = 0:Δt:tend)\nt, x = solgalerkin.t, solgalerkin.u;","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"For later purposes we compute the expected value and the standard deviation at all time instants using PCE.","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"# an advantage of PCE is that moments can be computed from the PCE coefficients alone; no sampling required\nmean_pce = [mean(x_, opq) for x_ in x]\nstd_pce = [std(x_, opq) for x_ in x]","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"We compare the solution from PCE to a Monte-Carlo-based solution. That means to solve the ordinary differential equation for many samples of mathsfa. We first sample from the measure using sampleMeasure, and then generate samples of mathsfa using evaluatePCE. After that we solve the ODE and store the results in xmc.","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"using Statistics\nNsmpl = 5000\nξ = sampleMeasure(Nsmpl, opq)     # sample from Gaussian measure; effectively randn() here    \nasmpl = evaluatePCE(a, ξ, opq)     # sample random variable with PCE coefficients a; effectively μ + σ*randn() here\n# or: asmpl = samplePCE(Nsmpl,a,opq)\nxmc = [solve(ODEProblem((u, p, t) -> aa * u, x0, (0, tend)); saveat = 0:Δt:tend).u\n       for aa in asmpl]\nxmc = hcat(xmc...);","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"Now we can compare the Monte Carlo mean and standard deviation to the expression from PCE for every time instant.","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"[mean(xmc, dims = 2) - mean_pce std(xmc, dims = 2) - std_pce]","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"Clearly, the accuracy of PCE deteriorates over time. Possible remedies are to increase the dimension of PCE, and to tweak the tolerances of the integrator.","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"Finally, we compare whether the samples follow a log-normal distribution, and compare the result to the analytic mean and standard deviation.","category":"page"},{"location":"random_ode/","page":"Random ODE","title":"Random ODE","text":"logx_pce = [log.(evaluatePCE(x_, ξ, opq)) for x_ in x]\n[mean.(logx_pce) - (log(x0) .+ μ * t) std.(logx_pce) - σ * t]","category":"page"},{"location":"gaussian_mixture_model/","page":"Gaussian Mixture Models","title":"Gaussian Mixture Models","text":"using Plots\nfunction f(x,μ,σ)\n    1/sqrt(2 *π*σ^2) * exp(-(x - μ)^2 / (2σ^2))\nend\nμ, σ = [1., 1.7], [0.2, 0.3]\nρ(x) = 0.5*f(x,μ[1],σ[1]) + 0.5*f(x,μ[2],σ[2])\nx = 0:0.01:3\nplot(x,ρ.(x))\nxlabel!(\"x\")\nylabel!(\"rho(x)\")\nusing PolyChaos\ndeg = 4\nmeas = Measure(\"my_GaussMixture\", ρ, (-Inf,Inf), false, Dict(:μ=>μ, :σ=>σ)) # build measure\nop = OrthoPoly(\"my_op\", deg, meas; Nquad = 100,Nrec = 2*deg) # construct orthogonal polynomial\nshowbasis(op, digits=2) # in case you wondered\nT2 = Tensor(2,op) # compute scalar products\nT2num_1 = [ T2.get([i,j]) for i in 0:deg, j in 0:deg]\nusing QuadGK\nT2num_2 = [quadgk(x -> evaluate(i,x,op)*evaluate(j,x,op)*ρ(x),-Inf,Inf)[1] for i in 0:deg, j in 0:deg ]\nT2num_1 - T2num_2","category":"page"},{"location":"gaussian_mixture_model/#Gaussian-Mixture-Models","page":"Gaussian Mixture Models","title":"Gaussian Mixture Models","text":"","category":"section"},{"location":"gaussian_mixture_model/","page":"Gaussian Mixture Models","title":"Gaussian Mixture Models","text":"Gaussian mixture models are popular for clustering data. Generally speaking, they are continuous random variables with a special probability density, namely","category":"page"},{"location":"gaussian_mixture_model/","page":"Gaussian Mixture Models","title":"Gaussian Mixture Models","text":"rho(x) = sum_i = 1^n fracw_isqrt2 pi sigma_i^2 exp left( frac(x - mu_i)^22 sigma_i^2 right) quad textwith quad sum_i = 1^n w_i = 1","category":"page"},{"location":"gaussian_mixture_model/","page":"Gaussian Mixture Models","title":"Gaussian Mixture Models","text":"where the pairs of means and standard deviations (mu_i sigma_i), and the weights w_i for all i in  1 dots n  are given. Let's consider a simple example.","category":"page"},{"location":"gaussian_mixture_model/","page":"Gaussian Mixture Models","title":"Gaussian Mixture Models","text":"using Plots\nf(x, μ, σ) = 1 / sqrt(2 * π * σ^2) * exp(-(x - μ)^2 / (2σ^2))\nμs, σs, ws = [1.0, 1.7], [0.2, 0.3], [0.5, 0.5]\nρ(x) = sum(w * f(x, μ, σ) for (μ, σ, w) in zip(μs, σs, ws))\nx = 0:0.01:3;\nplot(x, ρ.(x))\nxlabel!(\"x\");\nylabel!(\"rho(x)\");","category":"page"},{"location":"gaussian_mixture_model/","page":"Gaussian Mixture Models","title":"Gaussian Mixture Models","text":"This looks nice!","category":"page"},{"location":"gaussian_mixture_model/","page":"Gaussian Mixture Models","title":"Gaussian Mixture Models","text":"What are now the polynomials that are orthogonal relative to this specific density?","category":"page"},{"location":"gaussian_mixture_model/","page":"Gaussian Mixture Models","title":"Gaussian Mixture Models","text":"using PolyChaos\ndeg = 4\nmeas = Measure(\"my_GaussMixture\", ρ, (-Inf, Inf), false, Dict(:μ => μ, :σ => σ)) # build measure\nop = OrthoPoly(\"my_op\", deg, meas; Nquad = 100, Nrec = 2 * deg) # construct orthogonal polynomial\nshowbasis(op, digits = 2) # in case you wondered","category":"page"},{"location":"gaussian_mixture_model/","page":"Gaussian Mixture Models","title":"Gaussian Mixture Models","text":"Let's add the quadrature rule and compute the square norms of the basis polynomials.","category":"page"},{"location":"gaussian_mixture_model/","page":"Gaussian Mixture Models","title":"Gaussian Mixture Models","text":"T2 = Tensor(2, op) # compute scalar products\n[T2.get([i, j]) for i in 0:deg, j in 0:deg]","category":"page"},{"location":"gaussian_mixture_model/","page":"Gaussian Mixture Models","title":"Gaussian Mixture Models","text":"Great!","category":"page"},{"location":"numerical_integration/#NumericalIntegration","page":"Numerical Integration","title":"Numerical Integration","text":"","category":"section"},{"location":"numerical_integration/","page":"Numerical Integration","title":"Numerical Integration","text":"The goal of this tutorial is to solve an integral using Gauss quadrature,","category":"page"},{"location":"numerical_integration/","page":"Numerical Integration","title":"Numerical Integration","text":"I = int_0^1 f(t) mathrmd t approx sum_k=1^n w_k f(t_k)","category":"page"},{"location":"numerical_integration/","page":"Numerical Integration","title":"Numerical Integration","text":"where we choose f(t) = sin(t), and n = 5.","category":"page"},{"location":"numerical_integration/","page":"Numerical Integration","title":"Numerical Integration","text":"Make sure to check out this tutorial too.","category":"page"},{"location":"numerical_integration/#Variant-0","page":"Numerical Integration","title":"Variant 0","text":"","category":"section"},{"location":"numerical_integration/","page":"Numerical Integration","title":"Numerical Integration","text":"julia> using PolyChaos\n\njulia> n = 5;\n\njulia> f(t) = sin(t);\n\njulia> op = Uniform01OrthoPoly(n, addQuadrature = true);\n\njulia> variant0 = integrate(f, op)\n0.4596976941320484\n\njulia> print(\"Numerical error: $(abs(1 - cos(1) - variant0))\")\nNumerical error: 1.8868240303504535e-13","category":"page"},{"location":"numerical_integration/","page":"Numerical Integration","title":"Numerical Integration","text":"with negligible numerical errors.","category":"page"},{"location":"numerical_integration/#Variant-1","page":"Numerical Integration","title":"Variant 1","text":"","category":"section"},{"location":"numerical_integration/","page":"Numerical Integration","title":"Numerical Integration","text":"Let us  now solve the same problem, while elaborating what is going on under the hood. At first, we load the package by calling","category":"page"},{"location":"numerical_integration/","page":"Numerical Integration","title":"Numerical Integration","text":"using PolyChaos","category":"page"},{"location":"numerical_integration/","page":"Numerical Integration","title":"Numerical Integration","text":"Now we define a measure, specifically the uniform measure mathrmdlambda(t) = w(t) mathrmd t with the weight w defined as","category":"page"},{"location":"numerical_integration/","page":"Numerical Integration","title":"Numerical Integration","text":"  w mathcalW = 01 rightarrow mathbbR quad w(t) = 1","category":"page"},{"location":"numerical_integration/","page":"Numerical Integration","title":"Numerical Integration","text":"This measure can be defined using the composite type Uniform01Measure:","category":"page"},{"location":"numerical_integration/","page":"Numerical Integration","title":"Numerical Integration","text":"julia> measure = Uniform01Measure()\nUniform01Measure(PolyChaos.w_uniform01, (0.0, 1.0), true)","category":"page"},{"location":"numerical_integration/","page":"Numerical Integration","title":"Numerical Integration","text":"Next, we need to compute the quadrature rule relative to the uniform measure. To do this we use the composite type Quad.","category":"page"},{"location":"numerical_integration/","page":"Numerical Integration","title":"Numerical Integration","text":"julia> quadRule1 = Quad(n - 1, measure)\n┌ Warning: For measures of type Uniform01Measure the quadrature rule should be based on the recurrence coefficients.\n└ @ PolyChaos ~/Documents/Code/JuliaDev/PolyChaos/src/typesQuad.jl:58\nQuad{Float64,Array{Float64,1}}(\"quadgp\", 4, [1.0, 0.8535533905932737, 0.5, 0.14644660940672627, 0.0], [0.033333333333333354, 0.26666666666666666, 0.4, 0.26666666666666666, 0.033333333333333354])\n\njulia> nw(quadRule1)\n5×2 Array{Float64,2}:\n 1.0       0.0333333\n 0.853553  0.266667 \n 0.5       0.4      \n 0.146447  0.266667 \n 0.0       0.0333333","category":"page"},{"location":"numerical_integration/","page":"Numerical Integration","title":"Numerical Integration","text":"This creates a quadrature rule quadRule_1 relative to the measure measure. The function nw() prints the nodes and weights. To solve the integral we call integrate()","category":"page"},{"location":"numerical_integration/","page":"Numerical Integration","title":"Numerical Integration","text":"julia> variant1 = integrate(f, quadRule1)\n0.4596977927043755\n\njulia> print(\"Numerical error: $(abs(1 - cos(1) - variant1))\")\nNumerical error: 9.857251526135258e-8","category":"page"},{"location":"numerical_integration/#Revisiting-Variant-0","page":"Numerical Integration","title":"Revisiting Variant 0","text":"","category":"section"},{"location":"numerical_integration/","page":"Numerical Integration","title":"Numerical Integration","text":"Why is the error from variant 0 so much smaller? It's because the quadrature rule for variant 0 is based on the recurrence coefficients of the polynomials that are orthogonal relative to the measure measure. Let's take a closer look First, we compute the orthogonal polynomials using the composite type OrthoPoly, and we set the keyword addQuadrature to false.","category":"page"},{"location":"numerical_integration/","page":"Numerical Integration","title":"Numerical Integration","text":"julia> op = Uniform01OrthoPoly(n, addQuadrature = false)\nUniform01OrthoPoly{Array{Float64,1},Uniform01Measure,EmptyQuad{Float64}}(5, [0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [1.0, 0.08333333333333333, 0.06666666666666667, 0.06428571428571428, 0.06349206349206349, 0.06313131313131314], Uniform01Measure(PolyChaos.w_uniform01, (0.0, 1.0), true), EmptyQuad{Float64}())","category":"page"},{"location":"numerical_integration/","page":"Numerical Integration","title":"Numerical Integration","text":"Note how op has a field EmptyQuad, i.e. we computed no quadrature rule. The resulting system of orthogonal polynomials is characterized by its recursion coefficients (alpha beta), which can be extracted with the function coeffs().","category":"page"},{"location":"numerical_integration/","page":"Numerical Integration","title":"Numerical Integration","text":"julia> coeffs(op)\n6×2 Array{Float64,2}:\n 0.5  1.0      \n 0.5  0.0833333\n 0.5  0.0666667\n 0.5  0.0642857\n 0.5  0.0634921\n 0.5  0.0631313","category":"page"},{"location":"numerical_integration/","page":"Numerical Integration","title":"Numerical Integration","text":"Now, the quadrature rule can be constructed based on op, and the integral be solved.","category":"page"},{"location":"numerical_integration/","page":"Numerical Integration","title":"Numerical Integration","text":"julia> quadRule2 = Quad(n, op)\nQuad{Float64,Array{Float64,1}}(\"golubwelsch\", 5, [0.046910077030667935, 0.23076534494715842, 0.49999999999999994, 0.7692346550528418, 0.9530899229693321], [0.11846344252809445, 0.23931433524968332, 0.28444444444444444, 0.23931433524968337, 0.1184634425280949])\n\njulia> nw(quadRule2)\n5×2 Array{Float64,2}:\n 0.0469101  0.118463\n 0.230765   0.239314\n 0.5        0.284444\n 0.769235   0.239314\n 0.95309    0.118463\n\njulia> variant0_revisited = integrate(f, quadRule2)\n0.4596976941320484\n\njulia> print(\"Numerical error: $(abs(1 - cos(1) - variant0_revisited))\")\nNumerical error: 1.8818280267396403e-13","category":"page"},{"location":"numerical_integration/#Comparison","page":"Numerical Integration","title":"Comparison","text":"","category":"section"},{"location":"numerical_integration/","page":"Numerical Integration","title":"Numerical Integration","text":"We see that the different variants provide slightly different results:","category":"page"},{"location":"numerical_integration/","page":"Numerical Integration","title":"Numerical Integration","text":"julia> 1 - cos(1) .- [variant0 variant1 variant0_revisited]\n1×3 Array{Float64,2}:\n -1.88183e-13  -9.85725e-8  -1.88183e-13","category":"page"},{"location":"numerical_integration/","page":"Numerical Integration","title":"Numerical Integration","text":"with variant0 and variant0_revisited being the same and more accurate than variant1. The increased accuracy is based on the fact that for variant0 and variant0_revisited the quadrature rules are based on the recursion coefficients of the underlying orthogonal polynomials. The quadrature for variant1 is based on an general-purpose method that can be significantly less accurate, see also the next tutorial.","category":"page"},{"location":"math/#MathematicalBackground","page":"Mathematical Background","title":"Mathematical Background","text":"","category":"section"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"This section is heavily based on the book \"Orthogonal Polynomials: Computation and Approximation\" by Walter Gautschi (Oxford University Press)","category":"page"},{"location":"math/#Orthogonal-Polynomials","page":"Mathematical Background","title":"Orthogonal Polynomials","text":"","category":"section"},{"location":"math/#Basic-Theory","page":"Mathematical Background","title":"Basic Theory","text":"","category":"section"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"We always work with absolutely continuous measures for which we write mathrmd lambda (t) = w(t) mathrmdt, where the so-called weight function w","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"is a nonnegative integrable function on the real line mathbbR, i.e. w mathcalW subseteq mathbbR rightarrow mathbbR_geq 0\nhas finite limits in case mathcalW = mathbbR, i.e.","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"lim_t to pm infty w(t)  infty","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"has finite moments of all orders","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"mu_r(mathrmdlambda) = int_mathcalW t^r mathrmd lambda (t) quad r = 0 1 2 dots quad textwith mu_0  0","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"For any pair of integrable functions u v, their scalar product relative to mathrmd lambda is defined as","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"langle u v rangle_mathrmd lambda = int_mathcalW u(t) v(t) mathrmd lambda(t)","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"Let mathcalP be the set of real polynomials and mathcalP_d subset mathcalP be the set of real polynomials of degree at most d on mathcalW, respectively. Monic real polynomials are real polynomials with leading coefficient equal to one, i.e. pi_k(t) = t^k + dots for k = 0 1 dots","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"The polynomials uv in mathcalP with u neq v are said to be orthogonal if","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"langle u v rangle_mathrmd lambda = int_mathcalW u(t) v(t) mathrmd lambda(t) = 0","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"The norm of u is given by","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":" u _ mathrmdlambda = sqrtlangle u u rangle","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"If the polynomials u in mathcalP has unit length  u _ mathrmdlambda = 1, it is called orthonormal.","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"Monic orthogonal polynomials are polynomials that are monic and orthogonal, hence satisfy","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"pi_k(t) = pi_k(t mathrmd lambda) = t^k + dots\nfor k = 0 1 dots, and\nlangle pi_k pi_l rangle_mathrmdlambda = 0\nfor k neq l and k l = 0 1 dots, and langle pi_k pi_k rangle_mathrmdlambda =  pi_k ^2_ mathrmdlambda  0 for k = 0 1 dots.","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"note: Note\nThe support mathcalW of mathrmd lambda can be an interval (finite, half-finite, infinite), or a finite number of disjoint intervals. If the support consists of a finite or denumerably infinite number of distinct points t_k at which lambda has positive jumps w_k, the measure is called a discrete measure. For a finite number N of points, the discrete measure is denoted by mathrmdlambda_N, and it is characterized by its nodes and weights  t_k w_k _k=1^N according tomathrmd lambda_N (t) = sum_k=1^N w_k delta(t-t_k)where delta is the delta-function.The inner product associated with mathrmd lambda_N islangle u v rangle_mathrmdlambda_N = int_mathcalW u(t) v(t) mathrmd lambda_N (t) = sum_k=1^N w_k u(t_k) v(t_k)There exist only N orthogonal polynomials  pi_k(mathrmd lambda_N) _k=0^N-1 that are orthogonal relative to the discrete measure mathrmd lambda_N in the senselangle pi_k(mathrmd lambda_N) pi_l(mathrmd lambda_N) rangle_mathrmdlambda_N =  pi_k(mathrmd lambda_N) _mathrmd lambda_N delta_klwhere delta_kl is the Dirac-delta, for kl = 0 1 dots N-1.","category":"page"},{"location":"math/#Properties","page":"Mathematical Background","title":"Properties","text":"","category":"section"},{"location":"math/#Symmetry","page":"Mathematical Background","title":"Symmetry","text":"","category":"section"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"An absolutely continuous measure mathrmd lambda(t) = w(t) mathrmd t is symmetric (with respect to the origin) if its support is mathcalW = -aa for some 0  a leq infty, and if w(-t) = w(t) for all t in mathcalW.","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"Similarly, a discrete measure mathrmd lambda_N (t) = sum_k=1^N w_k delta(t-t_k) is symmetric if t_k = - t_N+1-k, and w_k = w_N+1-k for k=1 2 dots N.","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"Theorem 1.17 states that: If mathrmd lambda is symmetric, then","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"pi_k(-t mathrmd lambda) = (-1)^k pi_k(t mathrmd lambda) quad k=01 dots","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"hence the parity of k decides whether pi_k is even/odd.","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"note: Note\nSymmetry is exploited in computeSP, where symmetry need not be relative to the origin, but some arbitrary point of the support.","category":"page"},{"location":"math/#Three-term-Recurrence-Relation","page":"Mathematical Background","title":"Three-term Recurrence Relation","text":"","category":"section"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"The fact that orthogonal polynomials can be represented in terms of a three-term recurrence formula is at the heart of all numerical methods of the package. The importance of the three-term recurrence relation is difficult to overestimate. It provides","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"efficient means of evaluating polynomials (and derivatives),\nzeros of orthogonal polynomials by means of a eigenvalues of a symmetric, tridiagonal matrix\nacces to quadrature rules,\nnormalization constants to create orthonormal polynomials.","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"Theorem 1.27 states:","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"Let pi_k(cdot) = pi_k(cdot mathrmdlambda) for k = 0 1 dots be the monic orthogonal polynomials with respect to the measure mathrmd lambda. Then","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"beginaligned\npi_k+1(t) = (t - alpha_k) pi_k(t) - beta_k pi_k-1(t) quad k= 0 1 dots \npi_o(t) = 1 \npi_-1(t) = 0\nendaligned","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"where","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"beginaligned\nalpha = alpha_k(mathrmd lambda) = fraclangle t pi_k pi_k rangle_mathrmd lambdalangle pi_k pi_k rangle_mathrmd lambda  k=012 dots \nbeta = beta_k(mathrmd lambda) = fraclangle pi_k pi_k rangle_mathrmd lambdalangle pi_k-1 pi_k-1 rangle_mathrmd lambda  k=12dots\nendaligned","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"Let tildepi_k(cdot) = tildepi_k(cdot mathrmd lambda t) denote the orthonormal polynomials, then","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"beginaligned\nsqrtbeta_k+1 tildepi_k(t) = (t - alpha_k) tildepi_k(t) - sqrtbeta_k tildepi_k-1(t) quad k = 0 1 dots \ntildepi_0(t) = 1 \ntildepi_-1(t) = 0\nendaligned","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"note: Note\nWithin the package, the coefficients (α,β) are the building block to represent (monic) orthogonal polynomials.","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"Notice that beta_0 is arbitrary. Nevertheless, it is convenient to define it as","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"beta_0(mathrmdlambda) = langle pi_0 pi_0 rangle_mathrmd lambda = int_mathcalW mathrmd lambda (t)","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"because it allows to compute the norms of the polynomials based on beta_k alone","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":" pi_n _mathrmd lambda = beta_n(mathrmd lambda) beta_n-1(mathrmd lambda) cdots beta_0(mathrmd lambda) quad n = 01 dots","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"Let the support be mathcalW = ab for 0  ab  infty, then","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"beginaligned\n a  alpha_k(mathrmd lambda)  b  k = 012 dots \n 0  beta_k(mathrmd lambda)  max(a^2 b^2)  k = 1 2 dots\nendaligned","category":"page"},{"location":"math/#Quadrature-Rules","page":"Mathematical Background","title":"Quadrature Rules","text":"","category":"section"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"An n-point quadrature rule for the measure mathrmd lambda t is a formula of the form","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"int_mathcalW f(t) mathrmd lambda(t) = sum_nu = 1^n w_nu f(tau_nu) + R_n(f)","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"The quadrature rule  (tau_nu w_nu) _nu=1^n composed of (mutually distinct) nodes tau_nu and weights w_nu provides an approximation to the integral. The respective error is given by R_n(f). If, for polynomials p in mathcalP_d, the error R_n(p) vanishes, the respective quadrature rule is said to have a degree of exactness d. Gauss quadrature rule are special quadrature rules that have a degree of exactness d = 2n - 1. That means, taking a n =3-point quadrature rule, polynomials up to degree 5 can be integrated exactly. The nodes and weights for the Gauss quadrature rules have some remarkable properties:","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"all Gauss nodes are mutually distinct and contained in the interior of the support of mathrmd lambda;\nthe n Gauss nodes are the zeros of pi_n, the monic orthogonal polynomial of degree n relative to the measure mathrmd lambda;\nall Gauss weights are positive.","category":"page"},{"location":"math/","page":"Mathematical Background","title":"Mathematical Background","text":"The Gauss nodes and weights can be computed using the Golub-Welsch algorithm. This means to solve an eigenvalue problem of a symmetric tridiagonal matrix.","category":"page"},{"location":"multiple_discretization/","page":"Multiple Discretization","title":"Multiple Discretization","text":"using PolyChaos, LinearAlgebra, Plots\nγ = 0.5;\nint_exact = 1+pi/2; # exact value of the integral\nfunction my_w(t, γ)\n    γ + (1 - γ) * 1 / sqrt(1 - t^2)\nend\nN = 1000;\nn,w = fejer(N);\nint_fejer = dot(w,my_w.(n,γ))\nprint(\"Fejer error:\\t$(abs(int_exact-int_fejer))\\twith $N nodes\")\nfunction quad_gaussleg(N,γ)\n    a, b = rm_legendre(N)\n    n, w = golubwelsch(a,b)\nend\nn, w = quad_gaussleg(N+1, γ)\nint_gaussleg = dot(w,γ .+ (1-γ)/sqrt.(1 .- n.^2))\nprint(\"Gauss-Legendre error:\\t$(abs(int_exact-int_gaussleg))\\twith $N nodes\")\nfunction quad_gausscheb(N,γ)\n    a, b = rm_chebyshev1(N)\n    n, w = golubwelsch(a, b)\nend\nn, w = quad_gausscheb(N+1,γ)\nint_gausscheb = dot(w,γ .+ (1-γ)*sqrt.(1 .- n.^2))\nprint(\"Gauss-Chebyshev error:\\t$(abs(int_exact-int_gausscheb))\\twith $(length(n)) nodes\")\nfunction quad_gaussleg_mod(N::Int,γ::Float64)\n    n,w = quad_gaussleg(N+1,γ)\n    return n,γ*w\nend\nfunction quad_gausscheb_mod(N::Int,γ::Float64)\n            n,w = quad_gausscheb(N+1,γ)\n    return n,(1-γ)*w\nend\nN = 8\na,b = mcdiscretization(N,[n->quad_gaussleg_mod(n,γ); n->quad_gausscheb_mod(n,γ)])\nn,w = golubwelsch(a,b)\nint_mc = sum(w)\nprint(\"Discretization error:\\t$(abs(int_exact-int_mc))\\twith $(length(n)) nodes\")\nΓ = 0:0.1:1;\nab = [ mcdiscretization(N,[n->quad_gaussleg_mod(n,gam); n->quad_gausscheb_mod(n,gam)]) for gam in Γ ];\nbb = hcat([ ab[i][2] for i=1:length(Γ)]...);\nb_leg = rm_legendre(N)[2];\nb_cheb = rm_chebyshev1(N)[2]\nbb[:,1]-b_cheb\nbb[:,end]-b_leg\nusing Plots\nplot(Γ,bb',yaxis=:log10, w=3, legend=false)\nzs, os = zeros(N), ones(N)\nscatter!(zs,b_cheb,marker=:x)\nscatter!(os,b_leg,marker=:circle)","category":"page"},{"location":"multiple_discretization/#Multiple-Discretization","page":"Multiple Discretization","title":"Multiple Discretization","text":"","category":"section"},{"location":"multiple_discretization/","page":"Multiple Discretization","title":"Multiple Discretization","text":"This tutorial shows how to compute recurrence coefficients for non-trivial weight functions, and how they are being used for quadrature. The method we use is called multiple discretization, and follows W. Gautschi's book \"Orthogonal Polynomials: Computation and Approximation\", specifically Section 2.2.4, and Example 2.38.","category":"page"},{"location":"multiple_discretization/","page":"Multiple Discretization","title":"Multiple Discretization","text":"Suppose we have the weight function","category":"page"},{"location":"multiple_discretization/","page":"Multiple Discretization","title":"Multiple Discretization","text":"forall t in -11 gamma in 01 quad w(tgamma) = gamma + (1-gamma) frac1sqrt1-t^2","category":"page"},{"location":"multiple_discretization/","page":"Multiple Discretization","title":"Multiple Discretization","text":"and we would like to solve","category":"page"},{"location":"multiple_discretization/","page":"Multiple Discretization","title":"Multiple Discretization","text":"int_-1^1 f(t) w(tc) mathrmdt = sum_nu=1^N f(tau_nu) w_nu","category":"page"},{"location":"multiple_discretization/","page":"Multiple Discretization","title":"Multiple Discretization","text":"by some quadrature rule. We will see that ad-hoc quadrature rules will fail to solve the integral even for the simplest choice f equiv 1. However, finding the recurrence coefficients of the underlying orthogonal polynomials, and then finding the quadrature rule will do just fine.","category":"page"},{"location":"multiple_discretization/","page":"Multiple Discretization","title":"Multiple Discretization","text":"Let us first try to solve the integral for f equiv 1 by Féjer's rule.","category":"page"},{"location":"multiple_discretization/","page":"Multiple Discretization","title":"Multiple Discretization","text":"using PolyChaos, LinearAlgebra\nγ = 0.5;\nint_exact = 1 + pi / 2; # exact value of the integral\nfunction my_w(t, γ)\n    γ + (1 - γ) * 1 / sqrt(1 - t^2)\nend\n\nN = 1000;\nnodes, weights = fejer(N);\nint_fejer = dot(weights, my_w.(nodes, γ))\nprint(\"Fejer error:\\t$(abs(int_exact - int_fejer))\\twith $N nodes\")","category":"page"},{"location":"multiple_discretization/","page":"Multiple Discretization","title":"Multiple Discretization","text":"Clearly, that is not satisfying. Well, the term gamma of the weight w makes us think of Gauss-Legendre integration, so let's try it instead.","category":"page"},{"location":"multiple_discretization/","page":"Multiple Discretization","title":"Multiple Discretization","text":"function quad_gaussleg(N, γ)\n    a, b = rm_legendre(N)\n    nodes, weights = golubwelsch(a, b)\nend\nnodes, weights = quad_gaussleg(N + 1, γ)\nint_gaussleg = dot(weights, γ .+ (1 - γ) / sqrt.(1 .- nodes .^ 2))\nprint(\"Gauss-Legendre error:\\t$(abs(int_exact-int_gaussleg))\\twith $N nodes\")","category":"page"},{"location":"multiple_discretization/","page":"Multiple Discretization","title":"Multiple Discretization","text":"Even worse! Well, we can factor out frac1sqrt1-t^2, making the integral amenable to a Gauss-Chebyshev rule. So, let's give it anothery try.","category":"page"},{"location":"multiple_discretization/","page":"Multiple Discretization","title":"Multiple Discretization","text":"function quad_gausscheb(N, γ)\n    a, b = rm_chebyshev1(N)\n    nodes, weights = golubwelsch(a, b)\nend\nnodes, weights = quad_gausscheb(N + 1, γ)\nint_gausscheb = dot(weights, γ .+ (1 - γ) * sqrt.(1 .- nodes .^ 2))\n# int=sum(xw(:,2).*(1+sqrt(1-xw(:,1).^2)))\nprint(\"Gauss-Chebyshev error:\\t$(abs(int_exact - int_gausscheb))\\twith $(length(n)) nodes\")","category":"page"},{"location":"multiple_discretization/","page":"Multiple Discretization","title":"Multiple Discretization","text":"Okay, that's better, but it took us a lot of nodes to get this result. Is there a different way? Indeed, there is. As we have noticed, the weight w has a lot in common with Gauss-Legendre and Gauss-Chebyshev. We can decompose the integral as follows","category":"page"},{"location":"multiple_discretization/","page":"Multiple Discretization","title":"Multiple Discretization","text":"int_-1^1 f(t) w(t) mathrmdt = sum_i=1^m int_-1^1 f(t) w_i(t) mathrmd t","category":"page"},{"location":"multiple_discretization/","page":"Multiple Discretization","title":"Multiple Discretization","text":"with","category":"page"},{"location":"multiple_discretization/","page":"Multiple Discretization","title":"Multiple Discretization","text":"beginalign*\nw_1(t) = gamma \nw_2(t) = (1-gamma) frac1sqrt1-t^2\nendalign*","category":"page"},{"location":"multiple_discretization/","page":"Multiple Discretization","title":"Multiple Discretization","text":"To the weight w_1 we can apply Gauss-Legendre quadrature, to the weight w_2 we can apply Gauss-Chebyshev quadrature (with tiny modifications). This discretization of the measure can be used in our favor. The function mcdiscretization() takes the m discretization rules as an input","category":"page"},{"location":"multiple_discretization/","page":"Multiple Discretization","title":"Multiple Discretization","text":"function quad_gaussleg_mod(N, γ)\n    nodes, weights = quad_gaussleg(N + 1, γ)\n    nodes, γ * weights\nend\nfunction quad_gausscheb_mod(N, γ)\n    nodes, weights = quad_gausscheb(N + 1, γ)\n    return nodes, (1 - γ) * weights\nend\n\nN = 8\na, b = mcdiscretization(N, [n -> quad_gaussleg_mod(n, γ); n -> quad_gausscheb_mod(n, γ)])\nnodes, weights = golubwelsch(a, b)\nint_mc = sum(w)\nprint(\"Discretization error:\\t$(abs(int_exact-int_mc))\\twith $(length(n)) nodes\")","category":"page"},{"location":"multiple_discretization/","page":"Multiple Discretization","title":"Multiple Discretization","text":"Et voilà, no error with fewer nodes. (For this example, we'd need in fact just a single node.)","category":"page"},{"location":"multiple_discretization/","page":"Multiple Discretization","title":"Multiple Discretization","text":"The function mcdiscretization() is able to construct the recurrence coefficients of the orthogonal polynomials relative to the weight w. Let's inspect the values of the recurrence coefficients a little more. For gamma = 0, we are in the world of Chebyshev polynomials, for gamma = 1, we enter the realm of Legendre polynomials. And in between? That's exactly where the weight w comes in: it can be thought of as an interpolatory weight, interpolating Legendre polynomials and Chebyshev polynomials. Let's verify this by plotting the recurrence coefficients for several values of gamma.","category":"page"},{"location":"multiple_discretization/","page":"Multiple Discretization","title":"Multiple Discretization","text":"Γ = 0:0.1:1;\nab = [mcdiscretization(N,\n                       [n -> quad_gaussleg_mod(n, gam); n -> quad_gausscheb_mod(n, gam)])\n      for gam in Γ];\nbb = hcat([ab[i][2] for i in 1:length(Γ)]...);\nb_leg = rm_legendre(N)[2];\nb_cheb = rm_chebyshev1(N)[2]\nbb[:, 1] - b_cheb","category":"page"},{"location":"multiple_discretization/","page":"Multiple Discretization","title":"Multiple Discretization","text":"bb[:, end] - b_leg","category":"page"},{"location":"multiple_discretization/","page":"Multiple Discretization","title":"Multiple Discretization","text":"Let's plot these values to get a better feeling.","category":"page"},{"location":"multiple_discretization/","page":"Multiple Discretization","title":"Multiple Discretization","text":"using Plots\nplot(Γ, bb', yaxis = :log10, w = 3, legend = false)\nzs, os = zeros(N), ones(N)\nscatter!(zs, b_cheb, marker = :x)\nscatter!(os, b_leg, marker = :circle)\n\nxlabel!(\"Gamma\")\nylabel!(\"Beta\")","category":"page"},{"location":"multiple_discretization/","page":"Multiple Discretization","title":"Multiple Discretization","text":"The crosses denote the values of the β recursion coefficients for Chebyshev polynomials; the circles the β recursion coefficients for Legendre polynomials. The interpolating line in between stands for the β recursion coefficients of w(t gamma).","category":"page"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"using PolyChaos\nd = 6\nmyops = Dict()\npolynames = [\"gaussian\", \"beta01\", \"uniform01\", \"logistic\"]\ngaussian = GaussOrthoPoly(d);\nmyops[\"gaussian\"] = gaussian\nα, β = 1.3, 2.2\nbeta01 = Beta01OrthoPoly(d,α,β);\nmyops[\"beta01\"] = beta01\nuniform01 = Uniform01OrthoPoly(d);\nmyops[\"uniform01\"] = uniform01\nlogistic = LogisticOrthoPoly(d);\nmyops[\"logistic\"] = logistic;\nmyops\npoints, degrees = randn(10), 0:2:d\n[ evaluate(degree,points,gaussian) for degree in degrees ]\nμ, σ = 2., 0.2\npce_gaussian = convert2affinePCE(μ,σ,gaussian)\na, b = -0.3, 1.2\nconvert2affinePCE(a,b,uniform01)\npce_uniform = convert2affinePCE(μ,σ,uniform01;kind=\"μσ\")\nconvert2affinePCE(a,b,beta01)\npce_beta = convert2affinePCE(μ,σ,beta01; kind=\"μσ\")\na1, a2 = μ, sqrt(3)*σ/pi\npce_logistic = convert2affinePCE(a1,a2,logistic)\nmean(pce_gaussian,myops[\"gaussian\"]), std(pce_gaussian,myops[\"gaussian\"])\nmean(pce_uniform,myops[\"uniform01\"]), std(pce_uniform,myops[\"uniform01\"])\nmean(pce_beta,myops[\"beta01\"]), std(pce_beta,myops[\"beta01\"])\nmean(pce_logistic,myops[\"logistic\"]), std(pce_logistic,myops[\"logistic\"])\nusing Statistics\nN = 1000\nξ_gaussian = sampleMeasure(N,myops[\"gaussian\"])\nsamples_gaussian = evaluatePCE(pce_gaussian,ξ_gaussian,myops[\"gaussian\"])\nξ_uniform = sampleMeasure(N,myops[\"uniform01\"])\nsamples_uniform = evaluatePCE(pce_uniform,ξ_uniform,myops[\"uniform01\"])\nξ_beta = sampleMeasure(N,myops[\"beta01\"])\nsamples_beta = evaluatePCE(pce_beta,ξ_beta,myops[\"beta01\"])\nξ_logistic = sampleMeasure(N,myops[\"logistic\"])\nsamples_logistic = evaluatePCE(pce_logistic,ξ_logistic,myops[\"logistic\"])\n","category":"page"},{"location":"pce_tutorial/#CommonRandomVariables","page":"Basic Usage","title":"Common Random Variables","text":"","category":"section"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"Polynomial chaos expansion (PCE) is a Hilbert space technique for random variables with finite variance. Mathematically equivalent to Fourier series expansions for periodic signals, PCE allows to characterize a random variable in terms of its PCE coefficients (aka Fourier coefficients). That is, the PCE of a random variable mathsfx is given by","category":"page"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"mathsfx = sum_i=0^L x_i phi_i","category":"page"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"where x_i are the so-called PCE coefficients, and phi_i are the orthogonal polynomials that are orthogonal relative to the probability density function of mathsfx.","category":"page"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"This tutorial walks you through the PCE of common random variables, namely Gaussian (gaussian), Beta (beta01), Uniform(uniform01), Logistic (logistic), and shows how they are implemented in PolyChaos.","category":"page"},{"location":"pce_tutorial/#Construction-of-Basis","page":"Basic Usage","title":"Construction of Basis","text":"","category":"section"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"using PolyChaos","category":"page"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"The orthogonal polynomials are constructed using the OrthoPoly-type (here of degree at most d). For canonical measures special constructors are implemented:","category":"page"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"d = 6\n\nmyops = Dict()\npolynames = [\"gaussian\", \"beta01\", \"uniform01\", \"logistic\"]\n\n# gaussian\ngaussian = GaussOrthoPoly(d);\nmyops[\"gaussian\"] = gaussian\n\n# beta01\nα, β = 1.3, 2.2\nbeta01 = Beta01OrthoPoly(d, α, β);\nmyops[\"beta01\"] = beta01\n\n# uniform01\nuniform01 = Uniform01OrthoPoly(d);\nmyops[\"uniform01\"] = uniform01\n\n# logistic\nlogistic = LogisticOrthoPoly(d);\nmyops[\"logistic\"] = logistic;\n\nmyops","category":"page"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"For example, let's evaluate the Gaussian basis polynomials at some points","category":"page"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"points, degrees = randn(10), 0:2:d\n\n[evaluate(degree, points, gaussian) for degree in degrees]","category":"page"},{"location":"pce_tutorial/#Finding-PCE-Coefficients","page":"Basic Usage","title":"Finding PCE Coefficients","text":"","category":"section"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"Having constructed the orthogonal bases, the question remains how to find the PCE coefficients for the common random variables. Every random variable can be characterized exactly by two PCE coefficients. For a Gaussian random variable, this is familiar: the mean and the variance suffice to describe a Gaussian random variable entirely. The same is true for any random variable of finite variance given the right basis. The function convert2affinePCE provides the first two PCE coefficients (hence the name affine) for the common random variables.","category":"page"},{"location":"pce_tutorial/#Gaussian","page":"Basic Usage","title":"Gaussian","text":"","category":"section"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"Given the Gaussian random variable mathsfx sim mathcalN(mu sigma^2) with sigma  0, the affine PCE coefficients are","category":"page"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"# Gaussian\nμ, σ = 2.0, 0.2\npce_gaussian = convert2affinePCE(μ, σ, gaussian)","category":"page"},{"location":"pce_tutorial/#Uniform","page":"Basic Usage","title":"Uniform","text":"","category":"section"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"Given the uniform random variable mathsfx sim mathcalU(a b) with finite support ab, the affine PCE coefficients are","category":"page"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"a, b = -0.3, 1.2\nconvert2affinePCE(a, b, uniform01)","category":"page"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"Instead, if the expected value and standard deviation are known, the affine PCE coefficients of the uniform random variable are","category":"page"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"pce_uniform = convert2affinePCE(μ, σ, uniform01; kind = \"μσ\")\n# notice that the zero-order coefficient IS equivalent to the expected value μ","category":"page"},{"location":"pce_tutorial/#Beta","page":"Basic Usage","title":"Beta","text":"","category":"section"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"Given the Beta random variable mathsfx sim mathcalB(a b alpha beta) with finite support ab and shape parameters alpha beta  0, the affine PCE coefficients are","category":"page"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"convert2affinePCE(a, b, beta01)","category":"page"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"Instead, if the expected value and standard deviation are known, the affine PCE coefficients of the uniform random variable are","category":"page"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"pce_beta = convert2affinePCE(μ, σ, beta01; kind = \"μσ\")","category":"page"},{"location":"pce_tutorial/#Logistic","page":"Basic Usage","title":"Logistic","text":"","category":"section"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"Given the logstic random variable mathsfx sim mathcalL(a_1a_2) where a_20 with the probability density function","category":"page"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"rho(t) = frac14 a_2  operatornamesech^2 left(fract-a_12a_2right)","category":"page"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"the affine PCE coefficients of the uniform random variable are","category":"page"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"a1, a2 = μ, sqrt(3) * σ / pi\npce_logistic = convert2affinePCE(a1, a2, logistic)","category":"page"},{"location":"pce_tutorial/#Moments","page":"Basic Usage","title":"Moments","text":"","category":"section"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"It is a key feature of PCE to compute moments from the PCE coefficients alone; no sampling is required.","category":"page"},{"location":"pce_tutorial/#Gaussian-2","page":"Basic Usage","title":"Gaussian","text":"","category":"section"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"mean(pce_gaussian, myops[\"gaussian\"]), std(pce_gaussian, myops[\"gaussian\"])","category":"page"},{"location":"pce_tutorial/#Uniform-2","page":"Basic Usage","title":"Uniform","text":"","category":"section"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"mean(pce_uniform, myops[\"uniform01\"]), std(pce_uniform, myops[\"uniform01\"])","category":"page"},{"location":"pce_tutorial/#Beta-2","page":"Basic Usage","title":"Beta","text":"","category":"section"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"mean(pce_beta, myops[\"beta01\"]), std(pce_beta, myops[\"beta01\"])","category":"page"},{"location":"pce_tutorial/#Logistic-2","page":"Basic Usage","title":"Logistic","text":"","category":"section"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"mean(pce_logistic, myops[\"logistic\"]), std(pce_logistic, myops[\"logistic\"])","category":"page"},{"location":"pce_tutorial/#Sampling","page":"Basic Usage","title":"Sampling","text":"","category":"section"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"Having found the PCE coefficients, it may be useful to sample the random variables. That means, find N realizations of the random variable that obey the random variable's probability density function. This is done in two steps:","category":"page"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"Draw N samples from the measure (sampleMeasure()), and then\nEvaluate the basis polynomials and multiply times the PCE coefficients, i.e. sum_i=0^L x_i phi_i(xi_j) where xi_j is the j-th sample from the measure (evaluatePCE()).","category":"page"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"Both steps are combined in the function samplePCE().","category":"page"},{"location":"pce_tutorial/#Gaussian-3","page":"Basic Usage","title":"Gaussian","text":"","category":"section"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"using Statistics\nN = 1000\nξ_gaussian = sampleMeasure(N, myops[\"gaussian\"])\nsamples_gaussian = evaluatePCE(pce_gaussian, ξ_gaussian, myops[\"gaussian\"])\n# samplePCE(N,pce_gaussian,myops[\"gaussian\"])","category":"page"},{"location":"pce_tutorial/#Uniform-3","page":"Basic Usage","title":"Uniform","text":"","category":"section"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"ξ_uniform = sampleMeasure(N, myops[\"uniform01\"])\nsamples_uniform = evaluatePCE(pce_uniform, ξ_uniform, myops[\"uniform01\"])\n# samples_uniform = samplePCE(N,pce_uniform,myops[\"uniform01\"])","category":"page"},{"location":"pce_tutorial/#Beta-3","page":"Basic Usage","title":"Beta","text":"","category":"section"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"ξ_beta = sampleMeasure(N, myops[\"beta01\"])\nsamples_beta = evaluatePCE(pce_beta, ξ_beta, myops[\"beta01\"])\n# samples_beta = samplePCE(N,pce_beta,myops[\"beta01\"])","category":"page"},{"location":"pce_tutorial/#Logistic-3","page":"Basic Usage","title":"Logistic","text":"","category":"section"},{"location":"pce_tutorial/","page":"Basic Usage","title":"Basic Usage","text":"ξ_logistic = sampleMeasure(N, myops[\"logistic\"])\nsamples_logistic = evaluatePCE(pce_logistic, ξ_logistic, myops[\"logistic\"])\n# samples_logistic = samplePCE(N,pce_logistic,myops[\"logistic\"])","category":"page"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"using PolyChaos, LinearAlgebra\nmy_f(t) = t^2\na, b = 1.23, 3.45 # shape parameters of Jacobi weight\nint_exact = 0.353897; # reference value \nN = 4\nα, β = rm_jacobi(N+1,a,b)\nn_gauss, w_gauss = gauss(N,α,β)\nint_gauss = dot(w_gauss, my_f.(n_gauss))\nprint(\"first point:\\t $(n_gauss[1])\\n\")\nprint(\"end point:\\t $(n_gauss[end])\\n\")\nprint(\"error Gauss:\\t $(int_gauss - int_exact)\\n\")\nn_radau, w_radau = radau(N-1, α, β, 1.)\nint_radau = dot(w_radau, my_f.(n_radau))\nprint(\"first point:\\t $(n_radau[1])\\n\")\nprint(\"end point:\\t $(n_radau[end])\\n\")\nprint(\"error Radau:\\t $(int_radau - int_exact)\")\nn_lob, w_lob = lobatto(N-2, α, β, -1., 1.)\nint_lob = dot(w_lob, my_f.(n_lob))\nprint(\"first point:\\t $(n_lob[1])\\n\")\nprint(\"end point:\\t $(n_lob[end])\\n\")\nprint(\"error Lobatto:\\t $(int_lob - int_exact)\")\nn_fej, w_fej = fejer(N)\nint_fej = dot(w_fej, my_f.(n_fej).*(1 .- n_fej).^a.*(1 .+ n_fej).^b)\nprint(\"first point:\\t $(n_fej[1])\\n\")\nprint(\"end point:\\t $(n_fej[end])\\n\")\nprint(\"error Fejer:\\t $(int_fej - int_exact)\")\nn_fej2, w_fej2 = fejer2(N)\nint_fej2 = dot(w_fej2, my_f.(n_fej2).*(1 .- n_fej2).^a.*(1 .+ n_fej2).^b)\nprint(\"first point:\\t $(n_fej2[1])\\n\")\nprint(\"end point:\\t $(n_fej2[end])\\n\")\nprint(\"error Fejer2:\\t $(int_fej2 - int_exact)\")\nn_cc, w_cc = clenshaw_curtis(N)\nint_cc = dot(w_cc, my_f.(n_cc).*(1 .- n_cc).^a.*(1 .+ n_cc).^b)\nprint(\"first point:\\t\\t $(n_cc[1])\\n\")\nprint(\"end point:\\t\\t $(n_cc[end])\\n\")\nprint(\"error Clenshaw-Curtis:\\t $(int_cc - int_exact)\")","category":"page"},{"location":"quadrature_rules/#QuadratureRules","page":"Quadrature Rules","title":"Quadrature Rules","text":"","category":"section"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"In this tutorial we investigate how recurrence coefficients of orthogonal polynomials lead to quadrature rules.","category":"page"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"We want to solve the integral","category":"page"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"I = int_-1^1 f(t) w(t) mathrmd t","category":"page"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"with the weight function","category":"page"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"w(t) = (1-t)^a (1+t)^b","category":"page"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"for all t in -1 1 and a b  -1. For the function f we choose","category":"page"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"f(t) = t^2","category":"page"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"To solve the integral we do the following:","category":"page"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"Choose number of nodes N;\nGenerate recurrence coefficients;\nGenerate quadrature rule from those recurrence coefficients.","category":"page"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"We will compare Gauss quadrature to Gauss-Radau quadrature and Gauss-Lobatto quadrature.","category":"page"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"Make sure to check out this tutorial too.","category":"page"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"Let's begin:","category":"page"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"using PolyChaos, LinearAlgebra\nmy_f(t) = t^2\na, b = 1.23, 3.45 # shape parameters of Jacobi weight\nint_exact = 0.353897; # reference value ","category":"page"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"Now we compute N recurrence coefficients.","category":"page"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"N = 4\nα, β = rm_jacobi(N + 1, a, b)","category":"page"},{"location":"quadrature_rules/#Gauss","page":"Quadrature Rules","title":"Gauss","text":"","category":"section"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"The first quadrature rule is Gauss quadrature. This method goes back to Golub and Welsch.","category":"page"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"n_gauss, w_gauss = gauss(N, α, β)\nint_gauss = dot(w_gauss, my_f.(n_gauss))\nprint(\"first point:\\t $(n_gauss[1])\\n\")\nprint(\"end point:\\t $(n_gauss[end])\\n\")\nprint(\"error Gauss:\\t $(int_gauss - int_exact)\\n\")","category":"page"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"Since Gauss quadrature has a degree of exactness of 2N-1, the value of the integral is exact.","category":"page"},{"location":"quadrature_rules/#Gauss-Radau","page":"Quadrature Rules","title":"Gauss-Radau","text":"","category":"section"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"Gauss-Radau quadrature is a variant of Gauss quadrature that allows to specify a value of a node that has to be included. We choose to include the right end point t = 10.","category":"page"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"n_radau, w_radau = radau(N - 1, α, β, 1.0)\nint_radau = dot(w_radau, my_f.(n_radau))\nprint(\"first point:\\t $(n_radau[1])\\n\")\nprint(\"end point:\\t $(n_radau[end])\\n\")\nprint(\"error Radau:\\t $(int_radau - int_exact)\")","category":"page"},{"location":"quadrature_rules/#Gauss-Lobatto","page":"Quadrature Rules","title":"Gauss-Lobatto","text":"","category":"section"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"Next, we look at Gauss-Lobatto quadrature, which allows to include two points. We choose to include the left and end point of the interval, which are t in -10 10.","category":"page"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"n_lob, w_lob = lobatto(N - 2, α, β, -1.0, 1.0)\nint_lob = dot(w_lob, my_f.(n_lob))\nprint(\"first point:\\t $(n_lob[1])\\n\")\nprint(\"end point:\\t $(n_lob[end])\\n\")\nprint(\"error Lobatto:\\t $(int_lob - int_exact)\")","category":"page"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"There are other quadratures that we subsume as all-purpose quadrature rules. These include Fejér's first and second rule, and Clenshaw-Curtis quadrature.","category":"page"},{"location":"quadrature_rules/#Fejér's-First-Rule","page":"Quadrature Rules","title":"Fejér's First Rule","text":"","category":"section"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"Fejér's first rule does not include the end points of the interval.","category":"page"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"n_fej, w_fej = fejer(N)\nint_fej = dot(w_fej, my_f.(n_fej) .* (1 .- n_fej) .^ a .* (1 .+ n_fej) .^ b)\nprint(\"first point:\\t $(n_fej[1])\\n\")\nprint(\"end point:\\t $(n_fej[end])\\n\")\nprint(\"error Fejer:\\t $(int_fej-int_exact)\")","category":"page"},{"location":"quadrature_rules/#Fejér's-Second-Rule","page":"Quadrature Rules","title":"Fejér's Second Rule","text":"","category":"section"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"Fejér's second rule does include the end points of the interval.","category":"page"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"n_fej2, w_fej2 = fejer2(N)\nint_fej2 = dot(w_fej2, my_f.(n_fej2) .* (1 .- n_fej2) .^ a .* (1 .+ n_fej2) .^ b)\nprint(\"first point:\\t $(n_fej2[1])\\n\")\nprint(\"end point:\\t $(n_fej2[end])\\n\")\nprint(\"error Fejer2:\\t $(int_fej2 - int_exact)\")","category":"page"},{"location":"quadrature_rules/#Clenshaw-Curtis","page":"Quadrature Rules","title":"Clenshaw-Curtis","text":"","category":"section"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"Clenshaw-Curtis quadrature is similar to Féjer's second rule, as in it includes the end points of the integration interval. For the same number of nodes it is also more accurate than Féjer's rules, generally speaking.","category":"page"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"n_cc, w_cc = clenshaw_curtis(N)\nint_cc = dot(w_cc, my_f.(n_cc) .* (1 .- n_cc) .^ a .* (1 .+ n_cc) .^ b)\nprint(\"first point:\\t\\t $(n_cc[1])\\n\")\nprint(\"end point:\\t\\t $(n_cc[end])\\n\")\nprint(\"error Clenshaw-Curtis:\\t $(int_cc - int_exact)\")","category":"page"},{"location":"quadrature_rules/","page":"Quadrature Rules","title":"Quadrature Rules","text":"As we can see, for the same number of nodes N, the quadrature rules based on the recurrence coefficients can greatly outperform the all-purpose quadratures. So, whenever possible, use quadrature rules based on recurrence coefficients of the orthogonal polynomials relative to the underlying measure. Make sure to check out this tutorial too.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"using PolyChaos","category":"page"},{"location":"#Overview","page":"Overview","title":"Overview","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"PolyChaos is a collection of numerical routines for orthogonal polynomials written in the Julia programming language. Starting from some non-negative weight (aka an absolutely continuous nonnegative measure), PolyChaos allows","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"to compute the coefficients for the monic three-term recurrence relation,\nto evaluate the orthogonal polynomials at arbitrary points,\nto compute the quadrature rule,\nto compute tensors of scalar products,\nto do all of the above in a multivariate setting (aka product measures).","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"If the weight function is a probability density function, PolyChaos further provides routines to compute polynomial chaos expansions (PCEs) of random variables with this very density function. These routines allow","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"to compute affine PCE coefficients for arbitrary densities,\nto compute moments,\nto compute the tensors of scalar products.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"PolyChaos contains several canonical orthogonal polynomials such as Jacobi or Hermite polynomials. For these, closed-form expressions and state-of-the art quadrature rules are used whenever possible. However, a cornerstone principle of PolyChaos is to provide all the functionality for user-specific, arbitrary weights.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"note: Note\nWhat PolyChaos is not (at least currently):a self-contained introduction to orthogonal polynomials, quadrature rules and/or polynomial chaos expansions. We assume the user brings some experience to the table. However, over time we will focus on strengthening the tutorial charater of the package.\na symbolic toolbox\na replacement for FastGaussQuadrature.jl","category":"page"},{"location":"#Installation","page":"Overview","title":"Installation","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"The package requires Julia 1.3 or newer. In Julia switch to the package manager","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"using Pkg\nPkg.add(\"PolyChaos\")","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"This will install PolyChaos and its dependencies. Once that is done, load the package:","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"using PolyChaos","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"That's it.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Let's take a look at a simple example. We would like to solve the integral","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"int_0^1 6 x^5 mathrmdx","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Exploiting the underlying uniform measure, the integration can be done exactly with a 3-point quadrature rule.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"julia> using PolyChaos\n\njulia> opq = Uniform01OrthoPoly(3, addQuadrature = true)\nUniform01OrthoPoly{Array{Float64,1},Uniform01Measure,Quad{Float64,Array{Float64,1}}}(3, [0.5, 0.5, 0.5, 0.5], [1.0, 0.08333333333333333, 0.06666666666666667, 0.06428571428571428], Uniform01Measure(PolyChaos.w_uniform01, (0.0, 1.0), true), Quad{Float64,Array{Float64,1}}(\"golubwelsch\", 3, [0.11270166537925838, 0.49999999999999994, 0.8872983346207417], [0.2777777777777777, 0.4444444444444444, 0.27777777777777757]))\n\njulia> integrate(x -> 6x^5, opq)\n0.9999999999999993\n\njulia> show(opq)\n\nUnivariate orthogonal polynomials\ndegree:         3\n#coeffs:        4\nα =             [0.5, 0.5, 0.5, 0.5]\nβ =             [1.0, 0.08333333333333333, 0.06666666666666667, 0.06428571428571428]\n\nMeasure dλ(t)=w(t)dt\nw:      w_uniform01\ndom:    (0.0, 1.0)\nsymmetric:      true","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"To get going with PolyChaos check out the tutorials such as the one on numerical integration. In case you are unfamiliar with orthogonal polynomials, perhaps this background information is of help.","category":"page"},{"location":"#References","page":"Overview","title":"References","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"The code base of PolyChaos is partially based on Walter Gautschi's Matlab suite of programs for generating orthogonal polynomials and related quadrature rules, with much of the theory presented in his book Orthogonal Polynomials: Computation and Approximation published in 2004 by the Oxford University Press.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"For the theory of polynomial chaos expansion we mainly consulted T. J. Sullivan. Introduction to Uncertainty Quantification. Springer International Publishing Switzerland. 2015.","category":"page"},{"location":"#Contributing","page":"Overview","title":"Contributing","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"Please refer to the SciML ColPrac: Contributor's Guide on Collaborative Practices for Community Packages for guidance on PRs, issues, and other matters relating to contributing to SciML.\nSee the SciML Style Guide for common coding practices and other style decisions.\nThere are a few community forums:\nThe #diffeq-bridged and #sciml-bridged channels in the Julia Slack\nThe #diffeq-bridged and #sciml-bridged channels in the Julia Zulip\nOn the Julia Discourse forums\nSee also SciML Community page","category":"page"},{"location":"#Citing","page":"Overview","title":"Citing","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"If you found the software useful and applied it to your own research, we'd appreciate a citation. Add the following to your BibTeX file","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"@ARTICLE{2020arXiv200403970M,\n       author = {{M{\\\"u}hlpfordt}, Tillmann and {Zahn}, Frederik and {Hagenmeyer}, Veit and\n         {Faulwasser}, Timm},\n        title = \"{PolyChaos.jl -- A Julia Package for Polynomial Chaos in Systems and Control}\",\n      journal = {arXiv e-prints},\n     keywords = {Electrical Engineering and Systems Science - Systems and Control, Mathematics - Numerical Analysis, Mathematics - Optimization and Control},\n         year = 2020,\n        month = apr,\n          eid = {arXiv:2004.03970},\n        pages = {arXiv:2004.03970},\narchivePrefix = {arXiv},\n       eprint = {2004.03970},\n}","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Of course you are more than welcome to partake in GitHub's gamification: starring and forking is much appreciated.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Enjoy.","category":"page"},{"location":"#Reproducibility","page":"Overview","title":"Reproducibility","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"<details><summary>The documentation of this SciML package was built using these direct dependencies,</summary>","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"using Pkg # hide\nPkg.status() # hide","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"</details>","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"<details><summary>and using this machine and Julia version.</summary>","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"using InteractiveUtils # hide\nversioninfo() # hide","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"</details>","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"<details><summary>A more complete overview of all dependencies and their versions is also provided.</summary>","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"using Pkg # hide\nPkg.status(; mode = PKGMODE_MANIFEST) # hide","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"</details>","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"You can also download the \n<a href=\"","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"using TOML\nversion = TOML.parse(read(\"../../Project.toml\", String))[\"version\"]\nname = TOML.parse(read(\"../../Project.toml\", String))[\"name\"]\nlink = \"https://github.com/SciML/\" * name * \".jl/tree/gh-pages/v\" * version *\n       \"/assets/Manifest.toml\"","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"\">manifest</a> file and the\n<a href=\"","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"using TOML\nversion = TOML.parse(read(\"../../Project.toml\", String))[\"version\"]\nname = TOML.parse(read(\"../../Project.toml\", String))[\"name\"]\nlink = \"https://github.com/SciML/\" * name * \".jl/tree/gh-pages/v\" * version *\n       \"/assets/Project.toml\"","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"\">project</a> file.","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"note: Note\nIf you are unfamiliar with the mathematical background of orthogonal polynomials, check out this tutorial.","category":"page"},{"location":"type_hierarchy/#Type-Hierarchy","page":"Type Hierarchy","title":"Type Hierarchy","text":"","category":"section"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"Let's look at the types PolyChaos provides. There are four AbstractTypes: AbstractMeasure, AbstractOrthoPoly, AbstractQuad, and AbstractTensor. AbstractMeasure is the core on which AbstractOrthoPoly builds, on which AbstractQuad builds, which is then used by AbstractTensor.","category":"page"},{"location":"type_hierarchy/#AbstractMeasure","page":"Type Hierarchy","title":"AbstractMeasure","text":"","category":"section"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"The type tree for AbstractMeasure looks as follows","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"julia> using AbstractTrees, PolyChaos\n\njulia> AbstractTrees.children(x::Type) = subtypes(x)\n\njulia> print_tree(AbstractMeasure)\nAbstractMeasure\n├─ AbstractCanonicalMeasure\n│  ├─ Beta01Measure\n│  ├─ GammaMeasure\n│  ├─ GaussMeasure\n│  ├─ HermiteMeasure\n│  ├─ JacobiMeasure\n│  ├─ LaguerreMeasure\n│  ├─ LegendreMeasure\n│  ├─ LogisticMeasure\n│  ├─ MeixnerPollaczekMeasure\n│  ├─ Uniform01Measure\n│  ├─ Uniform_11Measure\n│  ├─ genHermiteMeasure\n│  └─ genLaguerreMeasure\n├─ Measure\n└─ ProductMeasure","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"There are several canonical measures that PolyChaos provides, all gathered in as subtypes of AbstractCanonicalMeasure. The Measure type is a generic measure, and ProductMeasure has an obvious meaning.","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"What are the relevant fields?","category":"page"},{"location":"type_hierarchy/#Measure","page":"Type Hierarchy","title":"Measure","text":"","category":"section"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"It all begins with a measure, more specifically absolutely continuous measures. What are the fields of such a type Measure?","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"Field Meaning\nname::String Name of measure\nw::Function Weight function w Omega rightarrow mathbbR\ndom::Tuple{Real,Real} Domain $ \\Omega$\nsymmetric::Bool Is w symmetric relative to some m in Omega, hence w(m-x) = w(m+x) for all x in Omega?\npars::Dict Additional parameters (e.g. shape parameters for Beta distribution)","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"They are a name, a weight function w Omega rightarrow mathbbR with domain Omega (dom). If the weight function is symmetric relative to some m in Omega, the field symmetric should be set to true. Symmetry relative to m means that","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"forall x in Omega quad w(m-x) = w(m+x)","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"For example, the Gaussian probability density","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"w(x) = frac1sqrt2pi mathrme^-x^22","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"is symmetric relative to the origin m=0. If the weight function has any parameters, then they are stored in the dictionary pars. For example, the probability density of the Beta distribution on Omega = 01 has two positive shape parameters alpha beta  0","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"w(x) = frac1B(alphabeta) x^alpha-1 (1-x)^beta-1","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"This tutorial shows the above in action.","category":"page"},{"location":"type_hierarchy/#ProductMeasure","page":"Type Hierarchy","title":"ProductMeasure","text":"","category":"section"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"So far, everything was univariate, the weight of the measure was mapping real numbers to real numbers. PolyChaos can handle product measures too. Let's assume the weight function is a product of two independent Gaussian densities","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"w mathbbR times mathbbR rightarrow mathbbR quad w(x) = frac1sqrt2pi mathrme^x_1^22 frac1sqrt2pi mathrme^x_2^22","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"The type ProductMeasure serves this purpose, with its straightforward fields","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"Field Meaning\nw::Function Weight function\nmeasures::Vector{<:AbstractMeasure} Vector of univariate measures","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"This tutorial shows the above in action.","category":"page"},{"location":"type_hierarchy/#Canonical-Measures","page":"Type Hierarchy","title":"Canonical Measures","text":"","category":"section"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"Canonical measures are special, because we know their orthogonal polynomials. That is why several canonical measures are pre-defined in PolyChaos. Some of them may require additional parameters. (alphabetical order)","category":"page"},{"location":"type_hierarchy/#Beta01Measure","page":"Type Hierarchy","title":"Beta01Measure","text":"","category":"section"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"Field Meaning\nw::Function frac1B(alphabeta)  t^alpha-1 (1-t)^beta-1\ndom::Tuple{<:Real,<:Real} (0 1)\nsymmetric::Bool true if alpha = beta\nashapeParameter::Real alpha  0\nbshapeParameter::Real beta  0","category":"page"},{"location":"type_hierarchy/#GammaMeasure","page":"Type Hierarchy","title":"GammaMeasure","text":"","category":"section"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"Field Meaning\nw::Function fracbeta^alphaGamma(alpha) t^alpha-1 exp(-beta t)\ndom::Tuple{<:Real,<:Real} (0 infty)\nsymmetric::Bool false\nshapeParameter::Real alpha  0\nrateParameter::Real 1","category":"page"},{"location":"type_hierarchy/#GaussMeasure","page":"Type Hierarchy","title":"GaussMeasure","text":"","category":"section"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"Field Meaning\nw::Function frac1sqrt2 pi  exp left( - fract^22 right)\ndom::Tuple{<:Real,<:Real} (-infty infty)\nsymmetric::Bool true","category":"page"},{"location":"type_hierarchy/#HermiteMeasure","page":"Type Hierarchy","title":"HermiteMeasure","text":"","category":"section"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"Field Meaning\nw::Function $ \\exp\\left( - t^2 \\right)$\ndom::Tuple{<:Real,<:Real} (-infty infty)\nsymmetric::Bool true","category":"page"},{"location":"type_hierarchy/#JacobiMeasure","page":"Type Hierarchy","title":"JacobiMeasure","text":"","category":"section"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"Field Meaning\ndom::Tuple{<:Real,<:Real} (-1 1)\nsymmetric::Bool true if alpha = beta\nashapeParameter::Real alpha  -1\nbshapeParameter::Real beta  -1","category":"page"},{"location":"type_hierarchy/#LaguerreMeasure","page":"Type Hierarchy","title":"LaguerreMeasure","text":"","category":"section"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"Field Meaning\nw::Function exp(-t)\ndom::Tuple{<:Real,<:Real} (0 infty)\nsymmetric::Bool true","category":"page"},{"location":"type_hierarchy/#LegendreMeasure","page":"Type Hierarchy","title":"LegendreMeasure","text":"","category":"section"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"Field Meaning\nw::Function 1\ndom::Tuple{<:Real,<:Real} (-1 1)\nsymmetric::Bool true","category":"page"},{"location":"type_hierarchy/#LogisticMeasure","page":"Type Hierarchy","title":"LogisticMeasure","text":"","category":"section"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"Field Meaning\nw::Function fracexp(-t)(1+exp(-t))^2\ndom::Tuple{<:Real,<:Real} (-infty infty)\nsymmetric::Bool true","category":"page"},{"location":"type_hierarchy/#MeixnerPollaczekMeasure","page":"Type Hierarchy","title":"MeixnerPollaczekMeasure","text":"","category":"section"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"Field Meaning\nw::Function frac12 pi exp((2phi-pi)t) lvertGamma(lambda + mathrmit)rvert^2\ndom::Tuple{<:Real,<:Real} (-inftyinfty)\nsymmetric::Bool false\nλParameter::Real lambda  0\nϕParameter::Real 0  phi  pi","category":"page"},{"location":"type_hierarchy/#Uniform01Measure","page":"Type Hierarchy","title":"Uniform01Measure","text":"","category":"section"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"Field Meaning\nw::Function 1\ndom::Tuple{<:Real,<:Real} (0 1)\nsymmetric::Bool true","category":"page"},{"location":"type_hierarchy/#Uniform_11Measure","page":"Type Hierarchy","title":"Uniform_11Measure","text":"","category":"section"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"Field Meaning\nw::Function 05\ndom::Tuple{<:Real,<:Real} (-1 1)\nsymmetric::Bool true","category":"page"},{"location":"type_hierarchy/#genHermiteMeasure","page":"Type Hierarchy","title":"genHermiteMeasure","text":"","category":"section"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"Field Meaning\nw::Function $ \\lvert t \\rvert^{2 \\mu}\\exp \\left( - t^2 \\right)$\ndom::Tuple{<:Real,<:Real} (-infty infty)\nsymmetric::Bool true\nmuParameter::Real mu  -05","category":"page"},{"location":"type_hierarchy/#genLaguerreMeasure","page":"Type Hierarchy","title":"genLaguerreMeasure","text":"","category":"section"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"Field Meaning\nw::Function t^alphaexp(-t)\ndom::Tuple{<:Real,<:Real} (0infty)\nsymmetric::Bool false\nshapeParameter::Bool alpha-1","category":"page"},{"location":"type_hierarchy/#AbstractOrthoPoly","page":"Type Hierarchy","title":"AbstractOrthoPoly","text":"","category":"section"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"Orthogonal polynomials are at the heart of PolyChaos. The type tree for AbstractOrthoPoly looks as follows","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"julia> print_tree(AbstractOrthoPoly)\nAbstractOrthoPoly\n├─ AbstractCanonicalOrthoPoly\n│  ├─ Beta01OrthoPoly\n│  ├─ GammaOrthoPoly\n│  ├─ GaussOrthoPoly\n│  ├─ HermiteOrthoPoly\n│  ├─ JacobiOrthoPoly\n│  ├─ LaguerreOrthoPoly\n│  ├─ LegendreOrthoPoly\n│  ├─ LogisticOrthoPoly\n│  ├─ MeixnerPollaczekOrthoPoly\n│  ├─ Uniform01OrthoPoly\n│  ├─ Uniform_11OrthoPoly\n│  ├─ genHermiteOrthoPoly\n│  └─ genLaguerreOrthoPoly\n├─ MultiOrthoPoly\n└─ OrthoPoly","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"It mirrors the type tree from AbstractMeasure: there is a generica (univariate) type OrthoPoly, a multivariate extension MultiOrthoPoly for product measures, and several univariate canonical orthogonal polynomials.","category":"page"},{"location":"type_hierarchy/#OrthoPoly","page":"Type Hierarchy","title":"OrthoPoly","text":"","category":"section"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"Given an absolutely continuous measure we are wondering what are the monic polynomials phi_i Omega rightarrow mathbbR that are orthogonal relative to this very measure? Mathematically this reads","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"langle phi_i phi_j rangle = int_Omega phi_i(t) phi_j(t) w(t) mathrmdt =\nbegincases\n 0  i=j \n= 0  ineq j\nendcases","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"They can be constructed using the type OrthoPoly, which has the fields","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"Name Meaning\nname::String Name\ndeg::Int Maximum degree\nα::Vector{<:Real} Vector of recurrence coefficients α\nβ::Vector{<:Real} Vector of recurrence coefficients β\nmeas::AbstractMeasure Underlying measure","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"The purpose of name is obvious. The integer deg stands for the maxium degree of the polynomials. Rather than storing the polynomials phi_i themselves we store the recurrence coefficients α, β that characterize the system of orthogonal polynomials. These recurrence coefficients are the single most important piece of information for the orthogonal polynomials. For several common measures, there exist analytic formulae. These are built-in to PolyChaos and should be used whenever possible.","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"This tutorial shows the above in action.","category":"page"},{"location":"type_hierarchy/#MultiOrthoPoly","page":"Type Hierarchy","title":"MultiOrthoPoly","text":"","category":"section"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"Just as we did in the univariate case, we use ProductMeasure as a building block for multivariate orthogonal polynomials. The type MultiOrthoPoly combines product measures with the respective orthogonal polynomials and their quadrature rules. Its fields are","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"Name Meaning\nname::Vector{String} Vector of names\ndeg::Int Maximum degree\ndim::Int Dimension\nind::Matrix{<:Int} Array of multi-indices\nmeasure::ProductMeasure Underlying product measure","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"The names of the univariate bases are stored in names; the maximum degree of the basis is deg; the overall dimension of the multivariate basis is dim; the multi-index ind maps the j-th multivariate basis to the elements of the univariate bases; the product measure is stored in meas; finally, all univariate bases are collected in uni.","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"This tutorial shows the above in action.","category":"page"},{"location":"type_hierarchy/#AbstractCanonicalOrthoPoly","page":"Type Hierarchy","title":"AbstractCanonicalOrthoPoly","text":"","category":"section"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"These are the bread-and-butter polynomials: polynomials for which we know analytic formulae for the recursion coefficients. The following canonical orthogonal polynomials are implemented","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"julia> print_tree(AbstractCanonicalOrthoPoly)\nAbstractCanonicalOrthoPoly\n├─ Beta01OrthoPoly\n├─ GammaOrthoPoly\n├─ GaussOrthoPoly\n├─ HermiteOrthoPoly\n├─ JacobiOrthoPoly\n├─ LaguerreOrthoPoly\n├─ LegendreOrthoPoly\n├─ LogisticOrthoPoly\n├─ MeixnerPollaczekOrthoPoly\n├─ Uniform01OrthoPoly\n├─ Uniform_11OrthoPoly\n├─ genHermiteOrthoPoly\n└─ genLaguerreOrthoPoly","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"Their fields follow","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"Name Meaning\ndeg::Int Maximum degree\nα::Vector{<:Real} Vector of recurrence coefficients\nβ::Vector{<:Real} Vector of recurrence coefficients\nmeasure::CanonicalMeasure Underlying canonical measure\nquad::AbstractQuad Quadrature rule","category":"page"},{"location":"type_hierarchy/#Quad","page":"Type Hierarchy","title":"Quad","text":"","category":"section"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"Quadrature rules are intricately related to orthogonal polynomials. An n-point quadrature rule is a pair of so-called nodes t_k and weights w_k for k=1dotsn that allow to solve integrals relative to the measure","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"int_Omega f(t) w(t) mathrmd t approx sum_k=1^n w_k f(t_k)","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"If the integrand f is polynomial, then the specific Gauss quadrature rules possess the remarkable property that an n-point quadrature rule can integrate polynomial integrands f of degree at most 2n-1 exactly; no approximation error is made.","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"The fields of Quad are","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"Name Meaning\nname::String Name\nNquad::Int Number n of quadrature points\nnodes::Vector{<:Real} Nodes\nweights::Vector{<:Real} Weights","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"with obvious meanings.","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"PolyChaos provides the type EmptyQuad that is added in case no quadrature rule is desired.","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"This tutorial shows the above in action.","category":"page"},{"location":"type_hierarchy/#Tensor","page":"Type Hierarchy","title":"Tensor","text":"","category":"section"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"The last type we need to address is Tensor. It is used to store the results of scalar products. Its fields are","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"Name Meaning\ndim: Dimension m of tensor langle phi_i_1 phi_i_2 cdots phi_i_m-1 phi_i_m rangle\nT::SparseVector{Float64,Int} Entries of tensor\nget::Function Function to get entries from T\nop::AbstractOrthoPoly Underlying univariate orthogonal polynomials","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"The dimension m of the tensor is the number of terms that appear in the scalar product. Let's assume we set m = 3, hence have langle phi_i phi_j phi_k rangle, then the concrete entry is obtained as Tensor.get([i,j,k]).","category":"page"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"This tutorial shows the above in action.","category":"page"}]
}
