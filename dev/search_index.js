var documenterSearchIndex = {"docs":
[{"location":"orthogonal_polynomials_canonical/#UnivariateMonicOrthogonalPolynomials","page":"Univariate Monic Orthogonal Polynomials","title":"Univariate Monic Orthogonal Polynomials","text":"Univariate monic orthogonal polynomials make up the core building block of the package. These are real polynomials  pi_k _k geq 0, which are univariate pi_k mathbbR rightarrow mathbbR and orthogonal relative to a non-negative weight function w mathbbR rightarrow mathbbR_geq 0, and which have a leading coefficient equal to one:\n\nbeginaligned\npi_k(t) = t^k + a_k-1 t^k-1 + dots + a_1 t + a_0 quad forall k = 0 1 dots \nlangle pi_k pi_l rangle = int_mathbbR pi_k(t) pi_l(t) w(t) mathrmdt =\nbegincases\n0  k neq l text and kl geq 0 \n pi_k ^2  0  k = l geq 0\nendcases\nendaligned\n\nThese univariate monic orthogonal polynomials satisfy the paramount three-term recurrence relation\n\nbeginaligned\npi_k+1(t) = (t - alpha_k) pi_k(t) - beta_k pi_k-1(t) quad k= 0 1 dots \npi_o(t) = 1 \npi_-1(t) = 0\nendaligned\n\nHence, every system of n univariate monic orthogonal polynomials  pi_k _k=0^n is isomorphic to its recurrence coefficients  alpha_k beta_k _k=0^n.","category":"section"},{"location":"orthogonal_polynomials_canonical/#Canonical-Orthogonal-Polynomials","page":"Univariate Monic Orthogonal Polynomials","title":"Canonical Orthogonal Polynomials","text":"The so-called classical or canonical orthogonal polynomials are polynomials named after famous mathematicians who each discovered a special family of orthogonal polynomials, for example Hermite polynomials or Jacobi polynomials. For classical orthogonal polynomials, there exist closed-form expressions of–-among others–-the recurrence coefficients. Also, quadrature rules for classical orthogonal polynomials are well-studied (with dedicated packages such as FastGaussQuadrature.jl). However, more often than not these classical orthogonal polynomials are neither monic nor orthogonal, hence not normalized in any sense. For example, there is a distinction between the probabilists' Hermite polynomials and the physicists' Hermite polynomials. The difference is in the weight function w(t) relative to which the polynomials are orthogonal:\n\nbeginaligned\ntextProbabilists w(t) = frac1sqrt2 pi  exp left( - fract^22 right) \ntextPhysicists w(t) =  exp left( - t^2 right)\nendaligned\n\nTo streamline the computations, all classical orthogonal polynomials are converted to monic orthogonal polynomials (for which, of course, the closed-form expressions persist). Currently, the following weight functions (hence classical orthogonal polynomials) are supported:\n\nName Weight w(t) Parameters Support Classical polynomial\nhermite $ \\exp \\left( - t^2 \\right)$ - (-infty infty) Hermite\ngenhermite $ \\lvert t \\rvert^{2 \\mu}\\exp \\left( - t^2 \\right)$ mu  -frac12 (-infty infty) Generalized Hermite\nlegendre 1 - (-11) Legendre\njacobi (1-t)^alpha (1+t)^beta alpha beta  -1 (-11) Jacobi\nlaguerre exp(-t) - (0infty) Laguerre\ngenlaguerre t^alphaexp(-t) alpha-1 (0infty) Generalized Laguerre\nmeixnerpollaczek frac12 pi exp((2phi-pi)t) lvertGamma(lambda + mathrmit)rvert^2 lambda  0 0phipi (-inftyinfty) Meixner-Pollaczek\n\nAdditionally, the following weight functions that are equivalent to probability density functions are supported:\n\nName Weight w(t) Parameters Support Classical polynomial\ngaussian frac1sqrt2 pi  exp left( - fract^22 right) - (-infty infty) Probabilists' Hermite\nuniform01 1 - (01) Legendre\nbeta01 frac1B(alphabeta)  t^alpha-1 (1-t)^beta-1 alpha beta  0 (01) Jacobi\ngamma fracbeta^alphaGamma(alpha) t^alpha-1 exp(-beta t) alpha beta  0 (0infty) Laguerre\nlogistic fracexp(-t)(1+exp(-t))^2 - (-inftyinfty) -\n\nTo generate the orthogonal polynomials up to maximum degree deg, simply call\n\njulia> using PolyChaos\n\njulia> deg = 4\n4\n\njulia> op = GaussOrthoPoly(deg)\nGaussOrthoPoly{Array{Float64,1},GaussMeasure,Quad{Float64,Array{Float64,1}}}(4, [0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 2.0, 3.0, 4.0], GaussMeasure(PolyChaos.w_gaussian, (-Inf, Inf), true), Quad{Float64,Array{Float64,1}}(\"golubwelsch\", 4, [-2.3344142183389778, -0.7419637843027257, 0.7419637843027258, 2.3344142183389778], [0.04587585476806844, 0.45412414523193134, 0.45412414523193106, 0.04587585476806852]))\n\njulia> show(op)\n\nUnivariate orthogonal polynomials\ndegree:         4\n#coeffs:        5\nα =             [0.0, 0.0, 0.0, 0.0, 0.0]\nβ =             [1.0, 1.0, 2.0, 3.0, 4.0]\n\nMeasure dλ(t)=w(t)dt\nw:      w_gaussian\ndom:    (-Inf, Inf)\nsymmetric:      true\n\nThis generates opas a GaussOrthoPoly type with the underlying Gaussian measure op.measure. The recurrence coefficients are accessible via coeffs().\n\njulia> coeffs(op)\n5×2 Array{Float64,2}:\n 0.0  1.0\n 0.0  1.0\n 0.0  2.0\n 0.0  3.0\n 0.0  4.0\n\nBy default, the constructor for OrthoPoly generates deg+1 recurrence coefficients. Sometimes, some other number Nrec may be required. This is why Nrec is a keyword for the constructor OrthoPoly.\n\njulia> N = 100\n100\n\njulia> opLogistic = LogisticOrthoPoly(deg; Nrec = N)\nLogisticOrthoPoly{Array{Float64,1},LogisticMeasure,Quad{Float64,Array{Float64,1}}}(4, [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 3.289868133696453, 10.527578027828648, 22.841084471092515, 40.10505915363294, 62.30810859273584, 89.4476035231595, 121.52266752315666, 158.53293971318436, 200.47824915030117  …  19986.565781520196, 20433.165380253333, 20884.69978120051, 21341.168984361153, 21802.572989734712, 22268.91179732067, 22740.185407118537, 23216.393819127847, 23697.53703334815, 24183.61504977904], LogisticMeasure(PolyChaos.w_logistic, (-Inf, Inf), true), Quad{Float64,Array{Float64,1}}(\"golubwelsch\", 99, [-285.97091675697385, -266.56611354854135, -251.01698966393153, -237.53179686807928, -225.4187633699017, -214.31820469129195, -204.0126795649811, -194.35793540921836, -185.25200558110012, -176.61940782973926  …  176.61940782973895, 185.25200558110018, 194.35793540921847, 204.01267956498108, 214.31820469129212, 225.4187633699016, 237.53179686807948, 251.01698966393138, 266.56611354854135, 285.9709167569736], [1.4541663108207099e-123, 2.897917000559268e-115, 1.3858976222735606e-108, 8.826460482953542e-103, 1.4618715331286334e-97, 8.935651454381735e-93, 2.49282531464423e-88, 3.6557113389197252e-84, 3.1147999002113552e-80, 1.660700338355251e-76  …  1.6607003383554774e-76, 3.1147999002111335e-80, 3.6557113389195227e-84, 2.492825314644278e-88, 8.935651454380596e-93, 1.461871533128785e-97, 8.826460482953113e-103, 1.3858976222735651e-108, 2.8979170005595435e-115, 1.4541663108207404e-123]))\n\njulia> show(opLogistic)\n\nUnivariate orthogonal polynomials\ndegree:         4\n#coeffs:        100\nα =             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]...\nβ =             [1.0, 3.289868133696453, 10.527578027828648, 22.841084471092515, 40.10505915363294, 62.30810859273584, 89.4476035231595]...\n\nMeasure dλ(t)=w(t)dt\nw:      w_logistic\ndom:    (-Inf, Inf)\nsymmetric:      true\n\nLet's check whether we truly have more coefficients:\n\njulia> size(coeffs(opLogistic), 1) == N\ntrue","category":"section"},{"location":"orthogonal_polynomials_canonical/#Arbitrary-Weights","page":"Univariate Monic Orthogonal Polynomials","title":"Arbitrary Weights","text":"If you are given a weight function w that does not belong to the Table above, it is still possible to generate the respective univariate monic orthogonal polynomials. First, we define the measure by specifying a name, the weight, the support, symmetry, and parameters\n\njulia> supp = (-1, 1)\n(-1, 1)\n\njulia> w(t) = 1 + t\nw (generic function with 1 method)\n\njulia> my_meas = Measure(\"my_meas\", w, supp, false, Dict())\nMeasure(\"my_meas\", w, (-1.0, 1.0), false, Dict{Any,Any}())\n\nNotice: it is advisable to define the weight such that an error is thrown for arguments outside the support.\n\nNow, we want to construct the univariate monic orthogonal polynomials up to degree deg relative to my_meas. The constructor is\n\njulia> my_op = OrthoPoly(\"my_op\", deg, my_meas; Nquad = 200);\n\njulia> show(my_op)\n\nUnivariate orthogonal polynomials\ndegree:         4\n#coeffs:        5\nα =             [0.3333333333333335, 0.06666666666666644, 0.028571428571428848, 0.015873015873015657, 0.010101010101010171]\nβ =             [2.0, 0.2222222222222223, 0.23999999999999996, 0.24489795918367344, 0.2469135802469136]\n\nMeasure dλ(t)=w(t)dt\nname:   my_meas\nw:      w\ndom:    (-1.0, 1.0)\nsymmetric:      false\npars:   Dict{Any,Any}()\n\nBy default, the recurrence coefficients are computed using the Stieltjes procedure with Clenshaw-Curtis quadrature (with Nquad nodes and weights). Hence, the choice of Nquad influences accuracy.","category":"section"},{"location":"orthogonal_polynomials_canonical/#MultivariateMonicOrthogonalPolynomials","page":"Univariate Monic Orthogonal Polynomials","title":"Multivariate Monic Orthogonal Polynomials","text":"Suppose we have p systems of univariate monic orthogonal polynomials,\n\n pi_k^(1) _kgeq 0   pi_k^(2) _kgeq 0 dots  pi_k^(p) _kgeq 0\n\neach system being orthogonal relative to the weights w^(1) w^(2) dots w^(p) with supports mathcalW^(1) mathcalW^(2) dots mathcalW^(p). Also, let d^(i) be the maximum degree of the i-th system of univariate orthogonal polynomials. We would like to construct a p-variate monic basis  psi_k _k geq 0 with psi mathbbR^p rightarrow mathbbR of degree at most 0 leq d leq min_i=1dotsk d^(i). Further, this basis shall be orthogonal relative to the product measure w mathcalW = mathcalW^(1) otimes mathcalW^(2) otimes cdots otimes mathcalW^(p) rightarrow mathbbR_geq 0 given by\n\nw(t) = prod_i=1^p w^(i)(t_i)\n\nhence satisfies\n\nlangle psi_k psi_l rangle = int_mathcalW psi_k(t) psi_l(t) w(t) mathrmd t =\nbegincases\n0  k neq l text and kl geq 0 \n psi_k ^2  0  k = l geq 0\nendcases\n\nFor this, there exists the composite struct MultiOrthoPoly. Let's consider an example where we mix classical orthogonal polynomials with an arbitrary weight.\n\njulia> deg = [3, 5, 6, 4]\n4-element Array{Int64,1}:\n 3\n 5\n 6\n 4\n\njulia> d = minimum(deg)\n3\n\njulia> op1 = GaussOrthoPoly(deg[1]);\n\njulia> op2 = Uniform01OrthoPoly(deg[2]);\n\njulia> op3 = Beta01OrthoPoly(deg[3], 2, 1.2);\n\njulia> ops = [op1, op2, op3, my_op];\n\njulia> mop = MultiOrthoPoly(ops, d);\n\njulia> show(mop)\n\n4-variate orthogonal polynomials\nname:           GaussOrthoPoly{Array{Float64,1},GaussMeasure,Quad{Float64,Array{Float64,1}}}\n                Uniform01OrthoPoly{Array{Float64,1},Uniform01Measure,Quad{Float64,Array{Float64,1}}}\n                Beta01OrthoPoly{Array{Float64,1},Beta01Measure,Quad{Float64,Array{Float64,1}}}\n                my_op\ndeg:            3\ndim:            35\nind:            [0, 0, 0, 0]\n                [1, 0, 0, 0]\n                [0, 1, 0, 0]\n                [0, 0, 1, 0]\n                [0, 0, 0, 1]\n                [2, 0, 0, 0]\n                [1, 1, 0, 0]\n                ...\n\nfalse\n\nThe total number of  basis polynomials is stored in the field dim. The univariate basis polynomials making up the multivariate basis are stored in the field uni. The field ind contains the multi-index, i.e. row i stores what combination of univariate polynomials makes up the i-th multivariate polynomial. For example,\n\njulia> i = 11;\n\njulia> mop.ind[i + 1, :]\n4-element Array{Int64,1}:\n 0\n 1\n 0\n 1\n\ntranslates mathematically to\n\npsi_11(t) = pi_0^(1)(t_1) pi_1^(2)(t_2) pi_0^(3)(t_3) pi_1^(4)(t_4)\n\nNotice that there is an offset by one, because the basis counting starts at 0, but Julia is 1-indexed. The underlying measure of mop is now of type ProductMeasure, and stored in the field measure The weight w can be evaluated as one would expect.","category":"section"},{"location":"functions/#Functions","page":"Functions","title":"Functions","text":"note: Note\nThe core interface of all essential functions are not dependent on specialized types such as AbstractOrthoPoly. Having said that, for exactly those essential functions, there exist overloaded functions that accept specialized types such as AbstractOrthoPoly as arguments.Too abstract? For example, the function evaluate that evaluates a polynomial of degree n at points x has the core interface    evaluate(n::Int,x::Array{<:Real},a::Vector{<:Real},b::Vector{<:Real})where a and b are the vectors of recurrence coefficients. For simplicity, there also exists the interface    evaluate(n::Int64,x::Vector{<:Real},op::AbstractOrthoPoly)So fret not upon the encounter of multiple-dispatched versions of the same thing. It's there to simplify your life.The idea of this approach is to make it simpler for others to copy and paste code snippets and use them in their own work.\n\nList of all functions in PolyChaos.\n\n","category":"section"},{"location":"functions/#Recurrence-Coefficients-for-Monic-Orthogonal-Polynomials","page":"Functions","title":"Recurrence Coefficients for Monic Orthogonal Polynomials","text":"The functions below provide analytic expressions for the recurrence coefficients of common orthogonal polynomials. All of these provide monic orthogonal polynomials relative to the weights.\n\nnote: Note\nThe number N of recurrence coefficients has to be positive for all functions below.","category":"section"},{"location":"functions/#Show-Orthogonal-Polynomials","page":"Functions","title":"Show Orthogonal Polynomials","text":"To get a human-readable output of the orthogonal polynomials, there is the function showpoly\n\nIn case you want to see the entire basis, just use showbasis\n\nBoth of these functions make excessive use of","category":"section"},{"location":"functions/#Evaluate-Orthogonal-Polynomials","page":"Functions","title":"Evaluate Orthogonal Polynomials","text":"","category":"section"},{"location":"functions/#Scalar-Products","page":"Functions","title":"Scalar Products","text":"","category":"section"},{"location":"functions/#Quadrature-Rules","page":"Functions","title":"Quadrature Rules","text":"","category":"section"},{"location":"functions/#Polynomial-Chaos","page":"Functions","title":"Polynomial Chaos","text":"","category":"section"},{"location":"functions/#Auxiliary-Functions","page":"Functions","title":"Auxiliary Functions","text":"","category":"section"},{"location":"functions/#PolyChaos.r_scale","page":"Functions","title":"PolyChaos.r_scale","text":"r_scale(c::Real,β::AbstractVector{<:Real},α::AbstractVector{<:Real})\n\nGiven the recursion coefficients (α,β) for a system of orthogonal polynomials that are orthogonal with respect to some positive weight m(t), this function returns the recursion coefficients (α_,β_) for the scaled measure c m(t) for some positive c.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.rm_compute","page":"Functions","title":"PolyChaos.rm_compute","text":"rm_compute(weight::Function,lb::Real,ub::Real,Npoly::Int=4,Nquad::Int=10;quadrature::Function=clenshaw_curtis)\n\nGiven a positive weight function with domain (lb,ub), i.e. a function w lb ub  rightarrow mathbbR_geq 0, this function creates Npoly recursion coefficients (α,β).\n\nThe keyword quadrature specifies what quadrature rule is being used.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.rm_logistic","page":"Functions","title":"PolyChaos.rm_logistic","text":"rm_logistic(N::Int)\n\nCreates N recurrence coefficients for monic polynomials that are orthogonal on (-inftyinfty) relative to w(t) = fracmathrme^-t(1 - mathrme^-t)^2\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.rm_hermite","page":"Functions","title":"PolyChaos.rm_hermite","text":"rm_hermite(N::Int,mu::Real)\nrm_hermite(N::Int)\n\nCreates N recurrence coefficients for monic generalized Hermite polynomials that are orthogonal on (-inftyinfty) relative to w(t) = t^2 mu mathrme^-t^2\n\nThe call rm_hermite(N) is the same as rm_hermite(N,0).\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.rm_hermite_prob","page":"Functions","title":"PolyChaos.rm_hermite_prob","text":"rm_hermite_prob(N::Int)\n\nCreates N recurrence coefficients for monic probabilists' Hermite polynomials that are orthogonal on (-inftyinfty) relative to w(t) = mathrme^-05t^2\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.rm_laguerre","page":"Functions","title":"PolyChaos.rm_laguerre","text":"rm_laguerre(N::Int,a::Real)\nrm_laguerre(N::Int)\n\nCreates N recurrence coefficients for monic generalized Laguerre polynomials that are orthogonal on (0infty) relative to w(t) = t^a mathrme^-t.\n\nThe call rm_laguerre(N) is the same as rm_laguerre(N,0).\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.rm_legendre","page":"Functions","title":"PolyChaos.rm_legendre","text":"rm_legendre(N::Int)\n\nCreates N recurrence coefficients for monic Legendre polynomials that are orthogonal on (-11) relative to w(t) = 1.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.rm_legendre01","page":"Functions","title":"PolyChaos.rm_legendre01","text":"rm_legendre01(N::Int)\n\nCreates N recurrence coefficients for monic Legendre polynomials that are orthogonal on (01) relative to w(t) = 1.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.rm_jacobi","page":"Functions","title":"PolyChaos.rm_jacobi","text":"rm_jacobi(N::Int,a::Real,b::Real)\nrm_jacobi(N::Int,a::Real)\nrm_jacobi(N::Int)\n\nCreates N recurrence coefficients for monic Jacobi polynomials that are orthogonal on (-11) relative to w(t) = (1-t)^a (1+t)^b.\n\nThe call rm_jacobi(N,a) is the same as rm_jacobi(N,a,a) and rm_jacobi(N) the same as rm_jacobi(N,0,0).\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.rm_jacobi01","page":"Functions","title":"PolyChaos.rm_jacobi01","text":"rm_jacobi01(N::Int,a::Real,b::Real)\nrm_jacobi01(N::Int,a::Real)\nrm_jacobi01(N::Int)\n\nCreates N recurrence coefficients for monic Jacobi polynomials that are orthogonal on (01) relative to w(t) = (1-t)^a t^b.\n\nThe call rm_jacobi01(N,a) is the same as rm_jacobi01(N,a,a) and rm_jacobi01(N) the same as rm_jacobi01(N,0,0).\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.rm_meixner_pollaczek","page":"Functions","title":"PolyChaos.rm_meixner_pollaczek","text":"rm_meixner_pollaczek(N::Int,lambda::Real,phi::Real)\nrm_meixner_pollaczek(N::Int,lambda::Real)\n\nCreates N recurrence coefficients for monic Meixner-Pollaczek polynomials with parameters λ and ϕ. These are orthogonal on -inftyinfty relative to the weight function w(t)=(2 pi)^-1 exp(2 phi-pi)t Gamma(lambda+ i t)^2.\n\nThe call rm_meixner_pollaczek(n,lambda) is the same as rm_meixner_pollaczek(n,lambda,pi/2).\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.stieltjes","page":"Functions","title":"PolyChaos.stieltjes","text":"stieltjes(N::Int,nodes_::AbstractVector{<:Real},weights_::AbstractVector{<:Real};removezeroweights::Bool=true)\n\nStieltjes procedure–-Given the nodes and weights, the function generates the firstN recurrence coefficients of the corresponding discrete orthogonal polynomials.\n\nSet the Boolean removezeroweights to true if zero weights should be removed.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.lanczos","page":"Functions","title":"PolyChaos.lanczos","text":"lanczos(N::Int,nodes::AbstractVector{<:Real},weights::AbstractVector{<:Real};removezeroweights::Bool=true)\n\nLanczos procedure–-given the nodes and weights, the function generates the first N recurrence coefficients of the corresponding discrete orthogonal polynomials.\n\nSet the Boolean removezeroweights to true if zero weights should be removed.\n\nThe script is adapted from the routine RKPW in W.B. Gragg and W.J. Harrod, The numerically stable reconstruction of Jacobi matrices from spectral data, Numer. Math. 44 (1984), 317-335.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.mcdiscretization","page":"Functions","title":"PolyChaos.mcdiscretization","text":"mcdiscretization(N::Int,quads::Vector{},discretemeasure::AbstractMatrix{<:Real}=zeros(0,2);discretization::Function=stieltjes,Nmax::Integer=300,ε::Float64=1e-8,gaussquad::Bool=false)\n\nThis routine returns N recurrence coefficients of the polynomials that are orthogonal relative to a weight function w that is decomposed as a sum of m weights w_i with domains a_ib_i for i=1dotsm,\n\nw(t) = sum_i^m w_i(t) quad textwith  operatornamedom(w_i) = a_i b_i\n\nFor each weight w_i and its domain a_i b_i the function mcdiscretization() expects a quadrature rule of the form nodes::AbstractVector{<:Real}, weights::AbstractVector{<:Real} = myquadi(N::Int) all of which are stacked in the parameter quad quad = [ myquad1, ..., myquadm ] If the weight function has a discrete part (specified by discretemeasure) it is added on to the discretized continuous weight function.\n\nThe function mcdiscretization() performs a sequence of discretizations of the given weight w(t), each discretization being followed by an application of the Stieltjes or Lanczos procedure (keyword discretization in [stieltjes, lanczos]) to produce approximations to the desired recurrence coefficients. The function applies to each subinterval i an N-point quadrature rule (the ith entry of quad) to discretize the weight function w_i on that subinterval. If the procedure converges to within a prescribed accuracy ε before N reaches its maximum allowed value Nmax. If the function does not converge, the function prompts an error message.\n\nThe keyword gaussquad should be set to true if Gauss quadrature rules are available for all m weights w_i(t) with i = 1 dots m.\n\nFor further information, please see W. Gautschi \"Orthogonal Polynomials: Approximation and Computation\", Section 2.2.4.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.showpoly","page":"Functions","title":"PolyChaos.showpoly","text":"showpoly(coeffs::Vector{<:Real};sym::String,digits::Integer)\n\nShow the monic polynomial with coefficients coeffs in a human-readable way. The keyword sym sets the name of the variable, and digits controls the number of shown digits.\n\njulia> using PolyChaos\n\njulia> showpoly([1.2, 2.3, 3.4456])\nx^3 + 3.45x^2 + 2.3x + 1.2\n\njulia> showpoly([1.2, 2.3, 3.4456], sym = \"t\", digits = 2)\nt^3 + 3.45t^2 + 2.3t + 1.2\n\nshowpoly(d::Integer,α::Vector{<:Real},β::Vector{<:Real}; sym::String,digits::Integer)\nshowpoly(d::Range,α::Vector{<:Real},β::Vector{<:Real};sym::String,digits::Integer) where Range <: OrdinalRange\n\nShow the monic polynomial of degree/range d that has the recurrence coefficients α, β.\n\njulia> using PolyChaos\n\njulia> α, β = rm_hermite(10)\n([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.77245, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5])\n\njulia> showpoly(3, α, β)\nx^3 - 1.5x\n\njulia> showpoly(0:2:10, α, β)\n1\nx^2 - 0.5\nx^4 - 3.0x^2 + 0.75\nx^6 - 7.5x^4 + 11.25x^2 - 1.88\nx^8 - 14.0x^6 + 52.5x^4 - 52.5x^2 + 6.56\nx^10 - 22.5x^8 + 157.5x^6 - 393.75x^4 + 295.31x^2 - 29.53\n\nTailored to types from PolyChaos.jl\n\nshowpoly(d::Union{Integer,Range},op::AbstractOrthoPoly;sym::String,digits::Integer) where Range <: OrdinalRange\n\nShow the monic polynomial of degree/range d of an AbstractOrthoPoly.\n\njulia> using PolyChaos\n\njulia> op = GaussOrthoPoly(5);\n\njulia> showpoly(3, op)\nx^3 - 3.0x\n\njulia> showpoly(0:(op.deg), op; sym = \"t\")\n1\nt\nt^2 - 1.0\nt^3 - 3.0t\nt^4 - 6.0t^2 + 3.0\nt^5 - 10.0t^3 + 15.0t\n\nThanks @pfitzseb for providing this functionality.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.showbasis","page":"Functions","title":"PolyChaos.showbasis","text":"showbasis(α::Vector{<:Real},β::Vector{<:Real};sym::String,digits::Integer)\n\nShow all basis polynomials given the recurrence coefficients α, β. The keyword sym sets the name of the variable, and digits controls the number of shown digits.\n\njulia> using PolyChaos\n\njulia> α, β = rm_hermite(5);\n\njulia> showbasis(α, β)\n1\nx\nx^2 - 0.5\nx^3 - 1.5x\nx^4 - 3.0x^2 + 0.75\nx^5 - 5.0x^3 + 3.75x\n\nTailored to types from PolyChaos.jl\n\nshowbasis(op::AbstractOrthoPoly;sym::String,digits::Integer)\n\nShow all basis polynomials of an AbstractOrthoPoly.\n\njulia> using PolyChaos\n\njulia> op = LegendreOrthoPoly(4);\n\njulia> showbasis(op)\n1\nx\nx^2 - 0.33\nx^3 - 0.6x\nx^4 - 0.86x^2 + 0.09\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.rec2coeff","page":"Functions","title":"PolyChaos.rec2coeff","text":"rec2coeff(deg::Int,a::Vector{<:Real},b::Vector{<:Real})\nrec2coeff(a,b) = rec2coeff(length(a),a,b)\n\nGet the coefficients of the orthogonal polynomial of degree up to deg specified by its recurrence coefficients (a,b). The function returns the values c_i^(k) from\n\np_k (t) = t^d + sum_i=0^k-1 c_i t^i\n\nwhere k runs from 1 to deg.\n\nThe call rec2coeff(a,b) outputs all possible recurrence coefficients given (a,b).\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.evaluate","page":"Functions","title":"PolyChaos.evaluate","text":"Univariate\n\nevaluate(n::Int,x::Array{<:Real},a::AbstractVector{<:Real},b::AbstractVector{<:Real})\nevaluate(n::Int,x::Real,a::AbstractVector{<:Real},b::AbstractVector{<:Real})\nevaluate(n::Int,x::AbstractVector{<:Real},op::AbstractOrthoPoly)\nevaluate(n::Int,x::Real,op::AbstractOrthoPoly)\n\nEvaluate the n-th univariate basis polynomial at point(s) x The function is multiple-dispatched to facilitate its use with the composite type AbstractOrthoPoly\n\nIf several basis polynomials (stored in ns) are to be evaluated at points x, then call\n\nevaluate(ns::AbstractVector{<:Int},x::AbstractVector{<:Real},op::AbstractOrthoPoly) = evaluate(ns,x,op.α,op.β)\nevaluate(ns::AbstractVector{<:Int},x::Real,op::AbstractOrthoPoly) = evaluate(ns,[x],op)\n\nIf all basis polynomials are to be evaluated at points x, then call\n\nevaluate(x::AbstractVector{<:Real},op::AbstractOrthoPoly) = evaluate(collect(0:op.deg),x,op)\nevaluate(x::Real,op::AbstractOrthoPoly) = evaluate([x],op)\n\nwhich returns an Array of dimensions (length(x),op.deg+1).\n\nnote: Note\nn is the degree of the univariate basis polynomial\nlength(x) = N, where N is the number of points\n(a,b) are the recursion coefficients\n\nMultivariate\n\nevaluate(n::AbstractVector{<:Int},x::AbstractMatrix{<:Real},a::Vector{<:AbstractVector{<:Real}},b::Vector{<:AbstractVector{<:Real}})\nevaluate(n::AbstractVector{<:Int},x::AbstractVector{<:Real},a::Vector{<:AbstractVector{<:Real}},b::Vector{<:AbstractVector{<:Real}})\nevaluate(n::AbstractVector{<:Int},x::AbstractMatrix{<:Real},op::MultiOrthoPoly)\nevaluate(n::AbstractVector{<:Int},x::AbstractVector{<:Real},op::MultiOrthoPoly)\n\nEvaluate the n-th p-variate basis polynomial at point(s) x The function is multiply dispatched to facilitate its use with the composite type MultiOrthoPoly\n\nIf several basis polynomials are to be evaluated at points x, then call\n\nevaluate(ind::AbstractMatrix{<:Int},x::AbstractMatrix{<:Real},a::Vector{<:AbstractVector{<:Real}},b::Vector{<:AbstractVector{<:Real}})\nevaluate(ind::AbstractMatrix{<:Int},x::AbstractMatrix{<:Real},op::MultiOrthoPoly)\n\nwhere ind is a matrix of multi-indices.\n\nIf all basis polynomials are to be evaluated at points x, then call\n\nevaluate(x::AbstractMatrix{<:Real},mop::MultiOrthoPoly) = evaluate(mop.ind,x,mop)\n\nwhich returns an array of dimensions (mop.dim,size(x,1)).\n\nnote: Note\nn is a multi-index\nlength(n) == p, i.e. a p-variate basis polynomial\nsize(x) = (N,p), where N is the number of points\nsize(a)==size(b)=p.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.computeSP2","page":"Functions","title":"PolyChaos.computeSP2","text":"computeSP2(n::Integer,β::AbstractVector{<:Real})\ncomputeSP2(n::Integer,op::AbstractOrthoPoly) = computeSP2(n,op.β)\ncomputeSP2(op::AbstractOrthoPoly) = computeSP2(op.deg,op.β)\n\nComputes the n regular scalar products aka 2-norms of the orthogonal polynomials, namely\n\nϕ_i^2 = langle phi_iphi_irangle quad forall i in  0dotsn \n\nNotice that only the values of β of the recurrence coefficients (α,β) are required. The computation is based on equation (1.3.7) from Gautschi, W. \"Orthogonal Polynomials: Computation and Approximation\". Whenever there exists an analytical expression for β, this function should be used.\n\nThe function is multiple-dispatched to facilitate its use with AbstractOrthoPoly.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.computeSP","page":"Functions","title":"PolyChaos.computeSP","text":"Univariate\n\ncomputeSP(a::AbstractVector{<:Integer},α::AbstractVector{<:Real},β::AbstractVector{<:Real},nodes::AbstractVector{<:Real},weights::AbstractVector{<:Real};issymmetric::Bool=false)\ncomputeSP(a::AbstractVector{<:Integer},op::AbstractOrthoPoly;issymmetric=issymmetric(op))\n\nMultivariate\n\ncomputeSP( a::AbstractVector{<:Integer},\n           α::AbstractVector{<:AbstractVector{<:Real}},β::AbstractVector{<:AbstractVector{<:Real}},\n           nodes::AbstractVector{<:AbstractVector{<:Real}},weights::AbstractVector{<:AbstractVector{<:Real}},\n           ind::AbstractMatrix{<:Integer};\n           issymmetric::BitArray=falses(length(α)))\ncomputeSP(a::AbstractVector{<:Integer},op::AbstractVector,ind::AbstractMatrix{<:Integer})\ncomputeSP(a::AbstractVector{<:Integer},mOP::MultiOrthoPoly)\n\nComputes the scalar product\n\nlangle phi_a_1phi_a_2cdotsphi_a_n rangle\n\nwhere n = length(a). This requires to provide the recurrence coefficients (α,β) and the quadrature rule (nodes,weights), as well as the multi-index ind. If provided via the keyword issymmetric, symmetry of the weight function is exploited. All computations of the multivariate scalar products resort back to efficient computations of the univariate scalar products. Mathematically, this follows from Fubini's theorem.\n\nThe function is dispatched to facilitate its use with AbstractOrthoPoly and its quadrature rule Quad.\n\nnote: Note\nZero entries of a are removed automatically to simplify computations, which follows fromlangle phi_i phi_j phi_0cdotsphi_0 rangle = langle phi_i phi_j ranglebecause \\phi_0 = 1.It is checked whether enough quadrature points are supplied to solve the integral exactly.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.fejer","page":"Functions","title":"PolyChaos.fejer","text":"fejer(N::Int)\n\nFejer's first quadrature rule.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.fejer2","page":"Functions","title":"PolyChaos.fejer2","text":"fejer2(n::Int)\n\nFejer's second quadrature rule according to Waldvogel, J. Bit Numer Math (2006) 46: 195.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.clenshaw_curtis","page":"Functions","title":"PolyChaos.clenshaw_curtis","text":"clenshaw_curtis(n::Int)\n\nClenshaw-Curtis quadrature according to Waldvogel, J. Bit Numer Math (2006) 46: 195.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.quadgp","page":"Functions","title":"PolyChaos.quadgp","text":"quadgp(weight::Function,lb::Real,ub::Real,N::Int=10;quadrature::Function=clenshaw_curtis,bnd::Float64=Inf)\n\ngeneral purpose quadrature based on Gautschi, \"Orthogonal Polynomials: Computation and Approximation\", Section 2.2.2, pp. 93-95\n\nCompute the N-point quadrature rule for weight with support (lb, ub). The quadrature rule can be specified by the keyword quadrature. The keyword bnd sets the numerical value for infinity.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.gauss","page":"Functions","title":"PolyChaos.gauss","text":"gauss(N::Int,α::AbstractVector{<:Real},β::AbstractVector{<:Real})\ngauss(α::AbstractVector{<:Real},β::AbstractVector{<:Real})\ngauss(N::Int,op::Union{OrthoPoly,AbstractCanonicalOrthoPoly})\ngauss(op::Union{OrthoPoly,AbstractCanonicalOrthoPoly})\n\nGauss quadrature rule, also known as Golub-Welsch algorithm\n\ngauss() generates the N Gauss quadrature nodes and weights for a given weight function. The weight function is represented by the N recurrence coefficients for the monic polynomials orthogonal with respect to the weight function.\n\nnote: Note\nThe function gauss accepts at most N = length(α) - 1 quadrature points, hence providing at most an (length(α) - 1)-point quadrature rule.\n\nnote: Note\nIf no N is provided, then N = length(α) - 1.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.radau","page":"Functions","title":"PolyChaos.radau","text":"radau(N::Int,α::AbstractVector{<:Real},β::AbstractVector{<:Real},end0::Real)\nradau(α::AbstractVector{<:Real},β::AbstractVector{<:Real},end0::Real)\nradau(N::Int,op::Union{OrthoPoly,AbstractCanonicalOrthoPoly},end0::Real)\nradau(op::Union{OrthoPoly,AbstractCanonicalOrthoPoly},end0::Real)\n\nGauss-Radau quadrature rule. Given a weight function encoded by the recurrence coefficients (α,β)for the associated orthogonal polynomials, the function generates the nodes and weights (N+1)-point Gauss-Radau quadrature rule for the weight function having a prescribed node end0 (typically at one of the end points of the support interval of w, or outside thereof).\n\nnote: Note\nThe function radau accepts at most N = length(α) - 2 as an input, hence providing at most an (length(α) - 1)-point quadrature rule.\n\nnote: Note\nReference: OPQ: A MATLAB SUITE OF PROGRAMS FOR GENERATING ORTHOGONAL POLYNOMIALS AND RELATED QUADRATURE RULES by Walter Gautschi\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.lobatto","page":"Functions","title":"PolyChaos.lobatto","text":"lobatto(N::Int,α::AbstractVector{<:Real},β::AbstractVector{<:Real},endl::Real,endr::Real)\nlobatto(α::AbstractVector{<:Real},β::AbstractVector{<:Real},endl::Real,endr::Real)\nlobatto(N::Int,op::Union{OrthoPoly,AbstractCanonicalOrthoPoly},endl::Real,endr::Real)\nlobatto(op::Union{OrthoPoly,AbstractCanonicalOrthoPoly},endl::Real,endr::Real)\n\nGauss-Lobatto quadrature rule. Given a weight function encoded by the recurrence coefficients for the associated orthogonal polynomials, the function generates the nodes and weights of the (N+2)-point Gauss-Lobatto quadrature rule for the weight function, having two prescribed nodes endl, endr (typically the left and right end points of the support interval, or points to the left resp. to the right thereof).\n\nnote: Note\nThe function radau accepts at most N = length(α) - 3 as an input, hence providing at most an (length(α) - 1)-point quadrature rule.\n\nnote: Note\nReference: OPQ: A MATLAB SUITE OF PROGRAMS FOR GENERATING ORTHOGONAL POLYNOMIALS AND RELATED QUADRATURE RULES by Walter Gautschi\n\n\n\n\n\n","category":"function"},{"location":"functions/#Statistics.mean","page":"Functions","title":"Statistics.mean","text":"Univariate\n\nmean(x::AbstractVector,op::AbstractOrthoPoly)\n\nMultivariate\n\nmean(x::AbstractVector,mop::MultiOrthoPoly)\n\ncompute mean of random variable with PCE x\n\n\n\n\n\n","category":"function"},{"location":"functions/#Statistics.var","page":"Functions","title":"Statistics.var","text":"Univariate\n\nvar(x::AbstractVector,op::AbstractOrthoPoly)\nvar(x::AbstractVector,t2::Tensor)\n\nMultivariate\n\nvar(x::AbstractVector,mop::MultiOrthoPoly)\nvar(x::AbstractVector,t2::Tensor)\n\ncompute variance of random variable with PCE x\n\n\n\n\n\n","category":"function"},{"location":"functions/#Statistics.std","page":"Functions","title":"Statistics.std","text":"Univariate\n\nstd(x::AbstractVector,op::AbstractOrthoPoly)\n\nMultivariate\n\nstd(x::AbstractVector,mop::MultiOrthoPoly)\n\ncompute standard deviation of random variable with PCE x\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.sampleMeasure","page":"Functions","title":"PolyChaos.sampleMeasure","text":"Univariate\n\nsampleMeasure(n::Int,name::String,w::Function,dom::Tuple{<:Real,<:Real},symm::Bool,d::Dict;method::String=\"adaptiverejection\")\nsampleMeasure(n::Int,m::Measure;method::String=\"adaptiverejection\")\nsampleMeasure(n::Int,op::AbstractOrthoPoly;method::String=\"adaptiverejection\")\n\nDraw n samples from the measure m described by its\n\nname\nweight function w,\ndomain dom,\nsymmetry property symm,\nand, if applicable, parameters stored in the dictionary d. By default, an adaptive rejection sampling method is used (from AdaptiveRejectionSampling.jl), unless it is a common random variable for which Distributions.jl is used.\n\nThe function is dispatched to accept AbstractOrthoPoly.\n\nMultivariate\n\nsampleMeasure(n::Int,m::ProductMeasure;method::Vector{String}=[\"adaptiverejection\" for i=1:length(m.name)])\nsampleMeasure(n::Int,mop::MultiOrthoPoly;method::Vector{String}=[\"adaptiverejection\" for i=1:length(mop.meas.name)])\n\nMultivariate extension, which provides an array of samples with n rows and as many columns as the multimeasure has univariate measures.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.evaluatePCE","page":"Functions","title":"PolyChaos.evaluatePCE","text":"evaluatePCE(x::AbstractVector{<:Real},ξ::AbstractVector{<:Real},α::AbstractVector{<:Real},β::AbstractVector{<:Real})\n\nEvaluation of polynomial chaos expansion\n\nmathsfx = sum_i=0^L x_i phi_ixi_j\n\nwhere L+1 = length(x) and x_j is the jth sample where j=1dotsm with m = length(ξ).\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.samplePCE","page":"Functions","title":"PolyChaos.samplePCE","text":"Univariate\n\nsamplePCE(n::Int,x::AbstractVector{<:Real},op::AbstractOrthoPoly;method::String=\"adaptiverejection\")\n\nCombines sampleMeasure and evaluatePCE, i.e. it first draws n samples from the measure, then evaluates the PCE for those samples.\n\nMultivariate\n\nsamplePCE(n::Int,x::AbstractVector{<:Real},mop::MultiOrthoPoly;method::Vector{String}=[\"adaptiverejection\" for i=1:length(mop.meas.name)])\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.calculateAffinePCE","page":"Functions","title":"PolyChaos.calculateAffinePCE","text":"calculateAffinePCE(α::AbstractVector{<:Real})\n\nComputes the affine PCE coefficients x_0 and x_1 from recurrence coefficients lpha.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.convert2affinePCE","page":"Functions","title":"PolyChaos.convert2affinePCE","text":"convert2affinePCE(mu::Real, sigma::Real, op::AbstractCanonicalOrthoPoly; kind::String)\n\nComputes the affine PCE coefficients x_0 and x_1 from\n\nX = a_1 + a_2 Xi = x_0 + x_1 phi_1(Xi)\n\nwhere phi_1(t) = t-alpha_0 is the first-order monic basis polynomial.\n\nWorks for subtypes of AbstractCanonicalOrthoPoly. The keyword kind in [\"lbub\", \"μσ\"] specifies whether p1 and p2 have the meaning of lower/upper bounds or mean/standard deviation.\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.nw","page":"Functions","title":"PolyChaos.nw","text":"nw(q::EmptyQuad)\nnw(q::AbstractQuad)\nnw(opq::AbstractOrthoPoly)\nnw(opq::AbstractVector)\nnw(mop::MultiOrthoPoly)\n\nreturns nodes and weights in matrix form\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.coeffs","page":"Functions","title":"PolyChaos.coeffs","text":"coeffs(op::AbstractOrthoPoly)\ncoeffs(op::AbstractVector)\ncoeffs(mop::MultiOrthoPoly)\n\nreturns recurrence coefficients of in matrix form\n\n\n\n\n\n","category":"function"},{"location":"functions/#PolyChaos.integrate","page":"Functions","title":"PolyChaos.integrate","text":"integrate(f::Function,nodes::AbstractVector{<:Real},weights::AbstractVector{<:Real})\nintegrate(f::Function,q::AbstractQuad)\nintegrate(f::Function,opq::AbstractOrthoPoly)\n\nintegrate function f using quadrature rule specified via nodes, weights. For example int_0^1 6x^5 = 1 can be solved as follows:\n\njulia> opq = Uniform01OrthoPoly(3) # a quadrature rule is added by default\n\njulia> integrate(x -> 6x^5, opq)\n0.9999999999999993\n\nnote: Note\n\n\nfunction f is assumed to return a scalar.\ninterval of integration is \"hidden\" in nodes.\n\n\n\n\n\nintegrate(f::Function, mop::MultiOrthoPoly)\n\nIntegrate a multivariate function f using tensor product quadrature from a MultiOrthoPoly. The function f should accept the same number of arguments as there are univariate orthogonal polynomials in mop.\n\nFor product measures, this computes the integral by evaluating f at all combinations of quadrature nodes and weighting by the product of the corresponding univariate weights.\n\nExample\n\nop1 = GaussOrthoPoly(3)\nop2 = Uniform01OrthoPoly(5)\nmop = MultiOrthoPoly([op1, op2], 3)\n\n# Integrate f(x,y) = x*y over the product measure\nintegrate((x, y) -> x * y, mop)\n\n\n\n\n\n","category":"function"},{"location":"functions/#LinearAlgebra.issymmetric","page":"Functions","title":"LinearAlgebra.issymmetric","text":"issymmetric(m::AbstractMeasure)\nissymmetric(op::AbstractOrthoPoly)\n\nIs the measure symmetric (around any point in the domain)?\n\n\n\n\n\n","category":"function"},{"location":"chi_squared_k_greater1/#Chi-squared-Distribution-(k1)","page":"Chi Squared, Several DOFs","title":"Chi-squared Distribution (k1)","text":"","category":"section"},{"location":"chi_squared_k_greater1/#Theory","page":"Chi Squared, Several DOFs","title":"Theory","text":"Given k standard random variables X_i sim mathcalN(01) for i=1dotsk we would like to find the random variable Y = sum_i=1^k X_i^2. The analytic solution is known: Y follows a chi-squared distribution with k degrees of freedom.\n\nUsing polynomial chaos expansion (PCE), the problem can be solved using Galerkin projection. Let phi_k _k=0^n be the monic orthogonal basis relative to the probability density of X = X_1 dots X_k, namely\n\nf_X(x) =  prod_i=1^k frac1sqrt2 pi  exp left( - fracx_i^22 right)\n\nThen, the PCE of X_i is given by\n\nX_i = sum_k=0^n x_ik phi_k\n\nwith\n\nx_i0 = 0 quad x_ii+1 = 1 quad x_il = 0 quad forall l in 1dotsn setminus i+1\n\nTo find the PCE coefficients y_k for Y = sum_k=^n y_k phi_k, we apply Galerkin projection, which leads to\n\ny_m langle phi_m phi_m rangle = sum_i=1^k sum_j_1=0^n sum_j_2=0^n x_ij_1 x_ij_2 langle phi_j_1 phi_j_2 phi_m rangle quad forall m = 0 dots n\n\nHence, knowing the scalars langle phi_m phi_m rangle, and langle phi_j_1 phi_j_2 phi_m rangle, the PCE coefficients y_k can be obtained immediately. From the PCE coefficients, we can get the moments and compare them to the closed-form expressions.\n\nNotice: A maximum degree of 2 suffices to get the exact solution with PCE. In other words, increasing the maximum degree to values greater than 2 introduces nothing but computational overhead (and numerical errors, possibly).","category":"section"},{"location":"chi_squared_k_greater1/#Practice","page":"Chi Squared, Several DOFs","title":"Practice","text":"First, we create a orthogonal basis relative to f_X(x) of degree at most d=2 (degree below).\n\nNotice that we consider a total of Nrec recursion coefficients, and that we also add a quadrature rule by setting addQuadrature = true.\n\nk = 12\nusing PolyChaos\ndegree, Nrec = 2, 20\nopq = GaussOrthoPoly(degree; Nrec = Nrec, addQuadrature = true);\n\nNow let's define a multivariate basis\n\nmop = MultiOrthoPoly([opq for i in 1:k], degree)\n\nNext, we define the PCE for all X_i with i = 1 dots k.\n\nL = dim(mop)\nmu, sig = 0.0, 1.0\nx = [assign2multi(convert2affinePCE(mu, sig, opq), i, mop.ind) for i in 1:k]\n\nWith the orthogonal basis and the quadrature at hand, we can compute the tensors t2 and t3 that store the entries langle phi_m phi_m rangle, and langle phi_j_1 phi_j_2 phi_m rangle, respectively.\n\nt2 = Tensor(2, mop)\nt3 = Tensor(3, mop)\n\nWith the tensors at hand, we can compute the Galerkin projection.\n\nNotice: there are more efficient ways to do this, but let's keep it simple.\n\ny = [sum(x[i][j1] * x[i][j2] * t3.get([j1 - 1, j2 - 1, m - 1]) / t2.get([m - 1, m - 1])\n     for i in 1:k, j1 in 1:L, j2 in 1:L) for m in 1:L]\n\nLet's compare the moments via PCE to the closed-form expressions.\n\nmoms_analytic(k) = [k, sqrt(2k), sqrt(8 / k)]\nfunction myskew(y)\n    e3 = sum(y[i] * y[j] * y[k] * t3.get([i - 1, j - 1, k - 1])\n    for i in 1:L, j in 1:L, k in 1:L)\n    μ = y[1]\n    σ = std(y, mop)\n    (e3 - 3 * μ * σ^2 - μ^3) / (σ^3)\nend\n\nprint(\"Expected value:\\t\\t$(moms_analytic(k)[1]) = $(mean(y,mop))\\n\")\nprint(\"\\t\\t\\terror = $(abs(mean(y,mop)-moms_analytic(k)[1]))\\n\")\nprint(\"Standard deviation:\\t$(moms_analytic(k)[2]) = $(std(y,mop))\\n\")\nprint(\"\\t\\t\\terror = $(moms_analytic(k)[2]-std(y,mop))\\n\")\nprint(\"Skewness:\\t\\t$(moms_analytic(k)[3]) = $(myskew(y))\\n\")\nprint(\"\\t\\t\\terror = $(moms_analytic(k)[3]-myskew(y))\\n\")\n\nLet's plot the probability density function to compare results. We first draw samples from the measure with the help of sampleMeasure(), and then evaluate the basis at these samples and multiply times the PCE coefficients. The latter stop is done using evaluatePCE(). Both steps are combined in the function samplePCE(). Finally, we compare the result against the analytical PDF rho(t) = fract^t2-1mathrme^-t22^k2  Gamma(k2) of the chi-squared distribution with one degree of freedom.\n\nusing Plots\nNsmpl = 10000\n# long way: ξ = sampleMeasure(Nsmpl,mop), ysmpl = evaluatePCE(y,ξ,mop)\nysmpl = samplePCE(Nsmpl, y, mop)\nhistogram(ysmpl; normalize = true, xlabel = \"t\", ylabel = \"rho(t)\")\n\nimport SpecialFunctions: gamma\nρ(t) = 1 / (2^(0.5 * k) * gamma(0.5 * k)) * t^(0.5 * k - 1) * exp(-0.5 * t)\nt = range(0.1; stop = maximum(ysmpl), length = 100)\nplot!(t, ρ.(t), w = 4)","category":"section"},{"location":"chi_squared_k1/#Chi-squared-Distribution-(k1)","page":"Chi Squared, One DOF","title":"Chi-squared Distribution (k=1)","text":"","category":"section"},{"location":"chi_squared_k1/#Theory","page":"Chi Squared, One DOF","title":"Theory","text":"Given a standard random variable X sim mathcalN(01) we would like to find the random variable Y = X^2. The analytic solution is known: Y follows a chi-squared distribution with k=1 degree of freedom.\n\nUsing polynomial chaos expansion (PCE), the problem can be solved using Galerkin projection. Let phi_k _k=0^n be the monic orthogonal basis relative to the probability density of X, namely\n\nf_X(x) = frac1sqrt2 pi exp left( - fracx^22 right)\n\nThen, the PCE of X is given by\n\nX = sum_k=0^n x_k phi_k\n\nwith\n\nx_0 = 0 quad x_1 = 1 quad x_i = 0 quad forall i =2dotsn\n\nTo find the PCE coefficients y_k for Y = sum_k=^n y_k phi_k, we apply Galerkin projection, which leads to\n\ny_m langle phi_m phi_m rangle = sum_i=0^n sum_j=0^n x_i x_j langle phi_i phi_j phi_m rangle quad forall m = 0 dots n\n\nHence, knowing the scalars langle phi_m phi_m rangle, and langle phi_i phi_j phi_m rangle, the PCE coefficients y_k can be obtained immediately. From the PCE coefficients, we can get the moments and compare them to the closed-form expressions.\n\nNotice: A maximum degree of 2 suffices to get the exact solution with PCE. In other words, increasing the maximum degree to values greater than 2 introduces nothing but computational overhead (and numerical errors, possibly).","category":"section"},{"location":"chi_squared_k1/#Practice","page":"Chi Squared, One DOF","title":"Practice","text":"First, we create a orthogonal basis relative to f_X(x) of degree at most d=2 (deg below).\n\nNotice that we consider a total of Nrec recursion coefficients, and that we also add a quadrature rule by setting addQuadrature = true.\n\nusing PolyChaos\nk = 1\ndeg, Nrec = 2, 20\nopq = GaussOrthoPoly(deg; Nrec = Nrec, addQuadrature = true);\n\nWhat are the basis polynomials?\n\nshowbasis(opq; sym = \"ξ\")\n\nNote that the command showbasis is based on the more general showpoly:\n\nshowpoly(0:2:deg, opq)\n\nNext, we define the PCE for X.\n\nL = dim(opq)\nmu, sig = 0.0, 1.0\nx = [convert2affinePCE(mu, sig, opq); zeros(Float64, L - 2)]\n\nWith the orthogonal basis and the quadrature at hand, we can compute the tensors t2 and t3 that store the entries langle phi_m phi_m rangle, and langle phi_i phi_j phi_m rangle, respectively.\n\nt2 = Tensor(2, opq);\nt3 = Tensor(3, opq)\n\nWith the tensors at hand, we can compute the Galerkin projection.\n\ny = [sum(x[i] * x[j] * t3.get([i - 1, j - 1, m - 1]) / t2.get([m - 1, m - 1])\n     for i in 1:L, j in 1:L) for m in 1:L]\n\nLet's compare the moments via PCE to the closed-form expressions.\n\nmoms_analytic(k) = [k, sqrt(2k), sqrt(8 / k)]\nfunction myskew(y)\n    e3 = sum(y[i] * y[j] * y[k] * t3.get([i - 1, j - 1, k - 1])\n    for i in 1:L, j in 1:L, k in 1:L)\n    μ = y[1]\n    σ = std(y, opq)\n    (e3 - 3 * μ * σ^2 - μ^3) / (σ^3)\nend\n\nprint(\"Expected value:\\t\\t$(moms_analytic(k)[1]) = $(mean(y,opq))\\n\")\nprint(\"\\t\\t\\terror = $(abs(mean(y,opq)-moms_analytic(k)[1]))\\n\")\nprint(\"Standard deviation:\\t$(moms_analytic(k)[2]) = $(std(y,opq))\\n\")\nprint(\"\\t\\t\\terror = $(moms_analytic(k)[2]-std(y,opq))\\n\")\nprint(\"Skewness:\\t\\t$(moms_analytic(k)[3]) = $(myskew(y))\\n\")\nprint(\"\\t\\t\\terror = $(moms_analytic(k)[3]-myskew(y))\\n\")\n\nLet's plot the probability density function to compare results. We first draw samples from the measure with the help of sampleMeasure(), and then evaluate the basis at these samples and multiply times the PCE coefficients. The latter stop is done using evaluatePCE(). Finally, we compare the result against the analytical PDF rho(t) = fracmathrme^-05tsqrt2 t  Gamma(05) of the chi-squared distribution with one degree of freedom.\n\nusing Plots\nNsmpl = 10000\n# long way: ξ = sampleMeasure(Nsmpl,opq), ysmpl = evaluatePCE(y,ξ,opq)\nysmpl = samplePCE(Nsmpl, y, opq)\nhistogram(ysmpl; normalize = true, xlabel = \"t\", ylabel = \"rho(t)\")\n\nimport SpecialFunctions: gamma\nρ(t) = 1 / (sqrt(2) * gamma(0.5)) * 1 / sqrt(t) * exp(-0.5 * t)\nt = range(0.1; stop = maximum(ysmpl), length = 100)\nplot!(t, ρ.(t), w = 4)","category":"section"},{"location":"scalar_products/#ComputationOfScalarProducts","page":"Computation of Scalar Products","title":"Computation of Scalar Products","text":"By now, we are able to construct orthogonal polynomials, and to construct quadrature rules for a given nonnegative weight function, respectively. Now we combine both ideas to solve integrals involving the orthogonal polynomials\n\nlangle phi_i_1 phi_i_2 cdots phi_i_m-1 phi_i_m rangle\n= int phi_i_1(t) phi_i_2(t) cdots phi_i_m-1(t) phi_i_m(t) w(t) mathrmd t\n\nboth for the univariate and multivariate case. The integrand is a polynomial (possibly multivariate) that can be solved exactly with the appropriate Gauss quadrature rules.\n\nnote: Note\nTo simplify notation, we drop the integration interval. It is clear from the context.","category":"section"},{"location":"scalar_products/#Univariate-Polynomials","page":"Computation of Scalar Products","title":"Univariate Polynomials","text":"","category":"section"},{"location":"scalar_products/#Classical-Polynomials","page":"Computation of Scalar Products","title":"Classical Polynomials","text":"Let's begin with a univariate basis for some classical orthogonal polynomial\n\nusing PolyChaos\ndeg, n = 4, 20\ns_α, s_β = 2.1, 3.2\nopq = Beta01OrthoPoly(deg, s_α, s_β; Nrec = n, addQuadrature = true)\n\nBy setting addQuadrature = true (which is default), an n-point Gauss quadrature rule is created relative to the underlying measure opq.measure, where n is the number of recurrence coefficients stored in opq.α and opq.β.\n\nTo compute the squared norms\n\n phi_k ^2 = langle phi_k phi_k  rangle\n= int phi_k(t) phi_k(t) w(t) mathrmd t\n\nof the basis we call computeSP2()\n\nnormsq = computeSP2(opq)\n\nFor the general case\n\nlangle phi_i_1 phi_i_2 cdots phi_i_m-1 phi_i_m rangle\n= int phi_i_1(t) phi_i_2(t) cdots phi_i_m-1(t) phi_i_m(t) w(t) mathrmd t\n\nthere exists a type Tensor that requires only two arguments: the dimension m geq 1, and an AbstractOrthoPoly\n\nm = 3\nt = Tensor(3, opq)\n\nTo get the desired entries, Tensor comes with a get() function that is called for some index a in mathbbN_0^m that has the entries a = i_1 i_2 dots i_m. For example\n\nt.get([1, 2, 3])\n\nOr using comprehension\n\nT = [t.get([i1, i2, i3])\n     for i1 in 0:(dim(opq) - 1), i2 in 0:(dim(opq) - 1), i3 in 0:(dim(opq) - 1)]\n\nNotice that we can cross-check the results.\n\nusing LinearAlgebra\nnormsq == diag(T[:, :, 1]) == diag(T[:, 1, :]) == diag(T[1, :, :])\n\nAlso, normsq can be computed analogously in Tensor format\n\nt2 = Tensor(2, opq)\nnormsq == [t2.get([i, i]) for i in 0:(dim(opq) - 1)]","category":"section"},{"location":"scalar_products/#Arbitrary-Weights","page":"Computation of Scalar Products","title":"Arbitrary Weights","text":"Of course, the type OrthoPoly can be constructed for arbitrary weights w(t). In this case, we have to compute the orthogonal basis and the respective quadrature rule. Let's re-work the above example manually.\n\nusing SpecialFunctions\nsupp = (0, 1)\nw(t) = (t^(s_α - 1) * (1 - t)^(s_β - 1) / SpecialFunctions.beta(s_α, s_β))\nmy_meas = Measure(\"my_meas\", w, supp, false)\nmy_opq = OrthoPoly(\"my_op\", deg, my_meas; Nrec = n, addQuadrature = true)\n\nNow we can compute the squared norms  phi_k ^2\n\nmy_normsq = computeSP2(my_opq)\n\nAnd the tensor\n\nmy_t = Tensor(m, my_opq)\nmy_T = [my_t.get([i1, i2, i3])\n        for i1 in 0:(dim(opq) - 1), i2 in 0:(dim(opq) - 1), i3 in 0:(dim(opq) - 1)]\n\nLet's compare the results:\n\nabs.(normsq - my_normsq)\n\nnorm(T - my_T)\n\nnote: Note\nThe possibility to create quadrature rules for arbitrary weights should be reserved to cases different from classical ones.","category":"section"},{"location":"scalar_products/#Multivariate-Polynomials","page":"Computation of Scalar Products","title":"Multivariate Polynomials","text":"For multivariate polynomials, the syntax for Tensor is very much alike, except that we are dealing with the type MultiOrthoPoly now.\n\nmop = MultiOrthoPoly([opq, my_opq], deg)\n\nmt2 = Tensor(2, mop)\nmt3 = Tensor(3, mop)\nmT2 = [mt2.get([i, i]) for i in 0:(dim(mop) - 1)]\n\nNotice that mT2 carries the elements of the 2-dimensional tensors for the univariate bases opq and my_opq. The encoding is given by the multi-index mop.ind\n\nmop.ind\n\nTo cross-check the results, we can distribute the multi-index back to its univariate indices with the help of findUnivariateIndices.\n\nind_opq = findUnivariateIndices(1, mop.ind)\nind_my_opq = findUnivariateIndices(2, mop.ind)\n\nmT2[ind_opq] - normsq\n\nmT2[ind_my_opq] - my_normsq","category":"section"},{"location":"random_ode/#Galerkin-based-Solution-of-Random-Differential-Equation","page":"Random ODE","title":"Galerkin-based Solution of Random Differential Equation","text":"This tutorial demonstrates how random differential equations can be solved using polynomial chaos expansions (PCE).","category":"section"},{"location":"random_ode/#Theory","page":"Random ODE","title":"Theory","text":"A random differential equation is an ordinary differential equation that has random parameters, hence its solution is itself a (time-varying) random variable. Perhaps the simplest non-trivial example is the following scalar, linear ordinary differential equation\n\ndotx(t) = a x(t) quad x(0) = x_0\n\nwhere a is the realization of a Gaussian random variable mathsfa sim mathcalN(mu sigma^2) with mean mu and variance sigma^2. Arguably, for every realization a we can solve the differential equation and obtain\n\nx(t) = x_0 mathrme^a t\n\nfrom which we find that\n\nln (x(t)) = ln (x_0) + at sim mathcalN(ln(x_0) + mu t (sigma t)^2)\n\nIn other words, the logarithm of the solution is normally distributed (so-called log-normal distribution).\n\nWe'd like to obtain this result numerically with the help of PCE. The first step is to define the (truncated) PCE for the random variable mathsfa\n\nmathsfa = sum_i=0^L a_i phi_i\n\nwhere a_i are the so-called PCE coefficients, and phi_i are the orthogonal basis polynomials. As the solution to the random differential equation is itself a random variable, we treat x(t) as the realization of the random variable mathsfx(t), and define its PCE\n\nmathsfx(t) = sum_i=0^L x_i(t) phi_i\n\nThe question is how to obtain the unknown PCE coefficients x_i(t) from the known PCE coefficients a_i relative to the orthogonal basis polynomials phi_i. This can be done using Galerkin projection, which is nothing else than projecting onto the orthogonal basis. Think of a three-dimensional space, in which you have placed some three-dimensional object. If you know project the silhouette of the object onto every axis of the three-dimensional space, then you are doing a Galerkin projection. With PCE the concept is equivalent, but the imagination has a harder time. The first step for Galerkin projection is to insert the PCEs\n\nsum_i=0^L dotx_i(t) phi_i = sum_j=0^L a_j phi_j sum_k=0^L x_k(t) phi_k\n\nthe second step is to project onto every basis polynomial phi_m for m = 0 1 dots L, and to exploit orthogonality of the basis. This gives\n\ndotx_m(t) langle phi_m phi_m rangle = sum_j=0^L sum_k=0^L a_j x_k(t) langle phi_l phi_k phi_m rangle quad m = 0 1 dots L\n\nOf course, the initial condition must not be forgotten:\n\nx_0(0) = x_0 quad x_m(0) = 0 quad m = 1 dots L\n\nIf we can solve this enlarged system of ordinary random differential equations, we can reconstruct the analytic solution.","category":"section"},{"location":"random_ode/#Practice","page":"Random ODE","title":"Practice","text":"We begin by defining the random differential equation\n\nx0 = 2.0\nμ, σ = -0.5, 0.05\ntend, Δt = 3.0, 0.01\n\nNext, we define an orthogonal basis (and its quadrature rule) relative to the Gaussian measure using PolyChaos. We choose a maximum degree of L.\n\nusing PolyChaos\nL, Nrec = 6, 40\nopq = GaussOrthoPoly(L; Nrec = Nrec, addQuadrature = true)\n\nNow we can define the PCE for mathsfa and solve the Galerkin-projected ordinary differential equation using DifferentialEquations.jl.\n\nusing DifferentialEquations\n\na = [convert2affinePCE(μ, σ, opq); zeros(Float64, L - 1)] # PCE coefficients of a\nxinit = [x0; zeros(Float64, L)] # PCE coefficients of initial condition\n\nt2 = Tensor(2, opq); # \\langle \\phi_i, \\phi_j \\rangle\nt3 = Tensor(3, opq); # \\langle \\phi_i \\phi_j, \\phi_k \\rangle\n\n# Galerkin-projected random differential equation\nfunction ODEgalerkin(du, u, p, t)\n    du[:] = [sum(p[j + 1] * u[k + 1] * t3.get([j, k, m]) / t2.get([m, m]) for j in 0:L\n             for k in 0:L) for m in 0:L]\nend\n\nprobgalerkin = ODEProblem(ODEgalerkin, xinit, (0, tend), a)\nsolgalerkin = solve(probgalerkin; saveat = 0:Δt:tend)\nt, x = solgalerkin.t, solgalerkin.u;\n\nFor later purposes, we compute the expected value and the standard deviation at all time instants using PCE.\n\n# an advantage of PCE is that moments can be computed from the PCE coefficients alone; no sampling required\nmean_pce = [mean(x_, opq) for x_ in x]\nstd_pce = [std(x_, opq) for x_ in x]\n\nWe compare the solution from PCE to a Monte-Carlo-based solution. That means to solve the ordinary differential equation for many samples of mathsfa. We first sample from the measure using sampleMeasure, and then generate samples of mathsfa using evaluatePCE. After that, we solve the ODE and store the results in xmc.\n\nusing Statistics\nNsmpl = 5000\nξ = sampleMeasure(Nsmpl, opq)     # sample from Gaussian measure; effectively randn() here    \nasmpl = evaluatePCE(a, ξ, opq)     # sample random variable with PCE coefficients a; effectively μ + σ*randn() here\n# or: asmpl = samplePCE(Nsmpl,a,opq)\nxmc = [solve(ODEProblem((u, p, t) -> aa * u, x0, (0, tend)); saveat = 0:Δt:tend).u\n       for aa in asmpl]\nxmc = hcat(xmc...);\n\nNow we can compare the Monte Carlo mean and standard deviation to the expression from PCE for every time instant.\n\n[mean(xmc, dims = 2) - mean_pce std(xmc, dims = 2) - std_pce]\n\nClearly, the accuracy of PCE deteriorates over time. Possible remedies are to increase the dimension of PCE, and to tweak the tolerances of the integrator.\n\nFinally, we compare whether the samples follow a log-normal distribution, and compare the result to the analytic mean and standard deviation.\n\nlogx_pce = [log.(evaluatePCE(x_, ξ, opq)) for x_ in x]\n[mean.(logx_pce) - (log(x0) .+ μ * t) std.(logx_pce) - σ * t]","category":"section"},{"location":"gaussian_mixture_model/#Gaussian-Mixture-Models","page":"Gaussian Mixture Models","title":"Gaussian Mixture Models","text":"Gaussian mixture models are popular for clustering data. Generally speaking, they are continuous random variables with a special probability density, namely\n\nrho(x) = sum_i = 1^n fracw_isqrt2 pi sigma_i^2 exp left( frac(x - mu_i)^22 sigma_i^2 right) quad textwith quad sum_i = 1^n w_i = 1\n\nwhere the pairs of means and standard deviations (mu_i sigma_i), and the weights w_i for all i in  1 dots n  are given. Let's consider a simple example.\n\nusing Plots\nf(x, μ, σ) = 1 / sqrt(2 * π * σ^2) * exp(-(x - μ)^2 / (2σ^2))\nμs, σs, ws = [1.0, 1.7], [0.2, 0.3], [0.5, 0.5]\nρ(x) = sum(w * f(x, μ, σ) for (μ, σ, w) in zip(μs, σs, ws))\nx = 0:0.01:3;\nplot(x, ρ.(x))\nxlabel!(\"x\");\nylabel!(\"rho(x)\");\n\nThis looks nice!\n\nWhat are now the polynomials that are orthogonal relative to this specific density?\n\nusing PolyChaos\ndeg = 4\nmeas = Measure(\"my_GaussMixture\", ρ, (-Inf, Inf), false, Dict(:μ => μ, :σ => σ)) # build measure\nop = OrthoPoly(\"my_op\", deg, meas; Nquad = 100, Nrec = 2 * deg) # construct orthogonal polynomial\nshowbasis(op, digits = 2) # in case you wondered\n\nLet's add the quadrature rule and compute the square norms of the basis polynomials.\n\nT2 = Tensor(2, op) # compute scalar products\n[T2.get([i, j]) for i in 0:deg, j in 0:deg]\n\nGreat!","category":"section"},{"location":"numerical_integration/#NumericalIntegration","page":"Numerical Integration","title":"Numerical Integration","text":"The goal of this tutorial is to solve an integral using Gauss quadrature,\n\nI = int_0^1 f(t) mathrmd t approx sum_k=1^n w_k f(t_k)\n\nwhere we choose f(t) = sin(t), and n = 5.\n\nMake sure to check out this tutorial too.","category":"section"},{"location":"numerical_integration/#Variant-0","page":"Numerical Integration","title":"Variant 0","text":"julia> using PolyChaos\n\njulia> n = 5;\n\njulia> f(t) = sin(t);\n\njulia> op = Uniform01OrthoPoly(n, addQuadrature = true);\n\njulia> variant0 = integrate(f, op)\n0.4596976941320484\n\njulia> print(\"Numerical error: $(abs(1 - cos(1) - variant0))\")\nNumerical error: 1.8868240303504535e-13\n\nwith negligible numerical errors.","category":"section"},{"location":"numerical_integration/#Variant-1","page":"Numerical Integration","title":"Variant 1","text":"Let us  now solve the same problem, while elaborating what is going on under the hood. At first, we load the package by calling\n\nusing PolyChaos\n\nNow we define a measure, specifically the uniform measure mathrmdlambda(t) = w(t) mathrmd t with the weight w defined as\n\n  w mathcalW = 01 rightarrow mathbbR quad w(t) = 1\n\nThis measure can be defined using the composite type Uniform01Measure:\n\njulia> measure = Uniform01Measure()\nUniform01Measure(PolyChaos.w_uniform01, (0.0, 1.0), true)\n\nNext, we need to compute the quadrature rule relative to the uniform measure. To do this, we use the composite type Quad.\n\njulia> quadRule1 = Quad(n - 1, measure)\n┌ Warning: For measures of type Uniform01Measure the quadrature rule should be based on the recurrence coefficients.\n└ @ PolyChaos ~/Documents/Code/JuliaDev/PolyChaos/src/typesQuad.jl:58\nQuad{Float64,Array{Float64,1}}(\"quadgp\", 4, [1.0, 0.8535533905932737, 0.5, 0.14644660940672627, 0.0], [0.033333333333333354, 0.26666666666666666, 0.4, 0.26666666666666666, 0.033333333333333354])\n\njulia> nw(quadRule1)\n5×2 Array{Float64,2}:\n 1.0       0.0333333\n 0.853553  0.266667 \n 0.5       0.4      \n 0.146447  0.266667 \n 0.0       0.0333333\n\nThis creates a quadrature rule quadRule_1 relative to the measure measure. The function nw() prints the nodes and weights. To solve the integral, we call integrate()\n\njulia> variant1 = integrate(f, quadRule1)\n0.4596977927043755\n\njulia> print(\"Numerical error: $(abs(1 - cos(1) - variant1))\")\nNumerical error: 9.857251526135258e-8","category":"section"},{"location":"numerical_integration/#Revisiting-Variant-0","page":"Numerical Integration","title":"Revisiting Variant 0","text":"Why is the error from variant 0 so much smaller? It's because the quadrature rule for variant 0 is based on the recurrence coefficients of the polynomials that are orthogonal relative to the measure measure. Let's take a closer look First, we compute the orthogonal polynomials using the composite type OrthoPoly, and we set the keyword addQuadrature to false.\n\njulia> op = Uniform01OrthoPoly(n, addQuadrature = false)\nUniform01OrthoPoly{Array{Float64,1},Uniform01Measure,EmptyQuad{Float64}}(5, [0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [1.0, 0.08333333333333333, 0.06666666666666667, 0.06428571428571428, 0.06349206349206349, 0.06313131313131314], Uniform01Measure(PolyChaos.w_uniform01, (0.0, 1.0), true), EmptyQuad{Float64}())\n\nNote how op has a field EmptyQuad, i.e. we computed no quadrature rule. The resulting system of orthogonal polynomials is characterized by its recursion coefficients (alpha beta), which can be extracted with the function coeffs().\n\njulia> coeffs(op)\n6×2 Array{Float64,2}:\n 0.5  1.0      \n 0.5  0.0833333\n 0.5  0.0666667\n 0.5  0.0642857\n 0.5  0.0634921\n 0.5  0.0631313\n\nNow, the quadrature rule can be constructed based on op, and the integral to be solved.\n\njulia> quadRule2 = Quad(n, op)\nQuad{Float64,Array{Float64,1}}(\"golubwelsch\", 5, [0.046910077030667935, 0.23076534494715842, 0.49999999999999994, 0.7692346550528418, 0.9530899229693321], [0.11846344252809445, 0.23931433524968332, 0.28444444444444444, 0.23931433524968337, 0.1184634425280949])\n\njulia> nw(quadRule2)\n5×2 Array{Float64,2}:\n 0.0469101  0.118463\n 0.230765   0.239314\n 0.5        0.284444\n 0.769235   0.239314\n 0.95309    0.118463\n\njulia> variant0_revisited = integrate(f, quadRule2)\n0.4596976941320484\n\njulia> print(\"Numerical error: $(abs(1 - cos(1) - variant0_revisited))\")\nNumerical error: 1.8818280267396403e-13","category":"section"},{"location":"numerical_integration/#Comparison","page":"Numerical Integration","title":"Comparison","text":"We see that the different variants provide slightly different results:\n\njulia> 1 - cos(1) .- [variant0 variant1 variant0_revisited]\n1×3 Array{Float64,2}:\n -1.88183e-13  -9.85725e-8  -1.88183e-13\n\nwith variant0 and variant0_revisited being the same and more accurate than variant1. The increased accuracy is based on the fact that for variant0 and variant0_revisited the quadrature rules are based on the recursion coefficients of the underlying orthogonal polynomials. The quadrature for variant1 is based on a general-purpose method that can be significantly less accurate, see also the next tutorial.","category":"section"},{"location":"math/#MathematicalBackground","page":"Mathematical Background","title":"Mathematical Background","text":"This section is heavily based on the book \"Orthogonal Polynomials: Computation and Approximation\" by Walter Gautschi (Oxford University Press)","category":"section"},{"location":"math/#Orthogonal-Polynomials","page":"Mathematical Background","title":"Orthogonal Polynomials","text":"","category":"section"},{"location":"math/#Basic-Theory","page":"Mathematical Background","title":"Basic Theory","text":"We always work with absolutely continuous measures for which we write mathrmd lambda (t) = w(t) mathrmdt, where the so-called weight function w\n\nis a nonnegative integrable function on the real line mathbbR, i.e. w mathcalW subseteq mathbbR rightarrow mathbbR_geq 0\nhas finite limits in case mathcalW = mathbbR, i.e.\n\nlim_t to pm infty w(t)  infty\n\nhas finite moments of all orders\n\nmu_r(mathrmdlambda) = int_mathcalW t^r mathrmd lambda (t) quad r = 0 1 2 dots quad textwith mu_0  0\n\nFor any pair of integrable functions u v, their scalar product relative to mathrmd lambda is defined as\n\nlangle u v rangle_mathrmd lambda = int_mathcalW u(t) v(t) mathrmd lambda(t)\n\nLet mathcalP be the set of real polynomials and mathcalP_d subset mathcalP be the set of real polynomials of degree at most d on mathcalW, respectively. Monic real polynomials are real polynomials with leading coefficient equal to one, i.e. pi_k(t) = t^k + dots for k = 0 1 dots\n\nThe polynomials uv in mathcalP with u neq v are said to be orthogonal if\n\nlangle u v rangle_mathrmd lambda = int_mathcalW u(t) v(t) mathrmd lambda(t) = 0\n\nThe norm of u is given by\n\n u _ mathrmdlambda = sqrtlangle u u rangle\n\nIf the polynomials u in mathcalP has unit length  u _ mathrmdlambda = 1, it is called orthonormal.\n\nMonic orthogonal polynomials are polynomials that are monic and orthogonal, hence satisfy\n\npi_k(t) = pi_k(t mathrmd lambda) = t^k + dots\nfor k = 0 1 dots, and\nlangle pi_k pi_l rangle_mathrmdlambda = 0\nfor k neq l and k l = 0 1 dots, and langle pi_k pi_k rangle_mathrmdlambda =  pi_k ^2_ mathrmdlambda  0 for k = 0 1 dots.\n\nnote: Note\nThe support mathcalW of mathrmd lambda can be an interval (finite, half-finite, infinite), or a finite number of disjoint intervals. If the support consists of a finite or denumerably infinite number of distinct points t_k at which lambda has positive jumps w_k, the measure is called a discrete measure. For a finite number N of points, the discrete measure is denoted by mathrmdlambda_N, and it is characterized by its nodes and weights  t_k w_k _k=1^N according tomathrmd lambda_N (t) = sum_k=1^N w_k delta(t-t_k)where delta is the delta-function.The inner product associated with mathrmd lambda_N islangle u v rangle_mathrmdlambda_N = int_mathcalW u(t) v(t) mathrmd lambda_N (t) = sum_k=1^N w_k u(t_k) v(t_k)There exist only N orthogonal polynomials  pi_k(mathrmd lambda_N) _k=0^N-1 that are orthogonal relative to the discrete measure mathrmd lambda_N in the senselangle pi_k(mathrmd lambda_N) pi_l(mathrmd lambda_N) rangle_mathrmdlambda_N =  pi_k(mathrmd lambda_N) _mathrmd lambda_N delta_klwhere delta_kl is the Dirac-delta, for kl = 0 1 dots N-1.","category":"section"},{"location":"math/#Properties","page":"Mathematical Background","title":"Properties","text":"","category":"section"},{"location":"math/#Symmetry","page":"Mathematical Background","title":"Symmetry","text":"An absolutely continuous measure mathrmd lambda(t) = w(t) mathrmd t is symmetric (with respect to the origin) if its support is mathcalW = -aa for some 0  a leq infty, and if w(-t) = w(t) for all t in mathcalW.\n\nSimilarly, a discrete measure mathrmd lambda_N (t) = sum_k=1^N w_k delta(t-t_k) is symmetric if t_k = - t_N+1-k, and w_k = w_N+1-k for k=1 2 dots N.\n\nTheorem 1.17 states that: If mathrmd lambda is symmetric, then\n\npi_k(-t mathrmd lambda) = (-1)^k pi_k(t mathrmd lambda) quad k=01 dots\n\nhence, the parity of k decides whether pi_k is even/odd.\n\nnote: Note\nSymmetry is exploited in computeSP, where symmetry need not be relative to the origin, but some arbitrary point of the support.","category":"section"},{"location":"math/#Three-term-Recurrence-Relation","page":"Mathematical Background","title":"Three-term Recurrence Relation","text":"The fact that orthogonal polynomials can be represented in terms of a three-term recurrence formula is at the heart of all numerical methods of the package. The importance of the three-term recurrence relation is difficult to overestimate. It provides\n\nefficient means of evaluating polynomials (and derivatives),\nzeros of orthogonal polynomials by means of the eigenvalues of a symmetric, tridiagonal matrix\naccess to quadrature rules,\nnormalization constants to create orthonormal polynomials.\n\nTheorem 1.27 states:\n\nLet pi_k(cdot) = pi_k(cdot mathrmdlambda) for k = 0 1 dots be the monic orthogonal polynomials with respect to the measure mathrmd lambda. Then\n\nbeginaligned\npi_k+1(t) = (t - alpha_k) pi_k(t) - beta_k pi_k-1(t) quad k= 0 1 dots \npi_o(t) = 1 \npi_-1(t) = 0\nendaligned\n\nwhere\n\nbeginaligned\nalpha = alpha_k(mathrmd lambda) = fraclangle t pi_k pi_k rangle_mathrmd lambdalangle pi_k pi_k rangle_mathrmd lambda  k=012 dots \nbeta = beta_k(mathrmd lambda) = fraclangle pi_k pi_k rangle_mathrmd lambdalangle pi_k-1 pi_k-1 rangle_mathrmd lambda  k=12dots\nendaligned\n\nLet tildepi_k(cdot) = tildepi_k(cdot mathrmd lambda t) denote the orthonormal polynomials, then\n\nbeginaligned\nsqrtbeta_k+1 tildepi_k(t) = (t - alpha_k) tildepi_k(t) - sqrtbeta_k tildepi_k-1(t) quad k = 0 1 dots \ntildepi_0(t) = 1 \ntildepi_-1(t) = 0\nendaligned\n\nnote: Note\nWithin the package, the coefficients (α,β) are the building block to represent (monic) orthogonal polynomials.\n\nNotice that beta_0 is arbitrary. Nevertheless, it is convenient to define it as\n\nbeta_0(mathrmdlambda) = langle pi_0 pi_0 rangle_mathrmd lambda = int_mathcalW mathrmd lambda (t)\n\nbecause it allows to compute the norms of the polynomials based on beta_k alone\n\n pi_n _mathrmd lambda = beta_n(mathrmd lambda) beta_n-1(mathrmd lambda) cdots beta_0(mathrmd lambda) quad n = 01 dots\n\nLet the support be mathcalW = ab for 0  ab  infty, then\n\nbeginaligned\n a  alpha_k(mathrmd lambda)  b  k = 012 dots \n 0  beta_k(mathrmd lambda)  max(a^2 b^2)  k = 1 2 dots\nendaligned","category":"section"},{"location":"math/#Quadrature-Rules","page":"Mathematical Background","title":"Quadrature Rules","text":"An n-point quadrature rule for the measure mathrmd lambda t is a formula of the form\n\nint_mathcalW f(t) mathrmd lambda(t) = sum_nu = 1^n w_nu f(tau_nu) + R_n(f)\n\nThe quadrature rule  (tau_nu w_nu) _nu=1^n composed of (mutually distinct) nodes tau_nu and weights w_nu provides an approximation to the integral. The respective error is given by R_n(f). If, for polynomials p in mathcalP_d, the error R_n(p) vanishes, the respective quadrature rule is said to have a degree of exactness d. Gauss quadrature rule are special quadrature rules that have a degree of exactness d = 2n - 1. That means, taking a n =3-point quadrature rule, polynomials up to degree 5 can be integrated exactly. The nodes and weights for the Gauss quadrature rules have some remarkable properties:\n\nall Gauss nodes are mutually distinct and contained in the interior of the support of mathrmd lambda;\nthe n Gauss nodes are the zeros of pi_n, the monic orthogonal polynomial of degree n relative to the measure mathrmd lambda;\nall Gauss weights are positive.\n\nThe Gauss nodes and weights can be computed using the Golub-Welsch algorithm. This means to solve an eigenvalue problem of a symmetric tridiagonal matrix.","category":"section"},{"location":"multiple_discretization/#Multiple-Discretization","page":"Multiple Discretization","title":"Multiple Discretization","text":"This tutorial shows how to compute recurrence coefficients for non-trivial weight functions, and how they are being used for quadrature. The method we use is called multiple discretization, and follows W. Gautschi's book \"Orthogonal Polynomials: Computation and Approximation\", specifically Section 2.2.4, and Example 2.38.\n\nSuppose we have the weight function\n\nforall t in -11 gamma in 01 quad w(tgamma) = gamma + (1-gamma) frac1sqrt1-t^2\n\nand we would like to solve\n\nint_-1^1 f(t) w(tc) mathrmdt = sum_nu=1^N f(tau_nu) w_nu\n\nby some quadrature rule. We will see that ad-hoc quadrature rules will fail to solve the integral even for the simplest choice f equiv 1. However, finding the recurrence coefficients of the underlying orthogonal polynomials, and then finding the quadrature rule will do just fine.\n\nLet us first try to solve the integral for f equiv 1 by Féjer's rule.\n\nusing PolyChaos, LinearAlgebra\nγ = 0.5;\nint_exact = 1 + pi / 2; # exact value of the integral\nfunction my_w(t, γ)\n    γ + (1 - γ) * 1 / sqrt(1 - t^2)\nend\n\nN = 1000;\nnodes, weights = fejer(N);\nint_fejer = dot(weights, my_w.(nodes, γ))\nprint(\"Fejer error:\\t$(abs(int_exact - int_fejer))\\twith $N nodes\")\n\nClearly, that is not satisfying. Well, the term gamma of the weight w makes us think of Gauss-Legendre integration, so let's try it instead.\n\nfunction quad_gaussleg(N, γ)\n    a, b = rm_legendre(N)\n    nodes, weights = golubwelsch(a, b)\nend\nnodes, weights = quad_gaussleg(N + 1, γ)\nint_gaussleg = dot(weights, γ .+ (1 - γ) / sqrt.(1 .- nodes .^ 2))\nprint(\"Gauss-Legendre error:\\t$(abs(int_exact-int_gaussleg))\\twith $N nodes\")\n\nEven worse! Well, we can factor out frac1sqrt1-t^2, making the integral amenable to a Gauss-Chebyshev rule. So, let's give it another try.\n\nfunction quad_gausscheb(N, γ)\n    a, b = rm_chebyshev1(N)\n    nodes, weights = golubwelsch(a, b)\nend\nnodes, weights = quad_gausscheb(N + 1, γ)\nint_gausscheb = dot(weights, γ .+ (1 - γ) * sqrt.(1 .- nodes .^ 2))\n# int=sum(xw(:,2).*(1+sqrt(1-xw(:,1).^2)))\nprint(\"Gauss-Chebyshev error:\\t$(abs(int_exact - int_gausscheb))\\twith $(length(n)) nodes\")\n\nOkay, that's better, but it took us a lot of nodes to get this result. Is there a different way? Indeed, there is. As we have noticed, the weight w has a lot in common with Gauss-Legendre and Gauss-Chebyshev. We can decompose the integral as follows\n\nint_-1^1 f(t) w(t) mathrmdt = sum_i=1^m int_-1^1 f(t) w_i(t) mathrmd t\n\nwith\n\nbeginalign*\nw_1(t) = gamma \nw_2(t) = (1-gamma) frac1sqrt1-t^2\nendalign*\n\nTo the weight w_1 we can apply Gauss-Legendre quadrature, to the weight w_2 we can apply Gauss-Chebyshev quadrature (with tiny modifications). This discretization of the measure can be used in our favor. The function mcdiscretization() takes the m discretization rules as an input\n\nfunction quad_gaussleg_mod(N, γ)\n    nodes, weights = quad_gaussleg(N + 1, γ)\n    nodes, γ * weights\nend\nfunction quad_gausscheb_mod(N, γ)\n    nodes, weights = quad_gausscheb(N + 1, γ)\n    return nodes, (1 - γ) * weights\nend\n\nN = 8\na, b = mcdiscretization(N, [n -> quad_gaussleg_mod(n, γ); n -> quad_gausscheb_mod(n, γ)])\nnodes, weights = golubwelsch(a, b)\nint_mc = sum(w)\nprint(\"Discretization error:\\t$(abs(int_exact-int_mc))\\twith $(length(n)) nodes\")\n\nEt voilà, no error with fewer nodes. (For this example, we'd need just a single node.)\n\nThe function mcdiscretization() is able to construct the recurrence coefficients of the orthogonal polynomials relative to the weight w. Let's inspect the values of the recurrence coefficients a little more. For gamma = 0, we are in the world of Chebyshev polynomials, for gamma = 1, we enter the realm of Legendre polynomials. And in between? That's exactly where the weight w comes in: it can be thought of as an interpolatory weight, interpolating Legendre polynomials and Chebyshev polynomials. Let's verify this by plotting the recurrence coefficients for several values of gamma.\n\nΓ = 0:0.1:1;\nab = [mcdiscretization(N,\n          [n -> quad_gaussleg_mod(n, gam); n -> quad_gausscheb_mod(n, gam)])\n      for gam in Γ];\nbb = hcat([ab[i][2] for i in 1:length(Γ)]...);\nb_leg = rm_legendre(N)[2];\nb_cheb = rm_chebyshev1(N)[2]\nbb[:, 1] - b_cheb\n\nbb[:, end] - b_leg\n\nLet's plot these values to get a better feeling.\n\nusing Plots\nplot(Γ, bb', yaxis = :log10, w = 3, legend = false)\nzs, os = zeros(N), ones(N)\nscatter!(zs, b_cheb, marker = :x)\nscatter!(os, b_leg, marker = :circle)\n\nxlabel!(\"Gamma\")\nylabel!(\"Beta\")\n\nThe crosses denote the values of the β recursion coefficients for Chebyshev polynomials; the circles the β recursion coefficients for Legendre polynomials. The interpolating line in between stands for the β recursion coefficients of w(t gamma).","category":"section"},{"location":"pce_tutorial/#CommonRandomVariables","page":"Basic Usage","title":"Common Random Variables","text":"Polynomial chaos expansion (PCE) is a Hilbert space technique for random variables with finite variance. Mathematically equivalent to Fourier series expansions for periodic signals, PCE allows characterizing a random variable in terms of its PCE coefficients (aka Fourier coefficients). That is, the PCE of a random variable mathsfx is given by\n\nmathsfx = sum_i=0^L x_i phi_i\n\nwhere x_i are the so-called PCE coefficients, and phi_i are the orthogonal polynomials that are orthogonal relative to the probability density function of mathsfx.\n\nThis tutorial walks you through the PCE of common random variables, namely Gaussian (gaussian), Beta (beta01), Uniform(uniform01), Logistic (logistic), and shows how they are implemented in PolyChaos.","category":"section"},{"location":"pce_tutorial/#Construction-of-Basis","page":"Basic Usage","title":"Construction of Basis","text":"using PolyChaos\n\nThe orthogonal polynomials are constructed using the OrthoPoly-type (here of degree at most d). For canonical measures, special constructors are implemented:\n\nd = 6\n\nmyops = Dict()\npolynames = [\"gaussian\", \"beta01\", \"uniform01\", \"logistic\"]\n\n# gaussian\ngaussian = GaussOrthoPoly(d);\nmyops[\"gaussian\"] = gaussian\n\n# beta01\nα, β = 1.3, 2.2\nbeta01 = Beta01OrthoPoly(d, α, β);\nmyops[\"beta01\"] = beta01\n\n# uniform01\nuniform01 = Uniform01OrthoPoly(d);\nmyops[\"uniform01\"] = uniform01\n\n# logistic\nlogistic = LogisticOrthoPoly(d);\nmyops[\"logistic\"] = logistic;\n\nmyops\n\nFor example, let's evaluate the Gaussian basis polynomials at some points\n\npoints, degrees = randn(10), 0:2:d\n\n[evaluate(degree, points, gaussian) for degree in degrees]","category":"section"},{"location":"pce_tutorial/#Finding-PCE-Coefficients","page":"Basic Usage","title":"Finding PCE Coefficients","text":"Having constructed the orthogonal bases, the question remains how to find the PCE coefficients for the common random variables. Every random variable can be characterized exactly by two PCE coefficients. For a Gaussian random variable, this is familiar: the mean and the variance suffice to describe a Gaussian random variable entirely. The same is true for any random variable of finite variance given the right basis. The function convert2affinePCE provides the first two PCE coefficients (hence the name affine) for the common random variables.","category":"section"},{"location":"pce_tutorial/#Gaussian","page":"Basic Usage","title":"Gaussian","text":"Given the Gaussian random variable mathsfx sim mathcalN(mu sigma^2) with sigma  0, the affine PCE coefficients are\n\n# Gaussian\nμ, σ = 2.0, 0.2\npce_gaussian = convert2affinePCE(μ, σ, gaussian)","category":"section"},{"location":"pce_tutorial/#Uniform","page":"Basic Usage","title":"Uniform","text":"Given the uniform random variable mathsfx sim mathcalU(a b) with finite support ab, the affine PCE coefficients are\n\na, b = -0.3, 1.2\nconvert2affinePCE(a, b, uniform01)\n\nInstead, if the expected value and standard deviation are known, the affine PCE coefficients of the uniform random variable are\n\npce_uniform = convert2affinePCE(μ, σ, uniform01; kind = \"μσ\")\n# notice that the zero-order coefficient IS equivalent to the expected value μ","category":"section"},{"location":"pce_tutorial/#Beta","page":"Basic Usage","title":"Beta","text":"Given the Beta random variable mathsfx sim mathcalB(a b alpha beta) with finite support ab and shape parameters alpha beta  0, the affine PCE coefficients are\n\nconvert2affinePCE(a, b, beta01)\n\nInstead, if the expected value and standard deviation are known, the affine PCE coefficients of the uniform random variable are\n\npce_beta = convert2affinePCE(μ, σ, beta01; kind = \"μσ\")","category":"section"},{"location":"pce_tutorial/#Logistic","page":"Basic Usage","title":"Logistic","text":"Given the logistic random variable mathsfx sim mathcalL(a_1a_2) where a_20 with the probability density function\n\nrho(t) = frac14 a_2  operatornamesech^2 left(fract-a_12a_2right)\n\nthe affine PCE coefficients of the uniform random variable are\n\na1, a2 = μ, sqrt(3) * σ / pi\npce_logistic = convert2affinePCE(a1, a2, logistic)","category":"section"},{"location":"pce_tutorial/#Moments","page":"Basic Usage","title":"Moments","text":"It is a key feature of PCE to compute moments from the PCE coefficients alone; no sampling is required.","category":"section"},{"location":"pce_tutorial/#Gaussian-2","page":"Basic Usage","title":"Gaussian","text":"mean(pce_gaussian, myops[\"gaussian\"]), std(pce_gaussian, myops[\"gaussian\"])","category":"section"},{"location":"pce_tutorial/#Uniform-2","page":"Basic Usage","title":"Uniform","text":"mean(pce_uniform, myops[\"uniform01\"]), std(pce_uniform, myops[\"uniform01\"])","category":"section"},{"location":"pce_tutorial/#Beta-2","page":"Basic Usage","title":"Beta","text":"mean(pce_beta, myops[\"beta01\"]), std(pce_beta, myops[\"beta01\"])","category":"section"},{"location":"pce_tutorial/#Logistic-2","page":"Basic Usage","title":"Logistic","text":"mean(pce_logistic, myops[\"logistic\"]), std(pce_logistic, myops[\"logistic\"])","category":"section"},{"location":"pce_tutorial/#Sampling","page":"Basic Usage","title":"Sampling","text":"Having found the PCE coefficients, it may be useful to sample the random variables. That means, find N realizations of the random variable that obey the random variable's probability density function. This is done in two steps:\n\nDraw N samples from the measure (sampleMeasure()), and then\nEvaluate the basis polynomials and multiply times the PCE coefficients, i.e. sum_i=0^L x_i phi_i(xi_j) where xi_j is the j-th sample from the measure (evaluatePCE()).\n\nBoth steps are combined in the function samplePCE().","category":"section"},{"location":"pce_tutorial/#Gaussian-3","page":"Basic Usage","title":"Gaussian","text":"using Statistics\nN = 1000\nξ_gaussian = sampleMeasure(N, myops[\"gaussian\"])\nsamples_gaussian = evaluatePCE(pce_gaussian, ξ_gaussian, myops[\"gaussian\"])\n# samplePCE(N,pce_gaussian,myops[\"gaussian\"])","category":"section"},{"location":"pce_tutorial/#Uniform-3","page":"Basic Usage","title":"Uniform","text":"ξ_uniform = sampleMeasure(N, myops[\"uniform01\"])\nsamples_uniform = evaluatePCE(pce_uniform, ξ_uniform, myops[\"uniform01\"])\n# samples_uniform = samplePCE(N,pce_uniform,myops[\"uniform01\"])","category":"section"},{"location":"pce_tutorial/#Beta-3","page":"Basic Usage","title":"Beta","text":"ξ_beta = sampleMeasure(N, myops[\"beta01\"])\nsamples_beta = evaluatePCE(pce_beta, ξ_beta, myops[\"beta01\"])\n# samples_beta = samplePCE(N,pce_beta,myops[\"beta01\"])","category":"section"},{"location":"pce_tutorial/#Logistic-3","page":"Basic Usage","title":"Logistic","text":"ξ_logistic = sampleMeasure(N, myops[\"logistic\"])\nsamples_logistic = evaluatePCE(pce_logistic, ξ_logistic, myops[\"logistic\"])\n# samples_logistic = samplePCE(N,pce_logistic,myops[\"logistic\"])","category":"section"},{"location":"quadrature_rules/#QuadratureRules","page":"Quadrature Rules","title":"Quadrature Rules","text":"In this tutorial, we investigate how recurrence coefficients of orthogonal polynomials lead to quadrature rules.\n\nWe want to solve the integral\n\nI = int_-1^1 f(t) w(t) mathrmd t\n\nwith the weight function\n\nw(t) = (1-t)^a (1+t)^b\n\nfor all t in -1 1 and a b  -1. For the function f we choose\n\nf(t) = t^2\n\nTo solve the integral, we do the following:\n\nChoose number of nodes N;\nGenerate recurrence coefficients;\nGenerate quadrature rule from those recurrence coefficients.\n\nWe will compare Gauss quadrature to Gauss-Radau quadrature and Gauss-Lobatto quadrature.\n\nMake sure to check out this tutorial too.\n\nLet's begin:\n\nusing PolyChaos, LinearAlgebra\nmy_f(t) = t^2\na, b = 1.23, 3.45 # shape parameters of Jacobi weight\nint_exact = 0.353897; # reference value \n\nNow we compute N recurrence coefficients.\n\nN = 4\nα, β = rm_jacobi(N + 1, a, b)","category":"section"},{"location":"quadrature_rules/#Gauss","page":"Quadrature Rules","title":"Gauss","text":"The first quadrature rule is Gauss quadrature. This method goes back to Golub and Welsch.\n\nn_gauss, w_gauss = gauss(N, α, β)\nint_gauss = dot(w_gauss, my_f.(n_gauss))\nprint(\"first point:\\t $(n_gauss[1])\\n\")\nprint(\"end point:\\t $(n_gauss[end])\\n\")\nprint(\"error Gauss:\\t $(int_gauss - int_exact)\\n\")\n\nSince Gauss quadrature has a degree of exactness of 2N-1, the value of the integral is exact.","category":"section"},{"location":"quadrature_rules/#Gauss-Radau","page":"Quadrature Rules","title":"Gauss-Radau","text":"Gauss-Radau quadrature is a variant of Gauss quadrature that allows including a value of a node that has to be included. We choose to include the right end point t = 10.\n\nn_radau, w_radau = radau(N - 1, α, β, 1.0)\nint_radau = dot(w_radau, my_f.(n_radau))\nprint(\"first point:\\t $(n_radau[1])\\n\")\nprint(\"end point:\\t $(n_radau[end])\\n\")\nprint(\"error Radau:\\t $(int_radau - int_exact)\")","category":"section"},{"location":"quadrature_rules/#Gauss-Lobatto","page":"Quadrature Rules","title":"Gauss-Lobatto","text":"Next, we look at Gauss-Lobatto quadrature, which allows to include two points. We choose to include the left and end point of the interval, which are t in -10 10.\n\nn_lob, w_lob = lobatto(N - 2, α, β, -1.0, 1.0)\nint_lob = dot(w_lob, my_f.(n_lob))\nprint(\"first point:\\t $(n_lob[1])\\n\")\nprint(\"end point:\\t $(n_lob[end])\\n\")\nprint(\"error Lobatto:\\t $(int_lob - int_exact)\")\n\nThere are other quadratures that we subsume as all-purpose quadrature rules. These include Fejér's first and second rule, and Clenshaw-Curtis quadrature.","category":"section"},{"location":"quadrature_rules/#Fejér's-First-Rule","page":"Quadrature Rules","title":"Fejér's First Rule","text":"Fejér's first rule does not include the end points of the interval.\n\nn_fej, w_fej = fejer(N)\nint_fej = dot(w_fej, my_f.(n_fej) .* (1 .- n_fej) .^ a .* (1 .+ n_fej) .^ b)\nprint(\"first point:\\t $(n_fej[1])\\n\")\nprint(\"end point:\\t $(n_fej[end])\\n\")\nprint(\"error Fejer:\\t $(int_fej-int_exact)\")","category":"section"},{"location":"quadrature_rules/#Fejér's-Second-Rule","page":"Quadrature Rules","title":"Fejér's Second Rule","text":"Fejér's second rule does include the end points of the interval.\n\nn_fej2, w_fej2 = fejer2(N)\nint_fej2 = dot(w_fej2, my_f.(n_fej2) .* (1 .- n_fej2) .^ a .* (1 .+ n_fej2) .^ b)\nprint(\"first point:\\t $(n_fej2[1])\\n\")\nprint(\"end point:\\t $(n_fej2[end])\\n\")\nprint(\"error Fejer2:\\t $(int_fej2 - int_exact)\")","category":"section"},{"location":"quadrature_rules/#Clenshaw-Curtis","page":"Quadrature Rules","title":"Clenshaw-Curtis","text":"Clenshaw-Curtis quadrature is similar to Féjer's second rule, as in it includes the end points of the integration interval. For the same number of nodes, it is also more accurate than Féjer's rules, generally speaking.\n\nn_cc, w_cc = clenshaw_curtis(N)\nint_cc = dot(w_cc, my_f.(n_cc) .* (1 .- n_cc) .^ a .* (1 .+ n_cc) .^ b)\nprint(\"first point:\\t\\t $(n_cc[1])\\n\")\nprint(\"end point:\\t\\t $(n_cc[end])\\n\")\nprint(\"error Clenshaw-Curtis:\\t $(int_cc - int_exact)\")\n\nAs we can see, for the same number of nodes N, the quadrature rules based on the recurrence coefficients can greatly outperform the all-purpose quadratures. So, whenever possible, use quadrature rules based on recurrence coefficients of the orthogonal polynomials relative to the underlying measure. Make sure to check out this tutorial too.","category":"section"},{"location":"#Overview","page":"Overview","title":"Overview","text":"PolyChaos is a collection of numerical routines for orthogonal polynomials, written in the Julia programming language. Starting from some non-negative weight (aka an absolutely continuous non-negative measure), PolyChaos allows\n\nto compute the coefficients for the monic three-term recurrence relation,\nto evaluate the orthogonal polynomials at arbitrary points,\nto compute the quadrature rule,\nto compute tensors of scalar products,\nto do all of the above in a multivariate setting (aka product measures).\n\nIf the weight function is a probability density function, PolyChaos further provides routines to compute polynomial chaos expansions (PCEs) of random variables with this very density function. These routines allow\n\nto compute affine PCE coefficients for arbitrary densities,\nto compute moments,\nto compute the tensors of scalar products.\n\nPolyChaos contains several canonical orthogonal polynomials, such as Jacobi or Hermite polynomials. For these, closed-form expressions and state-of-the art quadrature rules are used whenever possible. However, a cornerstone principle of PolyChaos is to provide all the functionality for user-specific, arbitrary weights.\n\nnote: Note\nWhat PolyChaos is not (at least currently):a self-contained introduction to orthogonal polynomials, quadrature rules and polynomial chaos expansions. We assume the user brings some experience to the table. However, over time we will focus on strengthening the tutorial character of the package.\na symbolic toolbox\na replacement for FastGaussQuadrature.jl","category":"section"},{"location":"#Installation","page":"Overview","title":"Installation","text":"The package requires Julia 1.3 or newer. To install PolyChaos.jl, use the Julia package manager:\n\nusing Pkg\nPkg.add(\"PolyChaos\")\n\nThis will install PolyChaos and its dependencies. Once that is done, load the package:\n\nusing PolyChaos\n\nThat's it.\n\nLet's take a look at a simple example. We would like to solve the integral\n\nint_0^1 6 x^5 mathrmdx\n\nExploiting the underlying uniform measure, the integration can be done exactly with a 3-point quadrature rule.\n\njulia> using PolyChaos\n\njulia> opq = Uniform01OrthoPoly(3, addQuadrature = true)\nUniform01OrthoPoly{Array{Float64,1},Uniform01Measure,Quad{Float64,Array{Float64,1}}}(3, [0.5, 0.5, 0.5, 0.5], [1.0, 0.08333333333333333, 0.06666666666666667, 0.06428571428571428], Uniform01Measure(PolyChaos.w_uniform01, (0.0, 1.0), true), Quad{Float64,Array{Float64,1}}(\"golubwelsch\", 3, [0.11270166537925838, 0.49999999999999994, 0.8872983346207417], [0.2777777777777777, 0.4444444444444444, 0.27777777777777757]))\n\njulia> integrate(x -> 6x^5, opq)\n0.9999999999999993\n\njulia> show(opq)\n\nUnivariate orthogonal polynomials\ndegree:         3\n#coeffs:        4\nα =             [0.5, 0.5, 0.5, 0.5]\nβ =             [1.0, 0.08333333333333333, 0.06666666666666667, 0.06428571428571428]\n\nMeasure dλ(t)=w(t)dt\nw:      w_uniform01\ndom:    (0.0, 1.0)\nsymmetric:      true\n\nTo get going with PolyChaos check out the tutorials such as the one on numerical integration. In case you are unfamiliar with orthogonal polynomials, perhaps this background information is of help.","category":"section"},{"location":"#References","page":"Overview","title":"References","text":"The code base of PolyChaos is partially based on Walter Gautschi's Matlab suite of programs for generating orthogonal polynomials and related quadrature rules, with much of the theory presented in his book Orthogonal Polynomials: Computation and Approximation published in 2004 by the Oxford University Press.\n\nFor the theory of polynomial chaos expansion, we mainly consulted T. J. Sullivan. Introduction to Uncertainty Quantification. Springer International Publishing Switzerland. 2015.","category":"section"},{"location":"#Contributing","page":"Overview","title":"Contributing","text":"Please refer to the SciML ColPrac: Contributor's Guide on Collaborative Practices for Community Packages for guidance on PRs, issues, and other matters relating to contributing to SciML.\nSee the SciML Style Guide for common coding practices and other style decisions.\nThere are a few community forums:\nThe #diffeq-bridged and #sciml-bridged channels in the Julia Slack\nThe #diffeq-bridged and #sciml-bridged channels in the Julia Zulip\nOn the Julia Discourse forums\nSee also SciML Community page","category":"section"},{"location":"#Citing","page":"Overview","title":"Citing","text":"If you found the software useful and applied it to your own research, we'd appreciate a citation. Add the following to your BibTeX file\n\n@ARTICLE{2020arXiv200403970M,\n       author = {{M{\\\"u}hlpfordt}, Tillmann and {Zahn}, Frederik and {Hagenmeyer}, Veit and\n         {Faulwasser}, Timm},\n        title = \"{PolyChaos.jl -- A Julia Package for Polynomial Chaos in Systems and Control}\",\n      journal = {arXiv e-prints},\n     keywords = {Electrical Engineering and Systems Science - Systems and Control, Mathematics - Numerical Analysis, Mathematics - Optimization and Control},\n         year = 2020,\n        month = apr,\n          eid = {arXiv:2004.03970},\n        pages = {arXiv:2004.03970},\narchivePrefix = {arXiv},\n       eprint = {2004.03970},\n}\n\nOf course, you are more than welcome to partake in GitHub's gamification: starring and forking is much appreciated.\n\nEnjoy.","category":"section"},{"location":"#Reproducibility","page":"Overview","title":"Reproducibility","text":"<details><summary>The documentation of this SciML package was built using these direct dependencies,</summary>\n\nusing Pkg # hide\nPkg.status() # hide\n\n</details>\n\n<details><summary>and using this machine and Julia version.</summary>\n\nusing InteractiveUtils # hide\nversioninfo() # hide\n\n</details>\n\n<details><summary>A more complete overview of all dependencies and their versions is also provided.</summary>\n\nusing Pkg # hide\nPkg.status(; mode = PKGMODE_MANIFEST) # hide\n\n</details>\n\nusing TOML\nusing Markdown\nversion = TOML.parse(read(\"../../Project.toml\", String))[\"version\"]\nname = TOML.parse(read(\"../../Project.toml\", String))[\"name\"]\nlink_manifest = \"https://github.com/SciML/\" * name * \".jl/tree/gh-pages/v\" * version *\n                \"/assets/Manifest.toml\"\nlink_project = \"https://github.com/SciML/\" * name * \".jl/tree/gh-pages/v\" * version *\n               \"/assets/Project.toml\"\nMarkdown.parse(\"\"\"You can also download the\n[manifest]($link_manifest)\nfile and the\n[project]($link_project)\nfile.\n\"\"\")","category":"section"},{"location":"type_hierarchy/","page":"Type Hierarchy","title":"Type Hierarchy","text":"note: Note\nIf you are unfamiliar with the mathematical background of orthogonal polynomials, check out this tutorial.","category":"section"},{"location":"type_hierarchy/#Type-Hierarchy","page":"Type Hierarchy","title":"Type Hierarchy","text":"Let's look at the types PolyChaos provides. There are four AbstractTypes: AbstractMeasure, AbstractOrthoPoly, AbstractQuad, and AbstractTensor. AbstractMeasure is the core on which AbstractOrthoPoly builds, on which AbstractQuad builds, which is then used by AbstractTensor.","category":"section"},{"location":"type_hierarchy/#AbstractMeasure","page":"Type Hierarchy","title":"AbstractMeasure","text":"The type tree for AbstractMeasure looks as follows\n\njulia> using AbstractTrees, PolyChaos\n\njulia> AbstractTrees.children(x::Type) = subtypes(x)\n\njulia> print_tree(AbstractMeasure)\nAbstractMeasure\n├─ AbstractCanonicalMeasure\n│  ├─ Beta01Measure\n│  ├─ GammaMeasure\n│  ├─ GaussMeasure\n│  ├─ HermiteMeasure\n│  ├─ JacobiMeasure\n│  ├─ LaguerreMeasure\n│  ├─ LegendreMeasure\n│  ├─ LogisticMeasure\n│  ├─ MeixnerPollaczekMeasure\n│  ├─ Uniform01Measure\n│  ├─ Uniform_11Measure\n│  ├─ genHermiteMeasure\n│  └─ genLaguerreMeasure\n├─ Measure\n└─ ProductMeasure\n\nThere are several canonical measures that PolyChaos provides, all gathered in as subtypes of AbstractCanonicalMeasure. The Measure type is a generic measure, and ProductMeasure has an obvious meaning.\n\nWhat are the relevant fields?","category":"section"},{"location":"type_hierarchy/#Measure","page":"Type Hierarchy","title":"Measure","text":"It all begins with a measure, more specifically, absolutely continuous measures. What are the fields of such a type Measure?\n\nField Meaning\nname::String Name of measure\nw::Function Weight function w Omega rightarrow mathbbR\ndom::Tuple{Real,Real} Domain $ \\Omega$\nsymmetric::Bool Is w symmetric relative to some m in Omega, hence w(m-x) = w(m+x) for all x in Omega?\npars::Dict Additional parameters (e.g. shape parameters for Beta distribution)\n\nThey are a name, a weight function w Omega rightarrow mathbbR with domain Omega (dom). If the weight function is symmetric relative to some m in Omega, the field symmetric should be set to true. Symmetry relative to m means that\n\nforall x in Omega quad w(m-x) = w(m+x)\n\nFor example, the Gaussian probability density\n\nw(x) = frac1sqrt2pi mathrme^-x^22\n\nis symmetric relative to the origin m=0. If the weight function has any parameters, then they are stored in the dictionary pars. For example, the probability density of the Beta distribution on Omega = 01 has two positive shape parameters alpha beta  0\n\nw(x) = frac1B(alphabeta) x^alpha-1 (1-x)^beta-1\n\nThis tutorial shows the above in action.","category":"section"},{"location":"type_hierarchy/#ProductMeasure","page":"Type Hierarchy","title":"ProductMeasure","text":"So far, everything was univariate, the weight of the measure was mapping real numbers to real numbers. PolyChaos can handle product measures too. Let's assume the weight function is a product of two independent Gaussian densities\n\nw mathbbR times mathbbR rightarrow mathbbR quad w(x) = frac1sqrt2pi mathrme^x_1^22 frac1sqrt2pi mathrme^x_2^22\n\nThe type ProductMeasure serves this purpose, with its straightforward fields\n\nField Meaning\nw::Function Weight function\nmeasures::Vector{<:AbstractMeasure} Vector of univariate measures\n\nThis tutorial shows the above in action.","category":"section"},{"location":"type_hierarchy/#Canonical-Measures","page":"Type Hierarchy","title":"Canonical Measures","text":"Canonical measures are special, because we know their orthogonal polynomials. That is why several canonical measures are pre-defined in PolyChaos. Some of them may require additional parameters. (alphabetical order)","category":"section"},{"location":"type_hierarchy/#Beta01Measure","page":"Type Hierarchy","title":"Beta01Measure","text":"Field Meaning\nw::Function frac1B(alphabeta)  t^alpha-1 (1-t)^beta-1\ndom::Tuple{<:Real,<:Real} (0 1)\nsymmetric::Bool true if alpha = beta\nashapeParameter::Real alpha  0\nbshapeParameter::Real beta  0","category":"section"},{"location":"type_hierarchy/#GammaMeasure","page":"Type Hierarchy","title":"GammaMeasure","text":"Field Meaning\nw::Function fracbeta^alphaGamma(alpha) t^alpha-1 exp(-beta t)\ndom::Tuple{<:Real,<:Real} (0 infty)\nsymmetric::Bool false\nshapeParameter::Real alpha  0\nrateParameter::Real 1","category":"section"},{"location":"type_hierarchy/#GaussMeasure","page":"Type Hierarchy","title":"GaussMeasure","text":"Field Meaning\nw::Function frac1sqrt2 pi  exp left( - fract^22 right)\ndom::Tuple{<:Real,<:Real} (-infty infty)\nsymmetric::Bool true","category":"section"},{"location":"type_hierarchy/#HermiteMeasure","page":"Type Hierarchy","title":"HermiteMeasure","text":"Field Meaning\nw::Function $ \\exp\\left( - t^2 \\right)$\ndom::Tuple{<:Real,<:Real} (-infty infty)\nsymmetric::Bool true","category":"section"},{"location":"type_hierarchy/#JacobiMeasure","page":"Type Hierarchy","title":"JacobiMeasure","text":"Field Meaning\ndom::Tuple{<:Real,<:Real} (-1 1)\nsymmetric::Bool true if alpha = beta\nashapeParameter::Real alpha  -1\nbshapeParameter::Real beta  -1","category":"section"},{"location":"type_hierarchy/#LaguerreMeasure","page":"Type Hierarchy","title":"LaguerreMeasure","text":"Field Meaning\nw::Function exp(-t)\ndom::Tuple{<:Real,<:Real} (0 infty)\nsymmetric::Bool true","category":"section"},{"location":"type_hierarchy/#LegendreMeasure","page":"Type Hierarchy","title":"LegendreMeasure","text":"Field Meaning\nw::Function 1\ndom::Tuple{<:Real,<:Real} (-1 1)\nsymmetric::Bool true","category":"section"},{"location":"type_hierarchy/#LogisticMeasure","page":"Type Hierarchy","title":"LogisticMeasure","text":"Field Meaning\nw::Function fracexp(-t)(1+exp(-t))^2\ndom::Tuple{<:Real,<:Real} (-infty infty)\nsymmetric::Bool true","category":"section"},{"location":"type_hierarchy/#MeixnerPollaczekMeasure","page":"Type Hierarchy","title":"MeixnerPollaczekMeasure","text":"Field Meaning\nw::Function frac12 pi exp((2phi-pi)t) lvertGamma(lambda + mathrmit)rvert^2\ndom::Tuple{<:Real,<:Real} (-inftyinfty)\nsymmetric::Bool false\nλParameter::Real lambda  0\nϕParameter::Real 0  phi  pi","category":"section"},{"location":"type_hierarchy/#Uniform01Measure","page":"Type Hierarchy","title":"Uniform01Measure","text":"Field Meaning\nw::Function 1\ndom::Tuple{<:Real,<:Real} (0 1)\nsymmetric::Bool true","category":"section"},{"location":"type_hierarchy/#Uniform_11Measure","page":"Type Hierarchy","title":"Uniform_11Measure","text":"Field Meaning\nw::Function 05\ndom::Tuple{<:Real,<:Real} (-1 1)\nsymmetric::Bool true","category":"section"},{"location":"type_hierarchy/#genHermiteMeasure","page":"Type Hierarchy","title":"genHermiteMeasure","text":"Field Meaning\nw::Function $ \\lvert t \\rvert^{2 \\mu}\\exp \\left( - t^2 \\right)$\ndom::Tuple{<:Real,<:Real} (-infty infty)\nsymmetric::Bool true\nmuParameter::Real mu  -05","category":"section"},{"location":"type_hierarchy/#genLaguerreMeasure","page":"Type Hierarchy","title":"genLaguerreMeasure","text":"Field Meaning\nw::Function t^alphaexp(-t)\ndom::Tuple{<:Real,<:Real} (0infty)\nsymmetric::Bool false\nshapeParameter::Bool alpha-1","category":"section"},{"location":"type_hierarchy/#AbstractOrthoPoly","page":"Type Hierarchy","title":"AbstractOrthoPoly","text":"Orthogonal polynomials are at the heart of PolyChaos. The type tree for AbstractOrthoPoly looks as follows\n\njulia> print_tree(AbstractOrthoPoly)\nAbstractOrthoPoly\n├─ AbstractCanonicalOrthoPoly\n│  ├─ Beta01OrthoPoly\n│  ├─ GammaOrthoPoly\n│  ├─ GaussOrthoPoly\n│  ├─ HermiteOrthoPoly\n│  ├─ JacobiOrthoPoly\n│  ├─ LaguerreOrthoPoly\n│  ├─ LegendreOrthoPoly\n│  ├─ LogisticOrthoPoly\n│  ├─ MeixnerPollaczekOrthoPoly\n│  ├─ Uniform01OrthoPoly\n│  ├─ Uniform_11OrthoPoly\n│  ├─ genHermiteOrthoPoly\n│  └─ genLaguerreOrthoPoly\n├─ MultiOrthoPoly\n└─ OrthoPoly\n\nIt mirrors the type tree from AbstractMeasure: there is a generic (univariate) type OrthoPoly, a multivariate extension MultiOrthoPoly for product measures, and several univariate canonical orthogonal polynomials.","category":"section"},{"location":"type_hierarchy/#OrthoPoly","page":"Type Hierarchy","title":"OrthoPoly","text":"Given an absolutely continuous measure, we are wondering what are the monic polynomials phi_i Omega rightarrow mathbbR that are orthogonal relative to this very measure? Mathematically this reads\n\nlangle phi_i phi_j rangle = int_Omega phi_i(t) phi_j(t) w(t) mathrmdt =\nbegincases\n 0  i=j \n= 0  ineq j\nendcases\n\nThey can be constructed using the type OrthoPoly, which has the fields\n\nName Meaning\nname::String Name\ndeg::Int Maximum degree\nα::Vector{<:Real} Vector of recurrence coefficients α\nβ::Vector{<:Real} Vector of recurrence coefficients β\nmeas::AbstractMeasure Underlying measure\n\nThe purpose of name is obvious. The integer deg stands for the maximum degree of the polynomials. Rather than storing the polynomials phi_i themselves, we store the recurrence coefficients α, β that characterize the system of orthogonal polynomials. These recurrence coefficients are the single most important piece of information for the orthogonal polynomials. For several common measures, there exist analytic formulae. These are built-in to PolyChaos and should be used whenever possible.\n\nThis tutorial shows the above in action.","category":"section"},{"location":"type_hierarchy/#MultiOrthoPoly","page":"Type Hierarchy","title":"MultiOrthoPoly","text":"Just as we did in the univariate case, we use ProductMeasure as a building block for multivariate orthogonal polynomials. The type MultiOrthoPoly combines product measures with the respective orthogonal polynomials and their quadrature rules. Its fields are\n\nName Meaning\nname::Vector{String} Vector of names\ndeg::Int Maximum degree\ndim::Int Dimension\nind::Matrix{<:Int} Array of multi-indices\nmeasure::ProductMeasure Underlying product measure\n\nThe names of the univariate bases are stored in names; the maximum degree of the basis is deg; the overall dimension of the multivariate basis is dim; the multi-index ind maps the j-th multivariate basis to the elements of the univariate bases; the product measure is stored in meas; finally, all univariate bases are collected in uni.\n\nThis tutorial shows the above in action.","category":"section"},{"location":"type_hierarchy/#AbstractCanonicalOrthoPoly","page":"Type Hierarchy","title":"AbstractCanonicalOrthoPoly","text":"These are the bread-and-butter polynomials: polynomials for which we know analytic formulae for the recursion coefficients. The following canonical orthogonal polynomials are implemented\n\njulia> print_tree(AbstractCanonicalOrthoPoly)\nAbstractCanonicalOrthoPoly\n├─ Beta01OrthoPoly\n├─ GammaOrthoPoly\n├─ GaussOrthoPoly\n├─ HermiteOrthoPoly\n├─ JacobiOrthoPoly\n├─ LaguerreOrthoPoly\n├─ LegendreOrthoPoly\n├─ LogisticOrthoPoly\n├─ MeixnerPollaczekOrthoPoly\n├─ Uniform01OrthoPoly\n├─ Uniform_11OrthoPoly\n├─ genHermiteOrthoPoly\n└─ genLaguerreOrthoPoly\n\nTheir fields follow\n\nName Meaning\ndeg::Int Maximum degree\nα::Vector{<:Real} Vector of recurrence coefficients\nβ::Vector{<:Real} Vector of recurrence coefficients\nmeasure::CanonicalMeasure Underlying canonical measure\nquad::AbstractQuad Quadrature rule","category":"section"},{"location":"type_hierarchy/#Quad","page":"Type Hierarchy","title":"Quad","text":"Quadrature rules are intricately related to orthogonal polynomials. An n-point quadrature rule is a pair of so-called nodes t_k and weights w_k for k=1dotsn that allow to solve integrals relative to the measure\n\nint_Omega f(t) w(t) mathrmd t approx sum_k=1^n w_k f(t_k)\n\nIf the integrand f is polynomial, then the specific Gauss quadrature rules possess the remarkable property that an n-point quadrature rule can integrate polynomial integrands f of degree at most 2n-1 exactly; no approximation error is made.\n\nThe fields of Quad are\n\nName Meaning\nname::String Name\nNquad::Int Number n of quadrature points\nnodes::Vector{<:Real} Nodes\nweights::Vector{<:Real} Weights\n\nwith obvious meanings.\n\nPolyChaos provides the type EmptyQuad that is added in case no quadrature rule is desired.\n\nThis tutorial shows the above in action.","category":"section"},{"location":"type_hierarchy/#Tensor","page":"Type Hierarchy","title":"Tensor","text":"The last type we need to address is Tensor. It is used to store the results of scalar products. Its fields are\n\nName Meaning\ndim: Dimension m of tensor langle phi_i_1 phi_i_2 cdots phi_i_m-1 phi_i_m rangle\nT::SparseVector{Float64,Int} Entries of tensor\nget::Function Function to get entries from T\nop::AbstractOrthoPoly Underlying univariate orthogonal polynomials\n\nThe dimension m of the tensor is the number of terms that appear in the scalar product. Let's assume we set m = 3, hence have langle phi_i phi_j phi_k rangle, then the concrete entry is obtained as Tensor.get([i,j,k]).\n\nThis tutorial shows the above in action.","category":"section"}]
}
